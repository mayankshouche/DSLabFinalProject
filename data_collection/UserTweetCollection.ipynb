{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('/home/sunny/fall_2020/ee460j/data/uselection_tweets_1jul_11nov.csv', nrows=10, sep=';')\n",
    "\n",
    "# path = '/home/sunny/fall_2020/ee460j/data/uselection_tweets_1jul_11nov.zip'\n",
    "path = \"uselection_tweets_1jul_11nov.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1005373425819553792, 1318619325402591232, 26487169, 818927131883356161, 1108472017144201216, 842071545296084992, 15937190, 11134252, 91882544, 468646961, 601535938, 3389073989, 41634520, 23022687, 582135529, 359403242, 473654129, 1084375028, 76543481, 18166778, 985728510}\n",
      "{803694179079458816, 834081571493785600, 1128409690902343680, 821784477076750338, 1129095209772552192, 1121369559078965250, 1253121466918408192, 1112714150080376832, 826283183767367680, 14298769, 357606935, 16513335, 216776631, 970207298, 29501253, 342863309, 68219213, 269314519, 260759782, 565469671, 74169715, 880404086, 138203134}\n"
     ]
    }
   ],
   "source": [
    "republican_users = pd.read_csv('republican_users.csv')\n",
    "republican_users\n",
    "\n",
    "republican_user_ids = set([int(id_) for id_ in republican_users.id.unique()])\n",
    "print(republican_user_ids)\n",
    "\n",
    "democrat_users = pd.read_csv('democratic_users.csv')\n",
    "democrat_user_ids = set([int(id_) for id_ in democrat_users.id.unique()])\n",
    "print(democrat_user_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "865\n",
      "539\n"
     ]
    }
   ],
   "source": [
    "path = '/home/sunny/fall_2020/ee460j/data/uselection_tweets_1jul_11nov.zip'\n",
    "\n",
    "chunksize = 10 ** 4\n",
    "\n",
    "count = 3\n",
    "republican_tweet_ids=[]\n",
    "democrat_tweet_ids=[]\n",
    "\n",
    "\n",
    "trump_tweets = []\n",
    "\n",
    "\n",
    "all_tweets_data = pd.read_csv(path, chunksize=chunksize, sep=';', compression='zip')\n",
    "for chunks in all_tweets_data:\n",
    "    temp_republican_id_list = chunks[(chunks['From-User-Id'].isin(republican_user_ids)) ][\"Id\"].tolist()\n",
    "    temp_democrat_id_list = chunks[(chunks['From-User-Id'].isin(democrat_user_ids)) ][\"Id\"].tolist()\n",
    "    if len(temp_republican_id_list) != 0:\n",
    "        for Id in temp_republican_id_list:\n",
    "            republican_tweet_ids.append(Id)\n",
    "    if len(temp_democrat_id_list) != 0:\n",
    "        for Id in temp_democrat_id_list:\n",
    "            democrat_tweet_ids.append(Id)\n",
    "            \n",
    "\n",
    "print(len(republican_tweet_ids))\n",
    "print(len(democrat_tweet_ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the tweets to a .txt file\n",
    "\n",
    "republican_tweet_ids_path = 'republican_tweet_ids_1.txt'\n",
    "democrat_tweet_ids_path = 'democrat_tweet_ids_1.txt'\n",
    "\n",
    "\n",
    "with open(republican_tweet_ids_path, 'w') as f:\n",
    "    for item in republican_tweet_ids:\n",
    "        f.write(\"%s\\n\" % str(item))\n",
    "\n",
    "with open(democrat_tweet_ids_path, 'w') as f:\n",
    "    for item in democrat_tweet_ids:\n",
    "        f.write(\"%s\\n\" % str(item))       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cols_to_keep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ec97da8b15a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# setup dataframe iterator, the ‘usecols’ parameter filters the columns in the csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m df_iter = pd.read_csv('/home/sunny/fall_2020/ee460j/data/uselection_tweets_1jul_11nov.zip', skiprows=1, compression='zip',\n\u001b[1;32m----> 6\u001b[1;33m chunksize=20000, usecols=cols_to_keep)\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cols_to_keep' is not defined"
     ]
    }
   ],
   "source": [
    "# columns we wish to keep/filter on\n",
    "\n",
    "\n",
    "# setup dataframe iterator, the ‘usecols’ parameter filters the columns in the csv\n",
    "df_iter = pd.read_csv('/home/sunny/fall_2020/ee460j/data/uselection_tweets_1jul_11nov.zip', skiprows=1, compression='zip',\n",
    "chunksize=20000, usecols=cols_to_keep)\n",
    "\n",
    "\n",
    "dfs = [] # this list will store the filtered dataframes for concatenation\n",
    "for df in df_iter:\n",
    "    temp_df = (df.rename(columns={col: col.lower() for col in df.columns})        \n",
    "    # filter\n",
    "    .pipe(lambda x: x[x.funded_amnt > 10000]))\n",
    "    dfs += [temp_df.copy()]\n",
    "    # combine filtered dfs into large output df\n",
    "    concat_df = pd.concat(dfs) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
