{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EvaluateModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f9c078aa1f714de08f79200fc269a871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_814db69be7d84fda81683e05326fb5c0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_870a048c054f4cdebf0d1a68545c1502",
              "IPY_MODEL_108723627e5a46fba933d8e0d1125b67"
            ]
          }
        },
        "814db69be7d84fda81683e05326fb5c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "870a048c054f4cdebf0d1a68545c1502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d475245471cf46919afcc87c5e7463ef",
            "_dom_classes": [],
            "description": "  1%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 931,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 12,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1bc4bfda63d5424f8ef41b28f6548819"
          }
        },
        "108723627e5a46fba933d8e0d1125b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fab226ff71aa4857a1c71488f7608ef7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/931 [00:18&lt;23:52,  1.56s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a30e8e249804b228a93cc8de7988a04"
          }
        },
        "d475245471cf46919afcc87c5e7463ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1bc4bfda63d5424f8ef41b28f6548819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fab226ff71aa4857a1c71488f7608ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a30e8e249804b228a93cc8de7988a04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "579bBwcvMU4e",
        "outputId": "e452e809-15c8-422c-cab8-1545b1e50791"
      },
      "source": [
        "!pip install transformers datasets tweet-preprocessor"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 7.6MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/38/0c24dce24767386123d528d27109024220db0e7a04467b658d587695241a/datasets-1.1.3-py3-none-any.whl (153kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 28.3MB/s \n",
            "\u001b[?25hCollecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 24.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 22.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.4)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 57.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.11.1)\n",
            "Collecting pyarrow>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n",
            "\u001b[K     |████████████████████████████████| 17.7MB 212kB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=793a1ef105f7812e677a8fac3028a9db0d3e8e3cb451bb996cec733265b61a53\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, xxhash, pyarrow, datasets, tweet-preprocessor\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed datasets-1.1.3 pyarrow-2.0.0 sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1 tweet-preprocessor-0.6.0 xxhash-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0AxO3wpL_oG"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import wordcloud\r\n",
        "import preprocessor as p # tweet-preprocessor\r\n",
        "import nltk\r\n",
        "import re\r\n",
        "import seaborn as sns\r\n",
        "import torch\r\n",
        "\r\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup\r\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\r\n",
        "from datasets import Dataset\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from scipy.special import softmax\r\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc3SmAkrPVVi"
      },
      "source": [
        "def auc_score(preds, labels):\r\n",
        "  soft_preds = softmax(preds, axis=1) # logit -> probability\r\n",
        "  print(preds.shape, labels.shape)\r\n",
        "  if np.shape(preds)[1] > 2: # check for multi-class\r\n",
        "    return roc_auc_score(labels, soft_preds, multi_class='ovr')\r\n",
        "  else:\r\n",
        "    soft_preds = soft_preds[:,1]\r\n",
        "    return roc_auc_score(labels, soft_preds)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzSoqAkAPkq5"
      },
      "source": [
        "device = \"cuda\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0yShuXhNH_1"
      },
      "source": [
        "X_val = pd.read_csv(\"/content/drive/MyDrive/X_val.csv.zip\")\r\n",
        "y_val = pd.read_csv(\"/content/drive/MyDrive/y_val.csv.zip\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbqTNj3AMlNP"
      },
      "source": [
        "def preprocess_tweet(tweet):\r\n",
        "  clean_tweet = tweet.replace('@', '')\r\n",
        "  clean_tweet = clean_tweet.replace('#', '')\r\n",
        "  clean_tweet = clean_tweet.replace('&', '')\r\n",
        "  clean_tweet = re.sub(r'[^A-Za-z0-9.!, ]+', '', clean_tweet)\r\n",
        "  split = [word.lower() for word in clean_tweet.split() if 'http' not in word.lower() and 'jpg' not in word.lower() and 'www' not in word.lower() and word.lower() not in['amp', 'qt']]\r\n",
        "  return ' '.join(split)\r\n",
        "\r\n",
        "\r\n",
        "X_val[\"clean_text\"] = X_val['text'].apply(lambda x: preprocess_tweet(x))\r\n",
        "y_val[\"label\"] = y_val['party'].apply(lambda party: 1 if party=='R' else 0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFsNKz21OL9F"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \r\n",
        "                                        do_lower_case=True)\r\n",
        "\r\n",
        "encoded_data_test = tokenizer.batch_encode_plus(\r\n",
        "  X_val.clean_text.values, \r\n",
        "  add_special_tokens=True, \r\n",
        "  return_attention_mask=True, \r\n",
        "  padding=True, \r\n",
        "  truncation=True, \r\n",
        "  return_tensors='pt'\r\n",
        ")\r\n",
        "\r\n",
        "input_ids_test = encoded_data_test['input_ids']\r\n",
        "attention_masks_test = encoded_data_test['attention_mask']\r\n",
        "labels_test = torch.tensor(y_val.label.values)\r\n",
        "\r\n",
        "BATCH_SIZE=128\r\n",
        "\r\n",
        "test_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\r\n",
        "\r\n",
        "test_dataloader = DataLoader(test_data,\r\n",
        "                             sampler=SequentialSampler(test_data),\r\n",
        "                             batch_size=BATCH_SIZE)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZOdoS6WPV7T"
      },
      "source": [
        "def evaluate(model, dataloader):\r\n",
        "  model.to(device)\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  loss_val_total = 0\r\n",
        "  predictions, true_vals = [], []\r\n",
        "  \r\n",
        "  progress_bar = tqdm(dataloader)\r\n",
        "  for batch in progress_bar:  \r\n",
        "    # convert data to CUDA\r\n",
        "    batch = tuple(b.to(device) for b in batch)\r\n",
        "    \r\n",
        "    inputs = {\r\n",
        "        'input_ids':      batch[0],\r\n",
        "        'attention_mask': batch[1],\r\n",
        "        'labels':         batch[2],\r\n",
        "    }\r\n",
        "\r\n",
        "    with torch.no_grad():        \r\n",
        "        outputs = model(**inputs) # get predictions\r\n",
        "        \r\n",
        "    loss = outputs[0]\r\n",
        "    logits = outputs[1]\r\n",
        "    loss_val_total += loss.item()\r\n",
        "\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    label_ids = inputs['labels'].cpu().numpy()\r\n",
        "    predictions.append(logits)\r\n",
        "    true_vals.append(label_ids)\r\n",
        "\r\n",
        "  loss_val_avg = loss_val_total/len(dataloader) \r\n",
        "\r\n",
        "  predictions = np.concatenate(predictions, axis=0)\r\n",
        "  true_vals = np.concatenate(true_vals, axis=0)\r\n",
        "\r\n",
        "  auc = auc_score(predictions, true_vals)\r\n",
        "\r\n",
        "  print(f'AUC: {auc}')\r\n",
        "  print(f'Cross-entropy loss: {loss_val_avg}')\r\n",
        "  print(f\"Accuracy: {accuracy_score(true_vals, np.argmax(predictions, axis=1))}\")  \r\n",
        "  sns.heatmap(confusion_matrix(true_vals, np.argmax(predictions, axis=1)), annot=True, fmt=\"d\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "f9c078aa1f714de08f79200fc269a871",
            "814db69be7d84fda81683e05326fb5c0",
            "870a048c054f4cdebf0d1a68545c1502",
            "108723627e5a46fba933d8e0d1125b67",
            "d475245471cf46919afcc87c5e7463ef",
            "1bc4bfda63d5424f8ef41b28f6548819",
            "fab226ff71aa4857a1c71488f7608ef7",
            "8a30e8e249804b228a93cc8de7988a04"
          ]
        },
        "id": "h9lHwGEtQmxY",
        "outputId": "3b370758-aa8f-42fb-9202-ccb5241a6cd2"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\r\n",
        "                                                      num_labels=2,\r\n",
        "                                                      output_attentions=False,\r\n",
        "                                                      output_hidden_states=False)\r\n",
        "\r\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/model_v2.model\"))\r\n",
        "\r\n",
        "evaluate(model, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9c078aa1f714de08f79200fc269a871",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=931.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}