{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BertV3.ipynb","provenance":[],"authorship_tag":"ABX9TyPrGYKPu3yUylCgl1e09Rb/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VjitfOFZJjV8","executionInfo":{"status":"ok","timestamp":1607478630854,"user_tz":360,"elapsed":3402,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"23c24c19-7652-422e-cd8b-4d0638c197fc"},"source":["!pip install transformers datasets tweet-preprocessor ray[tune] hyperopt"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.6/dist-packages (1.1.3)\n","Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.6.0)\n","Requirement already satisfied: ray[tune] in /usr/local/lib/python3.6/dist-packages (1.0.1.post1)\n","Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.11.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.4)\n","Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n","Requirement already satisfied: colorful in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.5.4)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.6.0)\n","Requirement already satisfied: opencensus in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.7.11)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.4.4)\n","Requirement already satisfied: gpustat in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.6.0)\n","Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.33.2)\n","Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.3.3)\n","Requirement already satisfied: aioredis in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.3.1)\n","Requirement already satisfied: google in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.0.3)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.12.4)\n","Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.7.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.13)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.0.0)\n","Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.7.3)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (7.1.2)\n","Requirement already satisfied: redis<3.5.0,>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.4.1)\n","Requirement already satisfied: tabulate; extra == \"tune\" in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.8.7)\n","Requirement already satisfied: tensorboardX; extra == \"tune\" in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.1)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.11.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: opencensus-context==0.1.2 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray[tune]) (0.1.2)\n","Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray[tune]) (1.16.0)\n","Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray[tune]) (7.352.0)\n","Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray[tune]) (1.7)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from gpustat->ray[tune]) (5.4.8)\n","Requirement already satisfied: hiredis in /usr/local/lib/python3.6/dist-packages (from aioredis->ray[tune]) (1.1.0)\n","Requirement already satisfied: async-timeout in /usr/local/lib/python3.6/dist-packages (from aioredis->ray[tune]) (3.0.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google->ray[tune]) (4.6.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray[tune]) (50.3.2)\n","Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (3.7.4.3)\n","Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (1.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (5.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (1.6.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (20.3.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.4.2)\n","Requirement already satisfied: contextvars; python_version >= \"3.6\" and python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from opencensus-context==0.1.2->opencensus->ray[tune]) (2.4)\n","Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.17.2)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.52.0)\n","Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars; python_version >= \"3.6\" and python_version < \"3.7\"->opencensus-context==0.1.2->opencensus->ray[tune]) (0.14)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.1.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.4.8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uPVY-s2WJ1GC","executionInfo":{"status":"ok","timestamp":1607478654352,"user_tz":360,"elapsed":402,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}}},"source":["import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import wordcloud\r\n","import preprocessor as p # tweet-preprocessor\r\n","import nltk\r\n","import re\r\n","import seaborn as sns\r\n","import torch\r\n","\r\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\r\n","from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\r\n","from sklearn.model_selection import train_test_split, StratifiedKFold\r\n","from scipy.special import softmax\r\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n","from tqdm.notebook import tqdm\r\n","from ray import tune\r\n","from ray.tune import CLIReporter\r\n","from ray.tune.schedulers import ASHAScheduler\r\n","from ray.tune.suggest.hyperopt import HyperOptSearch"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FOIjndjXJ410","executionInfo":{"status":"ok","timestamp":1607478660531,"user_tz":360,"elapsed":418,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"28e56082-32f4-4a2b-8460-cdae4ecd6c38"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HYpXyKdjKAKe"},"source":["# dataset_dem = pd.read_csv('/content/drive/MyDrive/democrat_tweets_v2.csv')\r\n","# dataset_gop = pd.read_csv('/content/drive/MyDrive/republican_tweets_v2.csv')\r\n","\r\n","# dataset_dem[\"label\"] = \"Democrat\"\r\n","# dataset_gop[\"label\"] = \"Republican\"\r\n","\r\n","# dataset_final = pd.concat([dataset_dem, dataset_gop])\r\n","# dataset_final.reset_index(drop=True, inplace=True)\r\n","dataset_final = pd.read_csv(\"/content/drive/MyDrive/Copy of 2020_labled_political_tweets.csv.zip\")\r\n","# dataset_final=dataset_final[(dataset_final[\"party\"].any()==\"D\")]\r\n","for index, row in dataset_final.iterrows():\r\n","    if str(row['party']) !=\"D\":\r\n","      if str(row[\"party\"])!=\"R\":\r\n","        dataset_final.drop(index, inplace=True)\r\n","dataset_final.head()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YKrKawj8l3OS","executionInfo":{"status":"ok","timestamp":1607474934243,"user_tz":360,"elapsed":443,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"06fa5ad0-d7a6-455f-ed2c-97867c836995"},"source":["dataset_final.count"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method DataFrame.count of         Unnamed: 0                   id  ...              source  party\n","0                1  1212432932746473472  ...  Twitter for iPhone      D\n","1                2  1212390455729696768  ...  Twitter for iPhone      D\n","2                3  1212250054788038656  ...  Twitter for iPhone      R\n","3                4  1212500813593169920  ...     Twitter Web App      R\n","4                6  1212239323392856064  ...  Twitter for iPhone      D\n","...            ...                  ...  ...                 ...    ...\n","595245        1027  1335304423225094144  ...     Twitter Web App      R\n","595246        1028  1335303090443087872  ...     Twitter Web App      R\n","595247        1029  1335302145990594560  ...     Twitter Web App      R\n","595248        1030  1335426205332500480  ...           TweetDeck      R\n","595249        1031  1335335839421919232  ...           TweetDeck      R\n","\n","[591635 rows x 9 columns]>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"wILCuGZ8tiHg"},"source":["# dataset=pd.read_csv(\"/content/drive/MyDrive/Copy of 2020_labled_political_tweets.csv.zip\")\r\n","# X=dataset.drop([\"party\"],axis=1)\r\n","# y = dataset[[\"party\"]]\r\n","# X_train, X_val, y_train, y_val = train_test_split(X, \r\n","#                                                   y, \r\n","#                                                   test_size=0.20, \r\n","#                                                   random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1z3V3jQia4-b"},"source":["LABEL_MAP = {\r\n","    \"D\": 0,\r\n","    \"R\": 1\r\n","}\r\n","\r\n","def buildLabels(row):\r\n","    return LABEL_MAP.get(row[\"party\"])\r\n","\r\n","# def cleanTweet(row):\r\n","#   tweet = row[\"text\"]\r\n","#   tweet = str(p.clean(tweet))\r\n","#   tweet = re.sub(r'[^\\w\\s]', '', tweet) # punctuation\r\n","#   tweet = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", tweet) # numbers\r\n","#   return tweet\r\n","\r\n","  \r\n","dataset_final[\"party\"] = dataset_final.apply(lambda row: buildLabels(row), axis=1)\r\n","# dataset_final[\"clean_text\"] = dataset_final.apply(lambda row: cleanTweet(row), \r\n","                                                  # axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":462},"id":"D3nyrMp9b1fw","executionInfo":{"status":"ok","timestamp":1607474960570,"user_tz":360,"elapsed":585,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"fe18af22-f43b-4509-c85d-4b43c70ef81c"},"source":["dataset_final.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>id</th>\n","      <th>screen_name</th>\n","      <th>user_id</th>\n","      <th>time</th>\n","      <th>link</th>\n","      <th>text</th>\n","      <th>source</th>\n","      <th>party</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1212432932746473472</td>\n","      <td>RepLoriTrahan</td>\n","      <td>1079802482640019456</td>\n","      <td>2020-01-01T12:58:31-05:00</td>\n","      <td>https://www.twitter.com/RepLoriTrahan/statuses...</td>\n","      <td>I am proud of the work we’ve done over the pas...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1212390455729696768</td>\n","      <td>RepDwightEvans</td>\n","      <td>90639372</td>\n","      <td>2020-01-01T10:09:44-05:00</td>\n","      <td>https://www.twitter.com/RepDwightEvans/statuse...</td>\n","      <td>2/ @MorethanmySLE – a cancer survivor and lupu...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1212250054788038656</td>\n","      <td>RepThomasMassie</td>\n","      <td>975200486</td>\n","      <td>2020-01-01T00:51:50-05:00</td>\n","      <td>https://www.twitter.com/RepThomasMassie/status...</td>\n","      <td>@ceQs17 Why are our people in Iraq, and how di...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1212500813593169920</td>\n","      <td>SenCoryGardner</td>\n","      <td>235217558</td>\n","      <td>2020-01-01T17:28:15-05:00</td>\n","      <td>https://www.twitter.com/SenCoryGardner/statuse...</td>\n","      <td>@EnergyGOP @BLMNational @SenatorBennet @Senate...</td>\n","      <td>Twitter Web App</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6</td>\n","      <td>1212239323392856064</td>\n","      <td>RepGraceMeng</td>\n","      <td>1051127714</td>\n","      <td>2020-01-01T00:09:11-05:00</td>\n","      <td>https://www.twitter.com/RepGraceMeng/statuses/...</td>\n","      <td>It’s 2020! As we enter a new decade, I wish ev...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                   id  ...              source  party\n","0           1  1212432932746473472  ...  Twitter for iPhone      0\n","1           2  1212390455729696768  ...  Twitter for iPhone      0\n","2           3  1212250054788038656  ...  Twitter for iPhone      1\n","3           4  1212500813593169920  ...     Twitter Web App      1\n","4           6  1212239323392856064  ...  Twitter for iPhone      0\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"cLcQ3mJVhc-t"},"source":["dataset_clf = dataset_final[[\"text\", \"party\"]]\r\n","dataset_clf.reset_index(drop=True, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4PmQdyTycjyF","executionInfo":{"status":"ok","timestamp":1607474992602,"user_tz":360,"elapsed":883,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"7f77b6a9-d0d4-411f-b82b-c8996a7dcb31"},"source":["X_train, X_val, y_train, y_val = train_test_split(dataset_clf.index.values, \r\n","                                                  dataset_clf.party.values, \r\n","                                                  test_size=0.20, \r\n","                                                  random_state=42, \r\n","                                                  stratify=dataset_clf.party.values)\r\n","\r\n","dataset_clf['data_type'] = ['not_set']*dataset_final.shape[0]\r\n","\r\n","dataset_clf.loc[X_train, 'data_type'] = 'train'\r\n","dataset_clf.loc[X_val, 'data_type'] = 'test'\r\n","\r\n","dataset_train = dataset_clf.loc[dataset_clf.data_type == 'train']\r\n","dataset_test = dataset_clf.loc[dataset_clf.data_type == 'test']\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  import sys\n","/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  isetter(loc, value)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"rPmkJjX5z0KD","executionInfo":{"status":"ok","timestamp":1607474996733,"user_tz":360,"elapsed":457,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"6fa87329-a96b-4c18-e1bb-59044c255b18"},"source":["dataset_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>party</th>\n","      <th>data_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I am proud of the work we’ve done over the pas...</td>\n","      <td>0</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2/ @MorethanmySLE – a cancer survivor and lupu...</td>\n","      <td>0</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>@ceQs17 Why are our people in Iraq, and how di...</td>\n","      <td>1</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@EnergyGOP @BLMNational @SenatorBennet @Senate...</td>\n","      <td>1</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>It’s 2020! As we enter a new decade, I wish ev...</td>\n","      <td>0</td>\n","      <td>train</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  party data_type\n","0  I am proud of the work we’ve done over the pas...      0     train\n","1  2/ @MorethanmySLE – a cancer survivor and lupu...      0     train\n","2  @ceQs17 Why are our people in Iraq, and how di...      1     train\n","3  @EnergyGOP @BLMNational @SenatorBennet @Senate...      1     train\n","4  It’s 2020! As we enter a new decade, I wish ev...      0     train"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"htScmGswouer"},"source":["def get_dataloaders(data, batch_size):\r\n","  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \r\n","                                            do_lower_case=True)\r\n","  # tokenize train and test data so BERT can understand it\r\n","  encoded_data_train = tokenizer.batch_encode_plus(\r\n","      data[data.data_type=='train'].text.values, \r\n","      add_special_tokens=True, \r\n","      return_attention_mask=True, \r\n","      padding=True,\r\n","      max_length=64, \r\n","      return_tensors='pt'\r\n","  )\r\n","\r\n","  encoded_data_test = tokenizer.batch_encode_plus(\r\n","      data[data.data_type=='test'].text.values, \r\n","      add_special_tokens=True, \r\n","      return_attention_mask=True, \r\n","      padding=True, \r\n","      max_length=64, \r\n","      return_tensors='pt'\r\n","  )\r\n","\r\n","\r\n","  # destructure out the input_ids, attention masks, and labels from tokenizer & encoder output\r\n","  input_ids_train = encoded_data_train['input_ids']\r\n","  attention_masks_train = encoded_data_train['attention_mask']\r\n","  labels_train = torch.tensor(data[data.data_type=='train'].party.values)\r\n","\r\n","  input_ids_test = encoded_data_test['input_ids']\r\n","  attention_masks_test = encoded_data_test['attention_mask']\r\n","  labels_test = torch.tensor(data[data.data_type=='test'].party.values)\r\n","\r\n","  train_data = TensorDataset(input_ids_train, attention_masks_train, labels_train)\r\n","  test_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\r\n","\r\n","  train_dataloader = DataLoader(train_data, \r\n","                                sampler=RandomSampler(train_data), \r\n","                                batch_size=batch_size)\r\n","\r\n","  test_dataloader = DataLoader(test_data,\r\n","                              sampler=SequentialSampler(test_data),\r\n","                              batch_size=batch_size)\r\n","  \r\n","  return train_dataloader, test_dataloader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7620ol2Fo_TL"},"source":["def auc_score(preds, labels):\r\n","  soft_preds = softmax(preds, axis=1) # logit -> probability\r\n","  if np.shape(preds)[1] > 2: # check for multi-class\r\n","    return roc_auc_score(labels, soft_preds, multi_class='ovr')\r\n","  else:\r\n","    soft_preds = soft_preds[:,1]\r\n","    return roc_auc_score(labels, soft_preds)\r\n","\r\n","def acc_score_by_class(preds, labels):\r\n","  label_dict_inverse = {v: k for k, v in LABEL_MAP.items()} \r\n","\r\n","  preds_flat = np.argmax(preds, axis=1).flatten()\r\n","  labels_flat = labels.flatten()\r\n","\r\n","  for label in np.unique(labels_flat):\r\n","    y_preds = preds_flat[labels_flat==label]\r\n","    y_true = labels_flat[labels_flat==label]\r\n","    print(f'Class: {label_dict_inverse[label]}')\r\n","    print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cVZOsYpbpB1W"},"source":["def evaluate(model, dataloader, device):\r\n","  model.eval()\r\n","\r\n","  loss_val_total = 0\r\n","  predictions, true_vals = [], []\r\n","  \r\n","  for batch in dataloader:\r\n","      \r\n","      # convert data to CUDA\r\n","      batch = tuple(b.to(device) for b in batch)\r\n","      \r\n","      inputs = {\r\n","          'input_ids':      batch[0],\r\n","          'attention_mask': batch[1],\r\n","          'labels':         batch[2],\r\n","      }\r\n","\r\n","      with torch.no_grad():        \r\n","          outputs = model(**inputs) # get predictions\r\n","          \r\n","      loss = outputs[0]\r\n","      logits = outputs[1]\r\n","      loss_val_total += loss.item()\r\n","\r\n","      logits = logits.detach().cpu().numpy()\r\n","      label_ids = inputs['labels'].cpu().numpy()\r\n","      predictions.append(logits)\r\n","      true_vals.append(label_ids)\r\n","  \r\n","  loss_val_avg = loss_val_total/len(dataloader) \r\n","  \r\n","  predictions = np.concatenate(predictions, axis=0)\r\n","  true_vals = np.concatenate(true_vals, axis=0)\r\n","          \r\n","  return loss_val_avg, predictions, true_vals"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r0dvG3yIpQhV"},"source":["def train_and_hyperparam_search(config,\r\n","                                model_init, # function to init a clean version of the net\r\n","                                data,       # data as Pandas array\r\n","                                cv          # rounds of cross-validation\r\n","                                ):\r\n","  losses = []\r\n","  aucs = []\r\n","  skf = StratifiedKFold(n_splits=cv, shuffle=True)\r\n","  for train_idx, test_idx in skf.split(data.text, data.party):\r\n","    model = model_init()\r\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","    model.to(device)\r\n","    print(f\"Device: {device}\")\r\n","\r\n","    optimizer = AdamW(model.parameters(),\r\n","                    lr=config['lr'],\r\n","                    eps=config['eps'],\r\n","                    weight_decay=config['weight_decay'])\r\n","    \r\n","    data.loc[train_idx, 'data_type'] = 'train'\r\n","    data.loc[test_idx, 'data_type'] = 'test'\r\n","    \r\n","    train_dataloader, test_dataloader = get_dataloaders(data,\r\n","                                                        config['batch_size'])\r\n","\r\n","    for epoch in range(1, config['epochs']+1):\r\n","      model.train() # enter training mode\r\n","      loss_train_total = 0\r\n","\r\n","      for batch in train_dataloader:\r\n","          model.zero_grad()\r\n","          \r\n","          # get CUDA data\r\n","          batch = tuple(b.to(device) for b in batch)\r\n","          \r\n","          inputs = {\r\n","              'input_ids':      batch[0],\r\n","              'attention_mask': batch[1],\r\n","              'labels':         batch[2],\r\n","          }\r\n","\r\n","          outputs = model(**inputs) # evaluate\r\n","          \r\n","          # for reference, we are using cross-entropy loss here,\r\n","          # as implemented in https://huggingface.co/transformers/_modules/transformers/modeling_bert.html\r\n","          loss = outputs[0]\r\n","          loss_train_total += loss.item()\r\n","          loss.backward() # do backprop\r\n","\r\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n","\r\n","          optimizer.step()\r\n","              \r\n","      \r\n","      loss_train_avg = loss_train_total/len(train_dataloader)    \r\n","      print(f\"Training loss for epoch {epoch}: {loss_train_avg}\")        \r\n","      \r\n","      val_loss, predictions, true_vals = evaluate(model, test_dataloader, device)\r\n","      auc = auc_score(predictions, true_vals)\r\n","\r\n","      losses.append(val_loss)\r\n","      aucs.append(auc)\r\n","\r\n","  tune.report(loss=np.mean(losses), auc=np.mean(aucs))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"b2Tl46SXpc8Y","executionInfo":{"status":"error","timestamp":1607478285054,"user_tz":360,"elapsed":39066,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"a2bbae07-d63b-4c0f-f666-a3bf0a29d4d3"},"source":["from functools import partial\r\n","\r\n","def model_init():\r\n","   return BertForSequenceClassification.from_pretrained('bert-base-uncased',\r\n","                                                        num_labels=2,\r\n","                                                        output_attentions=False,\r\n","                                                        output_hidden_states=False)   \r\n","\r\n","   \r\n","config = {\r\n","    \"lr\": tune.choice([5e-5,3e-5,2e-5]),\r\n","    \"eps\": tune.loguniform(1e-10, 1e-7),\r\n","    \"weight_decay\": tune.loguniform(1e-10, 1e-5),\r\n","    \"batch_size\": tune.choice([4,8,16, 32]),\r\n","    \"epochs\": tune.choice([2, 3, 4])\r\n","}\r\n","\r\n","scheduler = ASHAScheduler(\r\n","    metric=\"auc\",\r\n","    mode=\"max\",\r\n","    max_t=10,\r\n","    grace_period=1,\r\n","    reduction_factor=2\r\n",")\r\n","\r\n","reporter = CLIReporter(metric_columns=[\"loss\", \"auc\", \"training_iteration\"])\r\n","hyperopt_search = HyperOptSearch(metric=\"auc\", mode=\"max\")\r\n","\r\n","result = tune.run(\r\n","    partial(train_and_hyperparam_search, model_init=model_init, data=dataset_clf, cv=3),\r\n","    resources_per_trial={\"cpu\": 2, \"gpu\": 1},\r\n","    config=config,\r\n","    num_samples=8,\r\n","    scheduler=scheduler,\r\n","    search_alg=hyperopt_search,\r\n","    progress_reporter=reporter\r\n",")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["2020-12-09 01:10:50,306\tWARNING experiment.py:274 -- No name detected on trainable. Using DEFAULT.\n","2020-12-09 01:10:50,309\tINFO registry.py:65 -- Detected unknown callable for trainable. Converting to class.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=2953)\u001b[0m Device: cuda\n"],"name":"stdout"},{"output_type":"stream","text":["2020-12-09 01:11:02,279\tWARNING worker.py:1091 -- Warning: The actor ImplicitFunc has size 192469209 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n","2020-12-09 01:11:02,558\tWARNING util.py:140 -- The `start_trial` operation took 7.130183696746826 seconds to complete, which may be a performance bottleneck.\n"],"name":"stderr"},{"output_type":"stream","text":["== Status ==\n","Memory usage on this node: 6.9/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n","Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-09_01-10-51\n","Number of trials: 1/8 (1 RUNNING)\n","+------------------+----------+-------+--------------+----------+-------------+-------+----------------+\n","| Trial name       | status   | loc   |   batch_size |   epochs |         eps |    lr |   weight_decay |\n","|------------------+----------+-------+--------------+----------+-------------+-------+----------------|\n","| DEFAULT_61f9b6c0 | RUNNING  |       |            4 |        4 | 2.63632e-08 | 2e-05 |     1.6688e-10 |\n","+------------------+----------+-------+--------------+----------+-------------+-------+----------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["2020-12-09 01:11:03,592\tWARNING worker.py:1091 -- The actor or task with ID ffffffffffffffffae935fc001000000 is pending and cannot currently be scheduled. It requires {CPU: 2.000000}, {GPU: 1.000000} for execution and {CPU: 2.000000}, {GPU: 1.000000} for placement, but this node only has remaining {node:172.28.0.2: 1.000000}, {accelerator_type:T4: 1.000000}, {memory: 7.470703 GiB}, {object_store_memory: 2.587891 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n","2020-12-09 01:20:02,528\tWARNING worker.py:1091 -- A worker died or was killed while executing task ffffffffffffffff62223d8501000000.\n","\u001b[2m\u001b[36m(pid=3118)\u001b[0m 2020-12-09 01:20:14.578529: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=3118)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3118)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3118)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3118)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3118)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3118)\u001b[0m Device: cuda\n"],"name":"stdout"},{"output_type":"stream","text":["2020-12-09 01:29:18,557\tERROR trial_runner.py:793 -- Trial DEFAULT_61f9b6c0: Error processing event.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/ray/tune/trial_runner.py\", line 726, in _process_trial\n","    result = self.trial_executor.fetch_result(trial)\n","  File \"/usr/local/lib/python3.6/dist-packages/ray/tune/ray_trial_executor.py\", line 489, in fetch_result\n","    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n","  File \"/usr/local/lib/python3.6/dist-packages/ray/worker.py\", line 1454, in get\n","    raise value\n","ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n","2020-12-09 01:29:18,665\tWARNING worker.py:1091 -- A worker died or was killed while executing task ffffffffffffffffae935fc001000000.\n"],"name":"stderr"},{"output_type":"stream","text":["== Status ==\n","Memory usage on this node: 4.5/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n","Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-09_01-10-51\n","Number of trials: 2/8 (1 ERROR, 1 PENDING)\n","+------------------+----------+-------+--------------+----------+-------------+-------+----------------+\n","| Trial name       | status   | loc   |   batch_size |   epochs |         eps |    lr |   weight_decay |\n","|------------------+----------+-------+--------------+----------+-------------+-------+----------------|\n","| DEFAULT_67a8ea00 | PENDING  |       |            4 |        4 | 5.00462e-08 | 5e-05 |    4.10407e-08 |\n","| DEFAULT_61f9b6c0 | ERROR    |       |            4 |        4 | 2.63632e-08 | 2e-05 |    1.6688e-10  |\n","+------------------+----------+-------+--------------+----------+-------------+-------+----------------+\n","Number of errored trials: 1\n","+------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name       |   # failures | error file                                                                                                                                                           |\n","|------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n","| DEFAULT_61f9b6c0 |            1 | /root/ray_results/DEFAULT_2020-12-09_01-10-51/DEFAULT_61f9b6c0_1_batch_size=4,epochs=4,eps=2.6363e-08,lr=2e-05,weight_decay=1.6688e-10_2020-12-09_01-10-57/error.txt |\n","+------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"],"name":"stdout"},{"output_type":"stream","text":["2020-12-09 01:29:23,715\tWARNING util.py:140 -- The `start_trial` operation took 4.860376834869385 seconds to complete, which may be a performance bottleneck.\n","2020-12-09 01:29:26,317\tWARNING worker.py:1091 -- The actor or task with ID ffffffffffffffffb7603b6c01000000 is pending and cannot currently be scheduled. It requires {GPU: 1.000000}, {CPU: 2.000000} for execution and {GPU: 1.000000}, {CPU: 2.000000} for placement, but this node only has remaining {GPU: 1.000000}, {node:172.28.0.2: 1.000000}, {accelerator_type:T4: 1.000000}, {CPU: 2.000000}, {memory: 7.470703 GiB}, {object_store_memory: 2.587891 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n","\u001b[2m\u001b[36m(pid=3272)\u001b[0m 2020-12-09 01:29:35.809958: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=3272)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3272)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3272)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3272)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3272)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3272)\u001b[0m Device: cuda\n"],"name":"stdout"},{"output_type":"stream","text":["2020-12-09 01:38:32,347\tWARNING worker.py:1091 -- A worker died or was killed while executing task ffffffffffffffffb7603b6c01000000.\n","2020-12-09 01:38:32,353\tERROR trial_runner.py:793 -- Trial DEFAULT_67a8ea00: Error processing event.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/ray/tune/trial_runner.py\", line 726, in _process_trial\n","    result = self.trial_executor.fetch_result(trial)\n","  File \"/usr/local/lib/python3.6/dist-packages/ray/tune/ray_trial_executor.py\", line 489, in fetch_result\n","    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n","  File \"/usr/local/lib/python3.6/dist-packages/ray/worker.py\", line 1454, in get\n","    raise value\n","ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n"],"name":"stderr"},{"output_type":"stream","text":["== Status ==\n","Memory usage on this node: 4.5/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n","Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-09_01-10-51\n","Number of trials: 3/8 (2 ERROR, 1 PENDING)\n","+------------------+----------+-------+--------------+----------+-------------+-------+----------------+\n","| Trial name       | status   | loc   |   batch_size |   epochs |         eps |    lr |   weight_decay |\n","|------------------+----------+-------+--------------+----------+-------------+-------+----------------|\n","| DEFAULT_f80fab36 | PENDING  |       |           32 |        2 | 1.30343e-08 | 2e-05 |    1.05305e-10 |\n","| DEFAULT_61f9b6c0 | ERROR    |       |            4 |        4 | 2.63632e-08 | 2e-05 |    1.6688e-10  |\n","| DEFAULT_67a8ea00 | ERROR    |       |            4 |        4 | 5.00462e-08 | 5e-05 |    4.10407e-08 |\n","+------------------+----------+-------+--------------+----------+-------------+-------+----------------+\n","Number of errored trials: 2\n","+------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name       |   # failures | error file                                                                                                                                                           |\n","|------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n","| DEFAULT_61f9b6c0 |            1 | /root/ray_results/DEFAULT_2020-12-09_01-10-51/DEFAULT_61f9b6c0_1_batch_size=4,epochs=4,eps=2.6363e-08,lr=2e-05,weight_decay=1.6688e-10_2020-12-09_01-10-57/error.txt |\n","| DEFAULT_67a8ea00 |            1 | /root/ray_results/DEFAULT_2020-12-09_01-10-51/DEFAULT_67a8ea00_2_batch_size=4,epochs=4,eps=5.0046e-08,lr=5e-05,weight_decay=4.1041e-08_2020-12-09_01-29-20/error.txt |\n","+------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"],"name":"stdout"},{"output_type":"stream","text":["2020-12-09 01:38:37,418\tWARNING util.py:140 -- The `start_trial` operation took 4.779063701629639 seconds to complete, which may be a performance bottleneck.\n","2020-12-09 01:38:37,682\tWARNING worker.py:1091 -- The actor or task with ID ffffffffffffffffbe3cb80901000000 is pending and cannot currently be scheduled. It requires {CPU: 2.000000}, {GPU: 1.000000} for execution and {CPU: 2.000000}, {GPU: 1.000000} for placement, but this node only has remaining {GPU: 1.000000}, {node:172.28.0.2: 1.000000}, {accelerator_type:T4: 1.000000}, {CPU: 2.000000}, {memory: 7.470703 GiB}, {object_store_memory: 2.587891 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n","\u001b[2m\u001b[36m(pid=3424)\u001b[0m 2020-12-09 01:38:49.573025: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=3424)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3424)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3424)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3424)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3424)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3424)\u001b[0m Device: cuda\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-35fd25a62149>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0msearch_alg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperopt_search\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, loggers, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mtune_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m                     trial=next_trial)\n\u001b[1;32m    569\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;31m# TODO(ujvl): Consider combining get_next_available_trial and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;31m#  fetch_result functionality so that we don't timeout on fetch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_restoring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial_restore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout)\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m         )\n\u001b[1;32m   1584\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}