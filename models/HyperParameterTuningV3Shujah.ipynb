{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HyperParameterTuningV3Shujah.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"31359330e7334ae6887b0316824e69c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bf04a633fd3e48f8a5bdce238a80a618","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d9133a6242484bc9baaf79720bd1ccb6","IPY_MODEL_a032a8705eef4fee81c03228bcffa542"]}},"bf04a633fd3e48f8a5bdce238a80a618":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d9133a6242484bc9baaf79720bd1ccb6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_339c2feacb0745678a9fbf38a456626d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_425e4c7dd5fa4c799a8782622562e33e"}},"a032a8705eef4fee81c03228bcffa542":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9633c0a20aa44416836ff7390114dbf3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 3.36MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e5235be686f244169115f0686e5cbcbf"}},"339c2feacb0745678a9fbf38a456626d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"425e4c7dd5fa4c799a8782622562e33e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9633c0a20aa44416836ff7390114dbf3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e5235be686f244169115f0686e5cbcbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HIJEjje19PXm","executionInfo":{"status":"ok","timestamp":1607482035653,"user_tz":360,"elapsed":30064,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"5fc4fe00-0bb9-4a9e-f0b3-2574eeb6bbd7"},"source":["!pip install transformers datasets tweet-preprocessor ray[tune] hyperopt"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 6.7MB/s \n","\u001b[?25hCollecting datasets\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/38/0c24dce24767386123d528d27109024220db0e7a04467b658d587695241a/datasets-1.1.3-py3-none-any.whl (153kB)\n","\u001b[K     |████████████████████████████████| 163kB 51.9MB/s \n","\u001b[?25hCollecting tweet-preprocessor\n","  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n","Collecting ray[tune]\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/87/44476ad712acc1f7957cbf88d307d4a0283a740487cf85d710d0211d0135/ray-1.0.1.post1-cp36-cp36m-manylinux1_x86_64.whl (23.1MB)\n","\u001b[K     |████████████████████████████████| 23.1MB 1.7MB/s \n","\u001b[?25hRequirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 54.4MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 50.3MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting xxhash\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n","\u001b[K     |████████████████████████████████| 245kB 50.6MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.4)\n","Collecting pyarrow>=0.17.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n","\u001b[K     |████████████████████████████████| 17.7MB 202kB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.11.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.13)\n","Collecting aiohttp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/e6/d4b6235d776c9b33f853e603efede5aac5a34f71ca9d3877adb30492eb4e/aiohttp-3.7.3-cp36-cp36m-manylinux2014_x86_64.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 52.5MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.12.4)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.6.0)\n","Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.9.0)\n","Collecting aiohttp-cors\n","  Downloading https://files.pythonhosted.org/packages/13/e7/e436a0c0eb5127d8b491a9b83ecd2391c6ff7dcd5548dfaec2080a2340fd/aiohttp_cors-0.7.0-py3-none-any.whl\n","Requirement already satisfied: google in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.0.3)\n","Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.33.2)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.0.0)\n","Collecting py-spy>=0.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/a7/ab45c9ee3c4654edda3efbd6b8e2fa4962226718a7e3e3be6e3926bf3617/py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 51.3MB/s \n","\u001b[?25hCollecting colorful\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/8e/e386e248266952d24d73ed734c2f5513f34d9557032618c8910e605dfaf6/colorful-0.5.4-py2.py3-none-any.whl (201kB)\n","\u001b[K     |████████████████████████████████| 204kB 52.0MB/s \n","\u001b[?25hCollecting redis<3.5.0,>=3.3.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/05/1fc7feedc19c123e7a95cfc9e7892eb6cdd2e5df4e9e8af6384349c1cc3d/redis-3.4.1-py2.py3-none-any.whl (71kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.9MB/s \n","\u001b[?25hCollecting aioredis\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/64/1b1612d0a104f21f80eb4c6e1b6075f2e6aba8e228f46f229cfd3fdac859/aioredis-1.3.1-py3-none-any.whl (65kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.6MB/s \n","\u001b[?25hCollecting gpustat\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/69/d8c849715171aeabd61af7da080fdc60948b5a396d2422f1f4672e43d008/gpustat-0.6.0.tar.gz (78kB)\n","\u001b[K     |████████████████████████████████| 81kB 11.6MB/s \n","\u001b[?25hCollecting opencensus\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/68/4f407bc0980158001c802222fab17e946728aef13f42e5d80d39dfc9ca67/opencensus-0.7.11-py2.py3-none-any.whl (127kB)\n","\u001b[K     |████████████████████████████████| 133kB 54.3MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (7.1.2)\n","Requirement already satisfied: tabulate; extra == \"tune\" in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.8.7)\n","Collecting tensorboardX; extra == \"tune\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n","\u001b[K     |████████████████████████████████| 317kB 46.1MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.15.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.5)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.11.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n","Collecting multidict<7.0,>=4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/35/b22524d6b9cacfb4c5eff413a069bbc17c6ea628e54da5c6c989998ced5f/multidict-5.1.0-cp36-cp36m-manylinux2014_x86_64.whl (141kB)\n","\u001b[K     |████████████████████████████████| 143kB 53.5MB/s \n","\u001b[?25hCollecting async-timeout<4.0,>=3.0\n","  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n","Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (3.7.4.3)\n","Collecting idna-ssl>=1.0; python_version < \"3.7\"\n","  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n","Collecting yarl<2.0,>=1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/08/52b26b44bce7b818b410aee37c5e424c9ea420c557bca97dc2adac29b151/yarl-1.6.3-cp36-cp36m-manylinux2014_x86_64.whl (293kB)\n","\u001b[K     |████████████████████████████████| 296kB 49.8MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (20.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray[tune]) (50.3.2)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google->ray[tune]) (4.6.3)\n","Collecting hiredis\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/7d/6acf1c8d4f2fb327ff6feec000b4c56a20628fbe966a4c7cd16c0b80343c/hiredis-1.1.0-cp36-cp36m-manylinux2010_x86_64.whl (61kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.3MB/s \n","\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray[tune]) (7.352.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from gpustat->ray[tune]) (5.4.8)\n","Collecting blessings>=1.6\n","  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n","Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray[tune]) (1.16.0)\n","Collecting opencensus-context==0.1.2\n","  Downloading https://files.pythonhosted.org/packages/f1/33/990f1bd9e7ee770fc8d3c154fc24743a96f16a0e49e14e1b7540cc2fdd93/opencensus_context-0.1.2-py2.py3-none-any.whl\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.4.2)\n","Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.17.2)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.52.0)\n","Collecting contextvars; python_version >= \"3.6\" and python_version < \"3.7\"\n","  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.1.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.2.8)\n","Collecting immutables>=0.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n","\u001b[K     |████████████████████████████████| 102kB 12.9MB/s \n","\u001b[?25hRequirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.4.8)\n","Building wheels for collected packages: sacremoses, gpustat, idna-ssl, contextvars\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=a7ef4b95da183d3948327ff38bd3701fe1c4b5f0b365fbf674da3e06f84b1e98\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gpustat: filename=gpustat-0.6.0-cp36-none-any.whl size=12622 sha256=0a275b56c62a2bc4100bb20a6eaf9189e987c3e1fb9cd0cc208e37b8c7f6cd4b\n","  Stored in directory: /root/.cache/pip/wheels/48/b4/d5/fb5b7f1d040f2ff20687e3bad6867d63155dbde5a7c10f4293\n","  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-cp36-none-any.whl size=3161 sha256=e6a86129433f52ebfe2f86d213b91920cb23e7d52136c0f09ee3b41239376b11\n","  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n","  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=5f0c2f7d2be3581a922c4b47d7ba593806a3046c026fa5b3eaba242a9dfafbae\n","  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n","Successfully built sacremoses gpustat idna-ssl contextvars\n","Installing collected packages: sacremoses, tokenizers, transformers, xxhash, pyarrow, datasets, tweet-preprocessor, multidict, async-timeout, idna-ssl, yarl, aiohttp, aiohttp-cors, py-spy, colorful, redis, hiredis, aioredis, blessings, gpustat, immutables, contextvars, opencensus-context, opencensus, colorama, tensorboardX, ray\n","  Found existing installation: pyarrow 0.14.1\n","    Uninstalling pyarrow-0.14.1:\n","      Successfully uninstalled pyarrow-0.14.1\n","Successfully installed aiohttp-3.7.3 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-3.0.1 blessings-1.7 colorama-0.4.4 colorful-0.5.4 contextvars-2.4 datasets-1.1.3 gpustat-0.6.0 hiredis-1.1.0 idna-ssl-1.1.0 immutables-0.14 multidict-5.1.0 opencensus-0.7.11 opencensus-context-0.1.2 py-spy-0.3.3 pyarrow-2.0.0 ray-1.0.1.post1 redis-3.4.1 sacremoses-0.0.43 tensorboardX-2.1 tokenizers-0.9.4 transformers-4.0.0 tweet-preprocessor-0.6.0 xxhash-2.0.0 yarl-1.6.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_guPtNMu1SKb","executionInfo":{"status":"ok","timestamp":1607482077629,"user_tz":360,"elapsed":7723,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import wordcloud\n","import preprocessor as p # tweet-preprocessor\n","import nltk\n","import re\n","import seaborn as sns\n","import torch\n","\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n","from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from scipy.special import softmax\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from tqdm.notebook import tqdm\n","from ray import tune\n","from ray.tune import CLIReporter\n","from ray.tune.schedulers import ASHAScheduler\n","from ray.tune.suggest.hyperopt import HyperOptSearch"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yv4MEilxvqOx","executionInfo":{"status":"ok","timestamp":1607482113844,"user_tz":360,"elapsed":27452,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"813d1efd-de69-4ee0-c864-674857f3a008"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3NoYbhabPHjf","executionInfo":{"status":"ok","timestamp":1607486423496,"user_tz":360,"elapsed":431078,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}}},"source":["# dataset_dem = pd.read_csv('/content/drive/MyDrive/democrat_tweets_v2.csv')\n","# dataset_gop = pd.read_csv('/content/drive/MyDrive/republican_tweets_v2.csv')\n","\n","# dataset_dem[\"label\"] = \"Democrat\"\n","# dataset_gop[\"label\"] = \"Republican\"\n","\n","# dataset_final = pd.concat([dataset_dem, dataset_gop])\n","\n","dataset = pd.read_csv(\"/content/drive/MyDrive/Copy of 2020_labled_political_tweets.csv.zip\")\n","for index, row in dataset.iterrows():\n","    if str(row['party']) !=\"D\":\n","      if str(row[\"party\"])!=\"R\":\n","        dataset.drop(index, inplace=True)\n","\n","# dataset_final=dataset.reset_index(drop=True, inplace=True)\n","# dataset_final.head()"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"Y1MttrRieATR","executionInfo":{"status":"error","timestamp":1607489860479,"user_tz":360,"elapsed":445,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"c06c4f6c-7223-4560-9541-b509024dfd00"},"source":["dataset.head()\n","newDataset = dataset.copy()\n","newDataset.head()\n","newDataset = newDataset.head([5000])\n","# dataset_final=dataset\n","# dataset_final.head()\n","# dataset_final.rename(columns={\"party\": \"label\"},inplace=True)\n","# dataset_final.head()"],"execution_count":71,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-71-532c06ed3380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnewDataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnewDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnewDataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# dataset_final=dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# dataset_final.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   4710\u001b[0m         \u001b[0;36m5\u001b[0m     \u001b[0mparrot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4711\u001b[0m         \"\"\"\n\u001b[0;32m-> 4712\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFrameOrSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mFrameOrSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_positional_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1509\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_validate_positional_slice\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3119\u001b[0m         \"\"\"\n\u001b[1;32m   3120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_validate_indexer\u001b[0;34m(self, form, key, kind)\u001b[0m\n\u001b[1;32m   4995\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4996\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4997\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalid_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_cast_slice_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_invalid_indexer\u001b[0;34m(self, form, key)\u001b[0m\n\u001b[1;32m   3266\u001b[0m         \"\"\"\n\u001b[1;32m   3267\u001b[0m         raise TypeError(\n\u001b[0;32m-> 3268\u001b[0;31m             \u001b[0;34mf\"cannot do {form} indexing on {type(self).__name__} with these \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3269\u001b[0m             \u001b[0;34mf\"indexers [{key}] of type {type(key).__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3270\u001b[0m         )\n","\u001b[0;31mTypeError\u001b[0m: cannot do positional indexing on Int64Index with these indexers [[5000]] of type list"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"dnrybFt2q9tV","executionInfo":{"status":"ok","timestamp":1607486767901,"user_tz":360,"elapsed":287,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"0146426f-40b2-49d8-c4c1-541f99953131"},"source":["newDataset.rename(columns={\"party\": \"label\"},inplace=True)\n","newDataset.reset_index(drop=True, inplace=True)\n","newDataset.head()"],"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>id</th>\n","      <th>screen_name</th>\n","      <th>user_id</th>\n","      <th>time</th>\n","      <th>link</th>\n","      <th>text</th>\n","      <th>source</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1212432932746473472</td>\n","      <td>RepLoriTrahan</td>\n","      <td>1079802482640019456</td>\n","      <td>2020-01-01T12:58:31-05:00</td>\n","      <td>https://www.twitter.com/RepLoriTrahan/statuses...</td>\n","      <td>I am proud of the work we’ve done over the pas...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1212390455729696768</td>\n","      <td>RepDwightEvans</td>\n","      <td>90639372</td>\n","      <td>2020-01-01T10:09:44-05:00</td>\n","      <td>https://www.twitter.com/RepDwightEvans/statuse...</td>\n","      <td>2/ @MorethanmySLE – a cancer survivor and lupu...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1212250054788038656</td>\n","      <td>RepThomasMassie</td>\n","      <td>975200486</td>\n","      <td>2020-01-01T00:51:50-05:00</td>\n","      <td>https://www.twitter.com/RepThomasMassie/status...</td>\n","      <td>@ceQs17 Why are our people in Iraq, and how di...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1212500813593169920</td>\n","      <td>SenCoryGardner</td>\n","      <td>235217558</td>\n","      <td>2020-01-01T17:28:15-05:00</td>\n","      <td>https://www.twitter.com/SenCoryGardner/statuse...</td>\n","      <td>@EnergyGOP @BLMNational @SenatorBennet @Senate...</td>\n","      <td>Twitter Web App</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6</td>\n","      <td>1212239323392856064</td>\n","      <td>RepGraceMeng</td>\n","      <td>1051127714</td>\n","      <td>2020-01-01T00:09:11-05:00</td>\n","      <td>https://www.twitter.com/RepGraceMeng/statuses/...</td>\n","      <td>It’s 2020! As we enter a new decade, I wish ev...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>D</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                   id  ...              source  label\n","0           1  1212432932746473472  ...  Twitter for iPhone      D\n","1           2  1212390455729696768  ...  Twitter for iPhone      D\n","2           3  1212250054788038656  ...  Twitter for iPhone      R\n","3           4  1212500813593169920  ...     Twitter Web App      R\n","4           6  1212239323392856064  ...  Twitter for iPhone      D\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"t-2XQbD631J9","executionInfo":{"status":"ok","timestamp":1607487005259,"user_tz":360,"elapsed":161379,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}}},"source":["# dataset_final = dataset_final.rename(columns={\"party\": \"label\"})\n","LABEL_MAP = {\n","    \"D\": 0,\n","    \"R\": 1\n","}\n","\n","def buildLabels(row):\n","    return LABEL_MAP.get(row[\"label\"])\n","\n","def cleanTweet(row):\n","  tweet = row[\"text\"]\n","  tweet = str(p.clean(tweet))\n","  tweet = re.sub(r'[^\\w\\s]', '', tweet) # punctuation\n","  tweet = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", tweet) # numbers\n","  return tweet\n","\n","  \n","newDataset[\"label\"] = newDataset.apply(lambda row: buildLabels(row), axis=1)\n","newDataset[\"clean_text\"] = newDataset.apply(lambda row: cleanTweet(row), \n","                                                  axis=1)"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496},"id":"_b_9AG3dsfll","executionInfo":{"status":"ok","timestamp":1607487066438,"user_tz":360,"elapsed":329,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"40553ad3-7056-47e4-cd34-2bd4a508f752"},"source":["newDataset.head()"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>id</th>\n","      <th>screen_name</th>\n","      <th>user_id</th>\n","      <th>time</th>\n","      <th>link</th>\n","      <th>text</th>\n","      <th>source</th>\n","      <th>label</th>\n","      <th>clean_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1212432932746473472</td>\n","      <td>RepLoriTrahan</td>\n","      <td>1079802482640019456</td>\n","      <td>2020-01-01T12:58:31-05:00</td>\n","      <td>https://www.twitter.com/RepLoriTrahan/statuses...</td>\n","      <td>I am proud of the work we’ve done over the pas...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>0</td>\n","      <td>I am proud of the work weve done over the past...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1212390455729696768</td>\n","      <td>RepDwightEvans</td>\n","      <td>90639372</td>\n","      <td>2020-01-01T10:09:44-05:00</td>\n","      <td>https://www.twitter.com/RepDwightEvans/statuse...</td>\n","      <td>2/ @MorethanmySLE – a cancer survivor and lupu...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>0</td>\n","      <td>a cancer survivor and lupus warrior  spoke wi...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1212250054788038656</td>\n","      <td>RepThomasMassie</td>\n","      <td>975200486</td>\n","      <td>2020-01-01T00:51:50-05:00</td>\n","      <td>https://www.twitter.com/RepThomasMassie/status...</td>\n","      <td>@ceQs17 Why are our people in Iraq, and how di...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>1</td>\n","      <td>Why are our people in Iraq and how did Iran co...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1212500813593169920</td>\n","      <td>SenCoryGardner</td>\n","      <td>235217558</td>\n","      <td>2020-01-01T17:28:15-05:00</td>\n","      <td>https://www.twitter.com/SenCoryGardner/statuse...</td>\n","      <td>@EnergyGOP @BLMNational @SenatorBennet @Senate...</td>\n","      <td>Twitter Web App</td>\n","      <td>1</td>\n","      <td>This year the first ever statelevel measuremen...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6</td>\n","      <td>1212239323392856064</td>\n","      <td>RepGraceMeng</td>\n","      <td>1051127714</td>\n","      <td>2020-01-01T00:09:11-05:00</td>\n","      <td>https://www.twitter.com/RepGraceMeng/statuses/...</td>\n","      <td>It’s 2020! As we enter a new decade, I wish ev...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>0</td>\n","      <td>Its  As we enter a new decade I wish everybody...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  ...                                         clean_text\n","0           1  ...  I am proud of the work weve done over the past...\n","1           2  ...   a cancer survivor and lupus warrior  spoke wi...\n","2           3  ...  Why are our people in Iraq and how did Iran co...\n","3           4  ...  This year the first ever statelevel measuremen...\n","4           6  ...  Its  As we enter a new decade I wish everybody...\n","\n","[5 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"C6JbCNxH6c9H","executionInfo":{"status":"ok","timestamp":1607487091083,"user_tz":360,"elapsed":556,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}}},"source":["dataset_clf = newDataset[[\"clean_text\", \"label\"]]\n","dataset_clf.reset_index(drop=True, inplace=True)"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"xEB6rjLZjQ-Q","executionInfo":{"status":"ok","timestamp":1607487099647,"user_tz":360,"elapsed":271,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"a3688e87-9f6c-46a9-ec33-17f333955b1f"},"source":["dataset_clf.head()\n","# dataset_final.head()\n","# dataset.head()"],"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>clean_text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I am proud of the work weve done over the past...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>a cancer survivor and lupus warrior  spoke wi...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Why are our people in Iraq and how did Iran co...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>This year the first ever statelevel measuremen...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Its  As we enter a new decade I wish everybody...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          clean_text  label\n","0  I am proud of the work weve done over the past...      0\n","1   a cancer survivor and lupus warrior  spoke wi...      0\n","2  Why are our people in Iraq and how did Iran co...      1\n","3  This year the first ever statelevel measuremen...      1\n","4  Its  As we enter a new decade I wish everybody...      0"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"BltNRZ4kVLEX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487109236,"user_tz":360,"elapsed":792,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"30edb410-abfa-45ed-af74-76b0bcfa378e"},"source":["X_train, X_val, y_train, y_val = train_test_split(dataset_clf.index.values, \n","                                                  dataset_clf.label.values, \n","                                                  test_size=0.15, \n","                                                  random_state=42, \n","                                                  stratify=dataset_clf.label.values)\n","\n","dataset_clf['data_type'] = ['not_set']*dataset_final.shape[0]\n","\n","dataset_clf.loc[X_train, 'data_type'] = 'train'\n","dataset_clf.loc[X_val, 'data_type'] = 'test'\n","\n","dataset_train = dataset_clf.loc[dataset_clf.data_type == 'train']\n","dataset_test = dataset_clf.loc[dataset_clf.data_type == 'test']"],"execution_count":59,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  import sys\n","/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  isetter(loc, value)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PepEuSPxMxXB","executionInfo":{"status":"ok","timestamp":1607487152382,"user_tz":360,"elapsed":273,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}}},"source":["def get_dataloaders(data, batch_size):\n","  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n","                                            do_lower_case=True)\n","  # tokenize train and test data so BERT can understand it\n","  encoded_data_train = tokenizer.batch_encode_plus(\n","      data[data.data_type=='train'].clean_text.values, \n","      add_special_tokens=True, \n","      return_attention_mask=True, \n","      padding=True,\n","      max_length=64, \n","      return_tensors='pt'\n","  )\n","\n","  encoded_data_test = tokenizer.batch_encode_plus(\n","      data[data.data_type=='test'].clean_text.values, \n","      add_special_tokens=True, \n","      return_attention_mask=True, \n","      padding=True, \n","      max_length=64, \n","      return_tensors='pt'\n","  )\n","\n","\n","  # destructure out the input_ids, attention masks, and labels from tokenizer & encoder output\n","  input_ids_train = encoded_data_train['input_ids']\n","  attention_masks_train = encoded_data_train['attention_mask']\n","  labels_train = torch.tensor(data[data.data_type=='train'].label.values)\n","\n","  input_ids_test = encoded_data_test['input_ids']\n","  attention_masks_test = encoded_data_test['attention_mask']\n","  labels_test = torch.tensor(data[data.data_type=='test'].label.values)\n","\n","  train_data = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","  test_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n","\n","  train_dataloader = DataLoader(train_data, \n","                                sampler=RandomSampler(train_data), \n","                                batch_size=batch_size)\n","\n","  test_dataloader = DataLoader(test_data,\n","                              sampler=SequentialSampler(test_data),\n","                              batch_size=batch_size)\n","  \n","  return train_dataloader, test_dataloader"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"id":"RdmRjhMKPPzg","executionInfo":{"status":"ok","timestamp":1607487121209,"user_tz":360,"elapsed":316,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}}},"source":["def auc_score(preds, labels):\n","  soft_preds = softmax(preds, axis=1) # logit -> probability\n","  if np.shape(preds)[1] > 2: # check for multi-class\n","    return roc_auc_score(labels, soft_preds, multi_class='ovr')\n","  else:\n","    soft_preds = soft_preds[:,1]\n","    return roc_auc_score(labels, soft_preds)\n","\n","def acc_score_by_class(preds, labels):\n","  label_dict_inverse = {v: k for k, v in LABEL_MAP.items()} \n","\n","  preds_flat = np.argmax(preds, axis=1).flatten()\n","  labels_flat = labels.flatten()\n","\n","  for label in np.unique(labels_flat):\n","    y_preds = preds_flat[labels_flat==label]\n","    y_true = labels_flat[labels_flat==label]\n","    print(f'Class: {label_dict_inverse[label]}')\n","    print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQfxvBS6PSuc","executionInfo":{"status":"ok","timestamp":1607487124879,"user_tz":360,"elapsed":290,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}}},"source":["def evaluate(model, dataloader, device):\n","  model.eval()\n","\n","  loss_val_total = 0\n","  predictions, true_vals = [], []\n","  \n","  for batch in dataloader:\n","      \n","      # convert data to CUDA\n","      batch = tuple(b.to(device) for b in batch)\n","      \n","      inputs = {\n","          'input_ids':      batch[0],\n","          'attention_mask': batch[1],\n","          'labels':         batch[2],\n","      }\n","\n","      with torch.no_grad():        \n","          outputs = model(**inputs) # get predictions\n","          \n","      loss = outputs[0]\n","      logits = outputs[1]\n","      loss_val_total += loss.item()\n","\n","      logits = logits.detach().cpu().numpy()\n","      label_ids = inputs['labels'].cpu().numpy()\n","      predictions.append(logits)\n","      true_vals.append(label_ids)\n","  \n","  loss_val_avg = loss_val_total/len(dataloader) \n","  \n","  predictions = np.concatenate(predictions, axis=0)\n","  true_vals = np.concatenate(true_vals, axis=0)\n","          \n","  return loss_val_avg, predictions, true_vals"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"id":"GOZt7rnsXamy","executionInfo":{"status":"ok","timestamp":1607488622666,"user_tz":360,"elapsed":445,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}}},"source":["def train_and_hyperparam_search(config,\n","                                model_init, # function to init a clean version of the net\n","                                data,       # data as Pandas array\n","                                cv          # rounds of cross-validation\n","                                ):\n","  losses = []\n","  aucs = []\n","  skf = StratifiedKFold(n_splits=cv, shuffle=True)\n","  for train_idx, test_idx in skf.split(data.clean_text, data.label):\n","    model = model_init()\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    print(f\"Device: {device}\")\n","\n","    optimizer = AdamW(model.parameters(),\n","                    lr=config['lr'],\n","                    eps=1e-8) # keep this the same, just prevents exploding gradients\n","    \n","    data.loc[train_idx, 'data_type'] = 'train'\n","    data.loc[test_idx, 'data_type'] = 'test'\n","    \n","    train_dataloader, test_dataloader = get_dataloaders(data,\n","                                                        config['batch_size'])\n","\n","    for epoch in range(1, config['epochs']+1):\n","      model.train() # enter training mode\n","      loss_train_total = 0\n","\n","      for batch in train_dataloader:\n","          model.zero_grad()\n","          \n","          # get CUDA data\n","          batch = tuple(b.to(device) for b in batch)\n","          \n","          inputs = {\n","              'input_ids':      batch[0],\n","              'attention_mask': batch[1],\n","              'labels':         batch[2],\n","          }\n","\n","          outputs = model(**inputs) # evaluate\n","          \n","          # for reference, we are using cross-entropy loss here,\n","          # as implemented in https://huggingface.co/transformers/_modules/transformers/modeling_bert.html\n","          loss = outputs[0]\n","          loss_train_total += loss.item()\n","          loss.backward() # do backprop\n","\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","          optimizer.step()\n","              \n","      \n","      loss_train_avg = loss_train_total/len(train_dataloader)    \n","      print(f\"Training loss for epoch {epoch}: {loss_train_avg}\")        \n","      \n","      val_loss, predictions, true_vals = evaluate(model, test_dataloader, device)\n","      auc = auc_score(predictions, true_vals)\n","\n","      losses.append(val_loss)\n","      aucs.append(auc)\n","\n","  tune.report(loss=np.mean(losses), auc=np.mean(aucs))"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"NZDqsHpBPJ0T","executionInfo":{"status":"error","timestamp":1607489131081,"user_tz":360,"elapsed":376438,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"e5d66697-748f-4c2a-c3ca-8b5193e6990c"},"source":["\n","from functools import partial\n","\n","def model_init():\n","   return BertForSequenceClassification.from_pretrained('bert-base-uncased',\n","                                                        num_labels=2,\n","                                                        output_attentions=False,\n","                                                        output_hidden_states=False)   \n","\n","   \n","config = {\n","    \"lr\": tune.choice([5e-5, 3e-5, 1e-5, 2e-5]),\n","    \"batch_size\": tune.choice([8, 16, 32]),\n","    \"epochs\": tune.choice([2, 3, 4])\n","}\n","\n","scheduler = ASHAScheduler(\n","    metric=\"loss\",\n","    mode=\"min\",\n","    max_t=10,\n","    grace_period=1,\n","    reduction_factor=2\n",")\n","\n","reporter = CLIReporter(metric_columns=[\"loss\", \"auc\", \"training_iteration\"])\n","hyperopt_search = HyperOptSearch(metric=\"loss\", mode=\"min\")\n","\n","result = tune.run(\n","    partial(train_and_hyperparam_search, model_init=model_init, data=dataset_clf, cv=3),\n","    resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n","    config=config,\n","    num_samples=8,\n","    scheduler=scheduler,\n","    search_alg=hyperopt_search,\n","    progress_reporter=reporter\n",")"],"execution_count":70,"outputs":[{"output_type":"stream","text":["2020-12-09 04:39:14,761\tWARNING experiment.py:274 -- No name detected on trainable. Using DEFAULT.\n","2020-12-09 04:39:14,762\tINFO registry.py:65 -- Detected unknown callable for trainable. Converting to class.\n","2020-12-09 04:39:21,023\tWARNING worker.py:1091 -- Warning: The actor ImplicitFunc has size 129849879 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n","2020-12-09 04:39:21,196\tWARNING util.py:140 -- The `start_trial` operation took 3.4725444316864014 seconds to complete, which may be a performance bottleneck.\n"],"name":"stderr"},{"output_type":"stream","text":["== Status ==\n","Memory usage on this node: 6.4/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n","Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.18 GiB heap, 0.0/2.44 GiB objects (0/1.0 accelerator_type:P4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-09_04-39-15\n","Number of trials: 1/8 (1 RUNNING)\n","+------------------+----------+-------+--------------+----------+-------+\n","| Trial name       | status   | loc   |   batch_size |   epochs |    lr |\n","|------------------+----------+-------+--------------+----------+-------|\n","| DEFAULT_7e9cf5fe | RUNNING  |       |           32 |        3 | 5e-05 |\n","+------------------+----------+-------+--------------+----------+-------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=2130)\u001b[0m 2020-12-09 04:39:24.226679: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=2130)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=2130)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=2130)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=2130)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=2130)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=2130)\u001b[0m Device: cuda\n"],"name":"stdout"},{"output_type":"stream","text":["2020-12-09 04:45:09,598\tERROR trial_runner.py:793 -- Trial DEFAULT_7e9cf5fe: Error processing event.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/ray/tune/trial_runner.py\", line 726, in _process_trial\n","    result = self.trial_executor.fetch_result(trial)\n","  File \"/usr/local/lib/python3.6/dist-packages/ray/tune/ray_trial_executor.py\", line 489, in fetch_result\n","    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n","  File \"/usr/local/lib/python3.6/dist-packages/ray/worker.py\", line 1454, in get\n","    raise value\n","ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n","2020-12-09 04:45:09,634\tWARNING worker.py:1091 -- A worker died or was killed while executing task ffffffffffffffff0d247c2701000000.\n"],"name":"stderr"},{"output_type":"stream","text":["== Status ==\n","Memory usage on this node: 6.4/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n","Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.18 GiB heap, 0.0/2.44 GiB objects (0/1.0 accelerator_type:P4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-09_04-39-15\n","Number of trials: 2/8 (1 ERROR, 1 PENDING)\n","+------------------+----------+-------+--------------+----------+-------+\n","| Trial name       | status   | loc   |   batch_size |   epochs |    lr |\n","|------------------+----------+-------+--------------+----------+-------|\n","| DEFAULT_816d7920 | PENDING  |       |            8 |        2 | 2e-05 |\n","| DEFAULT_7e9cf5fe | ERROR    |       |           32 |        3 | 5e-05 |\n","+------------------+----------+-------+--------------+----------+-------+\n","Number of errored trials: 1\n","+------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name       |   # failures | error file                                                                                                                     |\n","|------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------|\n","| DEFAULT_7e9cf5fe |            1 | /root/ray_results/DEFAULT_2020-12-09_04-39-15/DEFAULT_7e9cf5fe_1_batch_size=32,epochs=3,lr=5e-05_2020-12-09_04-39-18/error.txt |\n","+------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------+\n","\n"],"name":"stdout"},{"output_type":"stream","text":["2020-12-09 04:45:12,885\tWARNING util.py:140 -- The `start_trial` operation took 3.092501401901245 seconds to complete, which may be a performance bottleneck.\n","2020-12-09 04:45:13,692\tWARNING worker.py:1091 -- The actor or task with ID ffffffffffffffff32bfbb1701000000 is pending and cannot currently be scheduled. It requires {CPU: 2.000000}, {GPU: 1.000000} for execution and {CPU: 2.000000}, {GPU: 1.000000} for placement, but this node only has remaining {GPU: 1.000000}, {node:172.28.0.2: 1.000000}, {accelerator_type:P4: 1.000000}, {CPU: 2.000000}, {memory: 7.177734 GiB}, {object_store_memory: 2.441406 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n","\u001b[2m\u001b[36m(pid=2234)\u001b[0m 2020-12-09 04:45:24.398157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-26f95e9680e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0msearch_alg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperopt_search\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, loggers, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mtune_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m                     trial=next_trial)\n\u001b[1;32m    569\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;31m# TODO(ujvl): Consider combining get_next_available_trial and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;31m#  fetch_result functionality so that we don't timeout on fetch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_restoring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial_restore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout)\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m         )\n\u001b[1;32m   1584\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"id":"uyn5bvPkOBKD","executionInfo":{"status":"ok","timestamp":1607385139643,"user_tz":360,"elapsed":7445754,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"ee262451-e0a2-4e3a-fcb5-e7cd73f119e9"},"source":["dfs = result.fetch_trial_dataframes()\n","\n","aucs = []\n","losses = []\n","for d in dfs.values():\n","  aucs.append(d.auc)\n","  losses.append(d.loss)\n","\n","plt.plot(range(0, 8), aucs, label=\"AUC\")\n","plt.plot(range(0, 8), losses, label=\"Loss\")\n","plt.legend()\n","plt.xlabel(\"Trial No.\")\n","plt.ylabel(\"Score\")\n"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, 'Score')"]},"metadata":{"tags":[]},"execution_count":13},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"zJ_8nj1gQ-ZN"},"source":["best candidates appear to come from trials 2,3,  & 5.\n","\n","*   List item\n","*   List item\n","\n","\n","let's evaluate both"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yvKjX7ZCmggB","executionInfo":{"status":"ok","timestamp":1607408362892,"user_tz":360,"elapsed":6411904,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"c87a5b04-69cf-4c7f-af8d-69e7895020bb"},"source":["from functools import partial\n","\n","def model_init():\n","   return BertForSequenceClassification.from_pretrained('bert-large-uncased',\n","                                                        num_labels=2,\n","                                                        output_attentions=False,\n","                                                        output_hidden_states=False)   \n","\n","   \n","config = {\n","    \"lr\": tune.choice([5e-5,3e-5,2e-5]),\n","    \"eps\": tune.choice([1e-6]),\n","    \"weight_decay\": tune.choice([0]),\n","    \"batch_size\": tune.choice([16, 32]),\n","    \"epochs\": tune.choice([2,3, 4])\n","}\n","\n","scheduler = ASHAScheduler(\n","    metric=\"auc\",\n","    mode=\"max\",\n","    max_t=10,\n","    grace_period=1,\n","    reduction_factor=2\n",")\n","\n","reporter = CLIReporter(metric_columns=[\"loss\", \"auc\", \"training_iteration\"])\n","hyperopt_search = HyperOptSearch(metric=\"auc\", mode=\"max\")\n","\n","result = tune.run(\n","    partial(train_and_hyperparam_search, model_init=model_init, data=dataset_clf, cv=3),\n","    resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n","    config=config,\n","    num_samples=8,\n","    scheduler=scheduler,\n","    search_alg=hyperopt_search,\n","    progress_reporter=reporter\n",")"],"execution_count":13,"outputs":[{"output_type":"stream","text":["2020-12-08 04:32:31,912\tINFO services.py:1092 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n","2020-12-08 04:32:35,131\tWARNING experiment.py:274 -- No name detected on trainable. Using DEFAULT.\n","2020-12-08 04:32:35,132\tINFO registry.py:65 -- Detected unknown callable for trainable. Converting to class.\n","2020-12-08 04:32:35,136\tWARNING function_runner.py:540 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"],"name":"stderr"},{"output_type":"stream","text":["== Status ==\n","Memory usage on this node: 1.4/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n","Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.52 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-08_04-32-35\n","Number of trials: 1/8 (1 RUNNING)\n","+------------------+----------+-------+--------------+----------+-------+-------+----------------+\n","| Trial name       | status   | loc   |   batch_size |   epochs |   eps |    lr |   weight_decay |\n","|------------------+----------+-------+--------------+----------+-------+-------+----------------|\n","| DEFAULT_64ff12fa | RUNNING  |       |           32 |        3 | 1e-06 | 3e-05 |              0 |\n","+------------------+----------+-------+--------------+----------+-------+-------+----------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3342)\u001b[0m 2020-12-08 04:32:36.615637: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3342)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m Training loss for epoch 1: 0.6692748904228211\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m Training loss for epoch 2: 0.5258093875646591\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m Training loss for epoch 3: 0.3100306811928749\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3342)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3342)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m Training loss for epoch 1: 0.6889145720005035\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m Training loss for epoch 2: 0.6129453384876251\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m Training loss for epoch 3: 0.47560290664434435\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3342)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3342)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m Training loss for epoch 1: 0.7335677325725556\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m Training loss for epoch 2: 0.7150760757923126\n","\u001b[2m\u001b[36m(pid=3342)\u001b[0m Training loss for epoch 3: 0.7105982983112336\n","Result for DEFAULT_64ff12fa:\n","  auc: 0.6914513803998568\n","  date: 2020-12-08_04-45-28\n","  done: false\n","  experiment_id: ce5d5985ad6f4482a57ce5939cd7170c\n","  experiment_tag: 1_batch_size=32,epochs=3,eps=1e-06,lr=3e-05,weight_decay=0\n","  hostname: 3dbdeaba70c6\n","  iterations_since_restore: 1\n","  loss: 0.6423841114176645\n","  node_ip: 172.28.0.2\n","  pid: 3342\n","  time_since_restore: 770.2191460132599\n","  time_this_iter_s: 770.2191460132599\n","  time_total_s: 770.2191460132599\n","  timestamp: 1607402728\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 64ff12fa\n","  \n","== Status ==\n","Memory usage on this node: 4.3/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.6914513803998568\n","Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.52 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-08_04-32-35\n","Number of trials: 2/8 (1 PENDING, 1 RUNNING)\n","+------------------+----------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","| Trial name       | status   | loc             |   batch_size |   epochs |   eps |    lr |   weight_decay |     loss |      auc |   training_iteration |\n","|------------------+----------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------|\n","| DEFAULT_64ff12fa | RUNNING  | 172.28.0.2:3342 |           32 |        3 | 1e-06 | 3e-05 |              0 | 0.642384 | 0.691451 |                    1 |\n","| DEFAULT_650f99f4 | PENDING  |                 |           32 |        2 | 1e-06 | 3e-05 |              0 |          |          |                      |\n","+------------------+----------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3341)\u001b[0m 2020-12-08 04:45:29.881480: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3341)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m Training loss for epoch 1: 0.6736257445812225\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m Training loss for epoch 2: 0.5824425190687179\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3341)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3341)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m Training loss for epoch 1: 0.6819853901863098\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m Training loss for epoch 2: 0.5430249333381653\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3341)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3341)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m Training loss for epoch 1: 0.6975177121162415\n","\u001b[2m\u001b[36m(pid=3341)\u001b[0m Training loss for epoch 2: 0.5991556799411774\n","Result for DEFAULT_650f99f4:\n","  auc: 0.745186523790104\n","  date: 2020-12-08_04-54-26\n","  done: false\n","  experiment_id: bde182d3436b495a92ec08a5c440f64b\n","  experiment_tag: 2_batch_size=32,epochs=2,eps=1e-06,lr=3e-05,weight_decay=0\n","  hostname: 3dbdeaba70c6\n","  iterations_since_restore: 1\n","  loss: 0.6089461175600688\n","  node_ip: 172.28.0.2\n","  pid: 3341\n","  time_since_restore: 535.3832182884216\n","  time_this_iter_s: 535.3832182884216\n","  time_total_s: 535.3832182884216\n","  timestamp: 1607403266\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 650f99f4\n","  \n","== Status ==\n","Memory usage on this node: 4.2/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.7183189520949804\n","Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.52 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-08_04-32-35\n","Number of trials: 3/8 (1 PENDING, 1 RUNNING, 1 TERMINATED)\n","+------------------+------------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","| Trial name       | status     | loc             |   batch_size |   epochs |   eps |    lr |   weight_decay |     loss |      auc |   training_iteration |\n","|------------------+------------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------|\n","| DEFAULT_650f99f4 | RUNNING    | 172.28.0.2:3341 |           32 |        2 | 1e-06 | 3e-05 |              0 | 0.608946 | 0.745187 |                    1 |\n","| DEFAULT_31e0cd12 | PENDING    |                 |           16 |        4 | 1e-06 | 5e-05 |              0 |          |          |                      |\n","| DEFAULT_64ff12fa | TERMINATED |                 |           32 |        3 | 1e-06 | 3e-05 |              0 | 0.642384 | 0.691451 |                    1 |\n","+------------------+------------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3512)\u001b[0m 2020-12-08 04:54:28.611629: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3512)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Training loss for epoch 1: 0.7092341762600523\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Training loss for epoch 2: 0.7095960390688193\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Training loss for epoch 3: 0.7089660209838791\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Training loss for epoch 4: 0.703097955145017\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3512)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3512)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Training loss for epoch 1: 0.7162659071912669\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Training loss for epoch 2: 0.7080549079962452\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Training loss for epoch 3: 0.7140601391744132\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Training loss for epoch 4: 0.7065302916247436\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3512)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3512)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Training loss for epoch 1: 0.6745883674934657\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Training loss for epoch 2: 0.6986678215590391\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Training loss for epoch 3: 0.7148925264676412\n","\u001b[2m\u001b[36m(pid=3512)\u001b[0m Training loss for epoch 4: 0.7131923413035846\n","Result for DEFAULT_31e0cd12:\n","  auc: 0.5576848396582704\n","  date: 2020-12-08_05-13-29\n","  done: true\n","  experiment_id: 63e6eb09aea34726b9e672af0191d997\n","  experiment_tag: 3_batch_size=16,epochs=4,eps=1e-06,lr=5e-05,weight_decay=0\n","  hostname: 3dbdeaba70c6\n","  iterations_since_restore: 1\n","  loss: 0.6916508907576402\n","  node_ip: 172.28.0.2\n","  pid: 3512\n","  time_since_restore: 1139.295240163803\n","  time_this_iter_s: 1139.295240163803\n","  time_total_s: 1139.295240163803\n","  timestamp: 1607404409\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 31e0cd12\n","  \n","== Status ==\n","Memory usage on this node: 5.1/12.7 GiB\n","Using AsyncHyperBand: num_stopped=1\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.6914513803998568\n","Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.52 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-08_04-32-35\n","Number of trials: 4/8 (1 PENDING, 3 TERMINATED)\n","+------------------+------------+-------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","| Trial name       | status     | loc   |   batch_size |   epochs |   eps |    lr |   weight_decay |     loss |      auc |   training_iteration |\n","|------------------+------------+-------+--------------+----------+-------+-------+----------------+----------+----------+----------------------|\n","| DEFAULT_72cad1fa | PENDING    |       |           16 |        2 | 1e-06 | 2e-05 |              0 |          |          |                      |\n","| DEFAULT_64ff12fa | TERMINATED |       |           32 |        3 | 1e-06 | 3e-05 |              0 | 0.642384 | 0.691451 |                    1 |\n","| DEFAULT_650f99f4 | TERMINATED |       |           32 |        2 | 1e-06 | 3e-05 |              0 | 0.608946 | 0.745187 |                    1 |\n","| DEFAULT_31e0cd12 | TERMINATED |       |           16 |        4 | 1e-06 | 5e-05 |              0 | 0.691651 | 0.557685 |                    1 |\n","+------------------+------------+-------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3591)\u001b[0m 2020-12-08 05:13:33.034826: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3591)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m Training loss for epoch 1: 0.6610894754077449\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m Training loss for epoch 2: 0.6587907957910287\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3591)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3591)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m Training loss for epoch 1: 0.6819026942807015\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m Training loss for epoch 2: 0.5923224070457497\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3591)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3591)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m Training loss for epoch 1: 0.6566136205437207\n","\u001b[2m\u001b[36m(pid=3591)\u001b[0m Training loss for epoch 2: 0.5925287939984389\n","Result for DEFAULT_72cad1fa:\n","  auc: 0.7125887256787613\n","  date: 2020-12-08_05-23-27\n","  done: false\n","  experiment_id: 15a03866ed0146b5b16ea5c03186b8c8\n","  experiment_tag: 4_batch_size=16,epochs=2,eps=1e-06,lr=2e-05,weight_decay=0\n","  hostname: 3dbdeaba70c6\n","  iterations_since_restore: 1\n","  loss: 0.6228359876573085\n","  node_ip: 172.28.0.2\n","  pid: 3591\n","  time_since_restore: 593.2399001121521\n","  time_this_iter_s: 593.2399001121521\n","  time_total_s: 593.2399001121521\n","  timestamp: 1607405007\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 72cad1fa\n","  \n","== Status ==\n","Memory usage on this node: 4.3/12.7 GiB\n","Using AsyncHyperBand: num_stopped=1\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.702020053039309\n","Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.52 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-08_04-32-35\n","Number of trials: 5/8 (1 PENDING, 1 RUNNING, 3 TERMINATED)\n","+------------------+------------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","| Trial name       | status     | loc             |   batch_size |   epochs |   eps |    lr |   weight_decay |     loss |      auc |   training_iteration |\n","|------------------+------------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------|\n","| DEFAULT_72cad1fa | RUNNING    | 172.28.0.2:3591 |           16 |        2 | 1e-06 | 2e-05 |              0 | 0.622836 | 0.712589 |                    1 |\n","| DEFAULT_1be00826 | PENDING    |                 |           32 |        4 | 1e-06 | 5e-05 |              0 |          |          |                      |\n","| DEFAULT_64ff12fa | TERMINATED |                 |           32 |        3 | 1e-06 | 3e-05 |              0 | 0.642384 | 0.691451 |                    1 |\n","| DEFAULT_650f99f4 | TERMINATED |                 |           32 |        2 | 1e-06 | 3e-05 |              0 | 0.608946 | 0.745187 |                    1 |\n","| DEFAULT_31e0cd12 | TERMINATED |                 |           16 |        4 | 1e-06 | 5e-05 |              0 | 0.691651 | 0.557685 |                    1 |\n","+------------------+------------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3639)\u001b[0m 2020-12-08 05:23:29.862768: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3639)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Training loss for epoch 1: 0.6837799835205078\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Training loss for epoch 2: 0.5796168011426925\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Training loss for epoch 3: 0.5312744915485382\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Training loss for epoch 4: 0.4144663369655609\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3639)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3639)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Training loss for epoch 1: 0.6468720155954361\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Training loss for epoch 2: 0.4968733757734299\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Training loss for epoch 3: 0.3787252396345139\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Training loss for epoch 4: 0.2542352817207575\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3639)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3639)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Training loss for epoch 1: 0.67778469145298\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Training loss for epoch 2: 0.5940318322181701\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Training loss for epoch 3: 0.46662801295518874\n","\u001b[2m\u001b[36m(pid=3639)\u001b[0m Training loss for epoch 4: 0.3353445766866207\n","Result for DEFAULT_1be00826:\n","  auc: 0.7435307191979917\n","  date: 2020-12-08_05-40-34\n","  done: false\n","  experiment_id: 51f775c8e9bc4b5199d79d508b6d4528\n","  experiment_tag: 5_batch_size=32,epochs=4,eps=1e-06,lr=5e-05,weight_decay=0\n","  hostname: 3dbdeaba70c6\n","  iterations_since_restore: 1\n","  loss: 0.7091321375469367\n","  node_ip: 172.28.0.2\n","  pid: 3639\n","  time_since_restore: 1023.2764966487885\n","  time_this_iter_s: 1023.2764966487885\n","  time_total_s: 1023.2764966487885\n","  timestamp: 1607406034\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 1be00826\n","  \n","== Status ==\n","Memory usage on this node: 4.3/12.7 GiB\n","Using AsyncHyperBand: num_stopped=1\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.7125887256787613\n","Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.52 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-08_04-32-35\n","Number of trials: 6/8 (1 PENDING, 1 RUNNING, 4 TERMINATED)\n","+------------------+------------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","| Trial name       | status     | loc             |   batch_size |   epochs |   eps |    lr |   weight_decay |     loss |      auc |   training_iteration |\n","|------------------+------------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------|\n","| DEFAULT_1be00826 | RUNNING    | 172.28.0.2:3639 |           32 |        4 | 1e-06 | 5e-05 |              0 | 0.709132 | 0.743531 |                    1 |\n","| DEFAULT_80868858 | PENDING    |                 |           32 |        4 | 1e-06 | 2e-05 |              0 |          |          |                      |\n","| DEFAULT_64ff12fa | TERMINATED |                 |           32 |        3 | 1e-06 | 3e-05 |              0 | 0.642384 | 0.691451 |                    1 |\n","| DEFAULT_650f99f4 | TERMINATED |                 |           32 |        2 | 1e-06 | 3e-05 |              0 | 0.608946 | 0.745187 |                    1 |\n","| DEFAULT_31e0cd12 | TERMINATED |                 |           16 |        4 | 1e-06 | 5e-05 |              0 | 0.691651 | 0.557685 |                    1 |\n","| DEFAULT_72cad1fa | TERMINATED |                 |           16 |        2 | 1e-06 | 2e-05 |              0 | 0.622836 | 0.712589 |                    1 |\n","+------------------+------------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3701)\u001b[0m 2020-12-08 05:40:36.413203: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3701)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Training loss for epoch 1: 0.6658939862251282\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Training loss for epoch 2: 0.5459538286924362\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Training loss for epoch 3: 0.3568506127595901\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Training loss for epoch 4: 0.20102380990982055\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3701)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3701)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Training loss for epoch 1: 0.6823783743381501\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Training loss for epoch 2: 0.5849812769889832\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Training loss for epoch 3: 0.4335847669839859\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Training loss for epoch 4: 0.29735022097826\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3701)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3701)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Training loss for epoch 1: 0.673695695400238\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Training loss for epoch 2: 0.5993942850828171\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Training loss for epoch 3: 0.4504946792125702\n","\u001b[2m\u001b[36m(pid=3701)\u001b[0m Training loss for epoch 4: 0.3381682547926903\n","Result for DEFAULT_80868858:\n","  auc: 0.7679395579767133\n","  date: 2020-12-08_05-57-27\n","  done: false\n","  experiment_id: 15f83b1ca08d4597803d4a3cf5a138be\n","  experiment_tag: 6_batch_size=32,epochs=4,eps=1e-06,lr=2e-05,weight_decay=0\n","  hostname: 3dbdeaba70c6\n","  iterations_since_restore: 1\n","  loss: 0.6279510885973772\n","  node_ip: 172.28.0.2\n","  pid: 3701\n","  time_since_restore: 1009.2359342575073\n","  time_this_iter_s: 1009.2359342575073\n","  time_total_s: 1009.2359342575073\n","  timestamp: 1607407047\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: '80868858'\n","  \n","== Status ==\n","Memory usage on this node: 4.3/12.7 GiB\n","Using AsyncHyperBand: num_stopped=1\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.7280597224383765\n","Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.52 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-08_04-32-35\n","Number of trials: 7/8 (1 PENDING, 1 RUNNING, 5 TERMINATED)\n","+------------------+------------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","| Trial name       | status     | loc             |   batch_size |   epochs |   eps |    lr |   weight_decay |     loss |      auc |   training_iteration |\n","|------------------+------------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------|\n","| DEFAULT_80868858 | RUNNING    | 172.28.0.2:3701 |           32 |        4 | 1e-06 | 2e-05 |              0 | 0.627951 | 0.76794  |                    1 |\n","| DEFAULT_e48dfe1a | PENDING    |                 |           32 |        2 | 1e-06 | 5e-05 |              0 |          |          |                      |\n","| DEFAULT_64ff12fa | TERMINATED |                 |           32 |        3 | 1e-06 | 3e-05 |              0 | 0.642384 | 0.691451 |                    1 |\n","| DEFAULT_650f99f4 | TERMINATED |                 |           32 |        2 | 1e-06 | 3e-05 |              0 | 0.608946 | 0.745187 |                    1 |\n","| DEFAULT_31e0cd12 | TERMINATED |                 |           16 |        4 | 1e-06 | 5e-05 |              0 | 0.691651 | 0.557685 |                    1 |\n","| DEFAULT_72cad1fa | TERMINATED |                 |           16 |        2 | 1e-06 | 2e-05 |              0 | 0.622836 | 0.712589 |                    1 |\n","| DEFAULT_1be00826 | TERMINATED |                 |           32 |        4 | 1e-06 | 5e-05 |              0 | 0.709132 | 0.743531 |                    1 |\n","+------------------+------------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3766)\u001b[0m 2020-12-08 05:57:28.955212: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3766)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m Training loss for epoch 1: 0.7143387031555176\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m Training loss for epoch 2: 0.6874774992465973\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3766)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3766)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m Training loss for epoch 1: 0.7212314891815186\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m Training loss for epoch 2: 0.628286537528038\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3766)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3766)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m Training loss for epoch 1: 0.68878497838974\n","\u001b[2m\u001b[36m(pid=3766)\u001b[0m Training loss for epoch 2: 0.6102926844358444\n","Result for DEFAULT_e48dfe1a:\n","  auc: 0.6701296879392956\n","  date: 2020-12-08_06-06-24\n","  done: true\n","  experiment_id: 5dad89444a1846c28231888ea3e5f837\n","  experiment_tag: 7_batch_size=32,epochs=2,eps=1e-06,lr=5e-05,weight_decay=0\n","  hostname: 3dbdeaba70c6\n","  iterations_since_restore: 1\n","  loss: 0.6724028853575388\n","  node_ip: 172.28.0.2\n","  pid: 3766\n","  time_since_restore: 533.6372172832489\n","  time_this_iter_s: 533.6372172832489\n","  time_total_s: 533.6372172832489\n","  timestamp: 1607407584\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: e48dfe1a\n","  \n","== Status ==\n","Memory usage on this node: 4.3/12.7 GiB\n","Using AsyncHyperBand: num_stopped=2\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.7125887256787613\n","Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.52 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-08_04-32-35\n","Number of trials: 8/8 (1 PENDING, 7 TERMINATED)\n","+------------------+------------+-------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","| Trial name       | status     | loc   |   batch_size |   epochs |   eps |    lr |   weight_decay |     loss |      auc |   training_iteration |\n","|------------------+------------+-------+--------------+----------+-------+-------+----------------+----------+----------+----------------------|\n","| DEFAULT_400dd862 | PENDING    |       |           32 |        3 | 1e-06 | 5e-05 |              0 |          |          |                      |\n","| DEFAULT_64ff12fa | TERMINATED |       |           32 |        3 | 1e-06 | 3e-05 |              0 | 0.642384 | 0.691451 |                    1 |\n","| DEFAULT_650f99f4 | TERMINATED |       |           32 |        2 | 1e-06 | 3e-05 |              0 | 0.608946 | 0.745187 |                    1 |\n","| DEFAULT_31e0cd12 | TERMINATED |       |           16 |        4 | 1e-06 | 5e-05 |              0 | 0.691651 | 0.557685 |                    1 |\n","| DEFAULT_72cad1fa | TERMINATED |       |           16 |        2 | 1e-06 | 2e-05 |              0 | 0.622836 | 0.712589 |                    1 |\n","| DEFAULT_1be00826 | TERMINATED |       |           32 |        4 | 1e-06 | 5e-05 |              0 | 0.709132 | 0.743531 |                    1 |\n","| DEFAULT_80868858 | TERMINATED |       |           32 |        4 | 1e-06 | 2e-05 |              0 | 0.627951 | 0.76794  |                    1 |\n","| DEFAULT_e48dfe1a | TERMINATED |       |           32 |        2 | 1e-06 | 5e-05 |              0 | 0.672403 | 0.67013  |                    1 |\n","+------------------+------------+-------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3811)\u001b[0m 2020-12-08 06:06:26.174096: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3811)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m Training loss for epoch 1: 0.6891255950927735\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m Training loss for epoch 2: 0.6047997176647186\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m Training loss for epoch 3: 0.43482783138751985\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3811)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3811)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m Training loss for epoch 1: 0.6903380227088928\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m Training loss for epoch 2: 0.5779154294729233\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m Training loss for epoch 3: 0.37280466586351396\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3811)\u001b[0m Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=3811)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m Training loss for epoch 1: 0.6528354704380035\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m Training loss for epoch 2: 0.4810764163732529\n","\u001b[2m\u001b[36m(pid=3811)\u001b[0m Training loss for epoch 3: 0.3093424171209335\n"],"name":"stdout"},{"output_type":"stream","text":["2020-12-08 06:19:22,633\tINFO tune.py:439 -- Total run time: 6411.52 seconds (6407.45 seconds for the tuning loop).\n"],"name":"stderr"},{"output_type":"stream","text":["Result for DEFAULT_400dd862:\n","  auc: 0.7802492532386718\n","  date: 2020-12-08_06-19-22\n","  done: false\n","  experiment_id: a0a46426c59043b7a2bbe428f1fa8767\n","  experiment_tag: 8_batch_size=32,epochs=3,eps=1e-06,lr=5e-05,weight_decay=0\n","  hostname: 3dbdeaba70c6\n","  iterations_since_restore: 1\n","  loss: 0.6392128335767322\n","  node_ip: 172.28.0.2\n","  pid: 3811\n","  time_since_restore: 774.9643497467041\n","  time_this_iter_s: 774.9643497467041\n","  time_total_s: 774.9643497467041\n","  timestamp: 1607408362\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 400dd862\n","  \n","== Status ==\n","Memory usage on this node: 4.3/12.7 GiB\n","Using AsyncHyperBand: num_stopped=2\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.7280597224383765\n","Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.52 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-08_04-32-35\n","Number of trials: 8/8 (1 RUNNING, 7 TERMINATED)\n","+------------------+------------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","| Trial name       | status     | loc             |   batch_size |   epochs |   eps |    lr |   weight_decay |     loss |      auc |   training_iteration |\n","|------------------+------------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------|\n","| DEFAULT_400dd862 | RUNNING    | 172.28.0.2:3811 |           32 |        3 | 1e-06 | 5e-05 |              0 | 0.639213 | 0.780249 |                    1 |\n","| DEFAULT_64ff12fa | TERMINATED |                 |           32 |        3 | 1e-06 | 3e-05 |              0 | 0.642384 | 0.691451 |                    1 |\n","| DEFAULT_650f99f4 | TERMINATED |                 |           32 |        2 | 1e-06 | 3e-05 |              0 | 0.608946 | 0.745187 |                    1 |\n","| DEFAULT_31e0cd12 | TERMINATED |                 |           16 |        4 | 1e-06 | 5e-05 |              0 | 0.691651 | 0.557685 |                    1 |\n","| DEFAULT_72cad1fa | TERMINATED |                 |           16 |        2 | 1e-06 | 2e-05 |              0 | 0.622836 | 0.712589 |                    1 |\n","| DEFAULT_1be00826 | TERMINATED |                 |           32 |        4 | 1e-06 | 5e-05 |              0 | 0.709132 | 0.743531 |                    1 |\n","| DEFAULT_80868858 | TERMINATED |                 |           32 |        4 | 1e-06 | 2e-05 |              0 | 0.627951 | 0.76794  |                    1 |\n","| DEFAULT_e48dfe1a | TERMINATED |                 |           32 |        2 | 1e-06 | 5e-05 |              0 | 0.672403 | 0.67013  |                    1 |\n","+------------------+------------+-----------------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","\n","\n","== Status ==\n","Memory usage on this node: 4.3/12.7 GiB\n","Using AsyncHyperBand: num_stopped=2\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.7280597224383765\n","Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.52 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-08_04-32-35\n","Number of trials: 8/8 (8 TERMINATED)\n","+------------------+------------+-------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","| Trial name       | status     | loc   |   batch_size |   epochs |   eps |    lr |   weight_decay |     loss |      auc |   training_iteration |\n","|------------------+------------+-------+--------------+----------+-------+-------+----------------+----------+----------+----------------------|\n","| DEFAULT_64ff12fa | TERMINATED |       |           32 |        3 | 1e-06 | 3e-05 |              0 | 0.642384 | 0.691451 |                    1 |\n","| DEFAULT_650f99f4 | TERMINATED |       |           32 |        2 | 1e-06 | 3e-05 |              0 | 0.608946 | 0.745187 |                    1 |\n","| DEFAULT_31e0cd12 | TERMINATED |       |           16 |        4 | 1e-06 | 5e-05 |              0 | 0.691651 | 0.557685 |                    1 |\n","| DEFAULT_72cad1fa | TERMINATED |       |           16 |        2 | 1e-06 | 2e-05 |              0 | 0.622836 | 0.712589 |                    1 |\n","| DEFAULT_1be00826 | TERMINATED |       |           32 |        4 | 1e-06 | 5e-05 |              0 | 0.709132 | 0.743531 |                    1 |\n","| DEFAULT_80868858 | TERMINATED |       |           32 |        4 | 1e-06 | 2e-05 |              0 | 0.627951 | 0.76794  |                    1 |\n","| DEFAULT_e48dfe1a | TERMINATED |       |           32 |        2 | 1e-06 | 5e-05 |              0 | 0.672403 | 0.67013  |                    1 |\n","| DEFAULT_400dd862 | TERMINATED |       |           32 |        3 | 1e-06 | 5e-05 |              0 | 0.639213 | 0.780249 |                    1 |\n","+------------------+------------+-------+--------------+----------+-------+-------+----------------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["31359330e7334ae6887b0316824e69c0","bf04a633fd3e48f8a5bdce238a80a618","d9133a6242484bc9baaf79720bd1ccb6","a032a8705eef4fee81c03228bcffa542","339c2feacb0745678a9fbf38a456626d","425e4c7dd5fa4c799a8782622562e33e","9633c0a20aa44416836ff7390114dbf3","e5235be686f244169115f0686e5cbcbf"]},"id":"zat15pljKhbw","executionInfo":{"status":"ok","timestamp":1607411054418,"user_tz":360,"elapsed":725,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"6b58570d-8f25-41c9-f450-cbe16ff0a852"},"source":["def train(model, epochs, train_dataloader, test_dataloader, optimizer, scheduler):\n","  for epoch in tqdm(range(1, epochs+1)): # use tqdm for a progress bar\n","    model.train() # enter training mode\n","    loss_train_total = 0\n","\n","    progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch}', leave=False, disable=False)\n","    for batch in progress_bar:\n","        model.zero_grad()\n","        \n","        # get CUDA data\n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {\n","            'input_ids':      batch[0],\n","            'attention_mask': batch[1],\n","            'labels':         batch[2],\n","        }\n","\n","        outputs = model(**inputs) # evaluate\n","        \n","        # for reference, we are using cross-entropy loss here,\n","        # as implemented in https://huggingface.co/transformers/_modules/transformers/modeling_bert.html\n","        loss = outputs[0]\n","        loss_train_total += loss.item()\n","        loss.backward() # do backprop\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n","          \n","        \n","    torch.save(model.state_dict(), f'/content/drive/MyDrive/finetuned_BERT_epoch_{epoch}.model')\n","        \n","    tqdm.write(f'\\nEpoch {epoch}')\n","    \n","    loss_train_avg = loss_train_total/len(train_dataloader)            \n","    tqdm.write(f'Training loss: {loss_train_avg}')\n","    \n","    val_loss, predictions, true_vals = evaluate(model, test_dataloader, device)\n","    auc = auc_score(predictions, true_vals)\n","    tqdm.write(f'Testing loss: {val_loss}')\n","    tqdm.write(f'AUC: {auc}')\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n","                                          do_lower_case=True)"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31359330e7334ae6887b0316824e69c0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yh0f1Z3OKlt1","executionInfo":{"status":"ok","timestamp":1607411066885,"user_tz":360,"elapsed":438,"user":{"displayName":"Shujah A Ahmad","photoUrl":"","userId":"08455194275534271011"}},"outputId":"2b4664f3-3719-41e0-e637-2269d0fa2552"},"source":["X_train, X_val, y_train, y_val = train_test_split(dataset_clf.index.values, \n","                                                  dataset_clf.label.values, \n","                                                  test_size=0.15, \n","                                                  random_state=42, \n","                                                  stratify=dataset_clf.label.values)\n","\n","dataset_clf['data_type'] = ['not_set']*dataset_final.shape[0]\n","\n","dataset_clf.loc[X_train, 'data_type'] = 'train'\n","dataset_clf.loc[X_val, 'data_type'] = 'test'\n","\n","dataset_train = dataset_clf.loc[dataset_clf.data_type == 'train']\n","dataset_test = dataset_clf.loc[dataset_clf.data_type == 'test']"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  import sys\n","/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  isetter(loc, value)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vm891kkjKomA"},"source":["# model 1\n","# |  batch_size |   epochs |         eps |          lr |   weight_decay |\n","# |           16 |        2 | 4.94087e-09 | 1.19201e-05|    5.42786e-09 |\n","\n","encoded_data_train = tokenizer.batch_encode_plus(\n","    dataset_clf[dataset_clf.data_type=='train'].clean_text.values, \n","    add_special_tokens=True, \n","    return_attention_mask=True, \n","    padding=True, \n","    max_length=64, \n","    return_tensors='pt'\n",")\n","\n","encoded_data_test = tokenizer.batch_encode_plus(\n","    dataset_clf[dataset_clf.data_type=='test'].clean_text.values, \n","    add_special_tokens=True, \n","    return_attention_mask=True, \n","    padding=True, \n","    max_length=64, \n","    return_tensors='pt'\n",")\n","\n","\n","# destructure out the input_ids, attention masks, and labels from tokenizer & encoder output\n","input_ids_train = encoded_data_train['input_ids']\n","attention_masks_train = encoded_data_train['attention_mask']\n","labels_train = torch.tensor(dataset_clf[dataset_clf.data_type=='train'].label.values)\n","\n","input_ids_test = encoded_data_test['input_ids']\n","attention_masks_test = encoded_data_test['attention_mask']\n","labels_test = torch.tensor(dataset_clf[dataset_clf.data_type=='test'].label.values)\n","\n","train_data = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","test_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n","\n","train_dataloader = DataLoader(train_data, \n","                              sampler=RandomSampler(train_data), \n","                              batch_size=16)\n","\n","test_dataloader = DataLoader(test_data,\n","                            sampler=SequentialSampler(test_data),\n","                            batch_size=16)\n"],"execution_count":null,"outputs":[]}]}