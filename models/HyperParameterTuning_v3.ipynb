{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HyperParameterTuning_v3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1cfd21f16baa4de08e7ed3f632b2ffc3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_19b841c63f81492ab9379b29bd6b64d1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8b2da1c67dd647f1b2c8e09f1ad58963","IPY_MODEL_8caf7eb70de5469986614de16c5948bf"]}},"19b841c63f81492ab9379b29bd6b64d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8b2da1c67dd647f1b2c8e09f1ad58963":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_146990475e1f4f32994a2e3da6996b17","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2870dbf4bdd248f586179dd3cbd8427e"}},"8caf7eb70de5469986614de16c5948bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b903bf8d55e34b8cb0e460837b75afdc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 3.55MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ee43b69be8c64a0fa8f45799fe8f22b2"}},"146990475e1f4f32994a2e3da6996b17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2870dbf4bdd248f586179dd3cbd8427e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b903bf8d55e34b8cb0e460837b75afdc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ee43b69be8c64a0fa8f45799fe8f22b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aedf86e4aef9406e8f070f04512f3f32":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_48ce09661b784e099a3e1d62e32828fd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_12e70703476545ec82b1e3db23dc699e","IPY_MODEL_ca9b36e92ecc41f7a19e9fa33302089a"]}},"48ce09661b784e099a3e1d62e32828fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"12e70703476545ec82b1e3db23dc699e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_351908f75d5b4c93bbaca50cf3507268","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a0d3717173604fd4ba8a6d27983bf003"}},"ca9b36e92ecc41f7a19e9fa33302089a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c72b9eae4555468ea6513489ab03b297","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3/3 [40:59&lt;00:00, 819.74s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2aa06c9a904548e4a6c9fef69e830bcd"}},"351908f75d5b4c93bbaca50cf3507268":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a0d3717173604fd4ba8a6d27983bf003":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c72b9eae4555468ea6513489ab03b297":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2aa06c9a904548e4a6c9fef69e830bcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c0c7bbf14ad41028c6eef573691baf8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_139a27385f704942aa5d99a6ea0297a7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_64c0de4931da452792a633bede2311ea","IPY_MODEL_c5abffc436f94a268ca7b95ff8df1219"]}},"139a27385f704942aa5d99a6ea0297a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"64c0de4931da452792a633bede2311ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cef028e4e93740ef89a2aea4866659c7","_dom_classes":[],"description":"Epoch 1: 100%","_model_name":"FloatProgressModel","bar_style":"","max":528,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":528,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b16ac8af65d146e7a051d537567d76b3"}},"c5abffc436f94a268ca7b95ff8df1219":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bf0b224ac1404de687c2ecd90601711c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 528/528 [05:10&lt;00:00,  2.10it/s, training_loss=0.027]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d90649d62549499c809afa09ccb0beae"}},"cef028e4e93740ef89a2aea4866659c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b16ac8af65d146e7a051d537567d76b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bf0b224ac1404de687c2ecd90601711c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d90649d62549499c809afa09ccb0beae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"12f4b8974f034a8fbc64cdfe584b1b12":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_96f306869c1c4ec6afe959fdf952ea84","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e40c4a1aa78a4075b8d541f02e4fe64c","IPY_MODEL_3afed3c5a3264a5daac1309c6d2b3b67"]}},"96f306869c1c4ec6afe959fdf952ea84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e40c4a1aa78a4075b8d541f02e4fe64c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6fd6edec6c7a46f89239b4ad06cf3bab","_dom_classes":[],"description":"Epoch 2: 100%","_model_name":"FloatProgressModel","bar_style":"","max":528,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":528,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e036eb9a9aea4fee80fc45f411522949"}},"3afed3c5a3264a5daac1309c6d2b3b67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fa9057f38fb44940920bf51cf16b8308","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 528/528 [05:10&lt;00:00,  2.09it/s, training_loss=0.159]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_75a7be2e6394498bb5645ac9b44afa6a"}},"6fd6edec6c7a46f89239b4ad06cf3bab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e036eb9a9aea4fee80fc45f411522949":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fa9057f38fb44940920bf51cf16b8308":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"75a7be2e6394498bb5645ac9b44afa6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"feb4e4b986634c05b2321069a6e9efb9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8883b2213938457a87d38e3596079dbf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c586891ac961483690da5fb6df07ce9d","IPY_MODEL_20a66a847789494b89ef52ed85945f0f"]}},"8883b2213938457a87d38e3596079dbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c586891ac961483690da5fb6df07ce9d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0d51e4d006534a2daf6fea48327ccb20","_dom_classes":[],"description":"Epoch 3: 100%","_model_name":"FloatProgressModel","bar_style":"","max":528,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":528,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_03e62d9a45fb4e44a0dede7c208902f1"}},"20a66a847789494b89ef52ed85945f0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ea5b360f8c9c4899882d65bb3927fab8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 528/528 [05:09&lt;00:00,  2.08it/s, training_loss=0.003]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5af1f5f8b95e423aae2f3b95585a8623"}},"0d51e4d006534a2daf6fea48327ccb20":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"03e62d9a45fb4e44a0dede7c208902f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ea5b360f8c9c4899882d65bb3927fab8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5af1f5f8b95e423aae2f3b95585a8623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c9ef9a33db2b4cde92249986068124ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_73a460d9379a4d54bcb09bcb42b22eca","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2b5ff1ac8d3149af80104e734c3e0f74","IPY_MODEL_1831070542a74857a0f40789e406a54c"]}},"73a460d9379a4d54bcb09bcb42b22eca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b5ff1ac8d3149af80104e734c3e0f74":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_29ee32da890543b4b66eb316991672b0","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cbf9cfb3ae0446eeb5faf7c9e3cd05cd"}},"1831070542a74857a0f40789e406a54c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2f73cd982d8c4c748e071ca22101fe66","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3/3 [2:32:39&lt;00:00, 3053.25s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7093e00c3a2b45588ba2b2bf65bc2089"}},"29ee32da890543b4b66eb316991672b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cbf9cfb3ae0446eeb5faf7c9e3cd05cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2f73cd982d8c4c748e071ca22101fe66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7093e00c3a2b45588ba2b2bf65bc2089":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3f648499a90943e9b6d26bce1ef02655":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3f7b38aace164d25ae9b4092c7605c39","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c577a11afdde4100a4d51dfcb97f3464","IPY_MODEL_3ca74aa8697c43358d840dfafd9557c5"]}},"3f7b38aace164d25ae9b4092c7605c39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c577a11afdde4100a4d51dfcb97f3464":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dbf0b26e0234456384d947ab193abd5a","_dom_classes":[],"description":"Epoch 1: 100%","_model_name":"FloatProgressModel","bar_style":"","max":5278,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5278,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_184ea8a5f9754264b11e7a98188572da"}},"3ca74aa8697c43358d840dfafd9557c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_67e02d0ab2d34779b671300c6fa5ec51","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5278/5278 [48:10&lt;00:00,  2.03it/s, training_loss=0.114]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_596479eb4d6d4a879221cf610d457937"}},"dbf0b26e0234456384d947ab193abd5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"184ea8a5f9754264b11e7a98188572da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"67e02d0ab2d34779b671300c6fa5ec51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"596479eb4d6d4a879221cf610d457937":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f69570c1e9e945a4a6802d7125a94416":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d27dbe86269043959a63cbdd0173ed05","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_414f68ba7c10437cbaf9dfc5009cda86","IPY_MODEL_72cd75e94bc94ddd956c680006a2d8c5"]}},"d27dbe86269043959a63cbdd0173ed05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"414f68ba7c10437cbaf9dfc5009cda86":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e8f304fb4a90453a9122da9679d38b32","_dom_classes":[],"description":"Epoch 2: 100%","_model_name":"FloatProgressModel","bar_style":"","max":5278,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5278,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b6e9e4fcd6d14154b57efdd2222d6018"}},"72cd75e94bc94ddd956c680006a2d8c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cf3cf25e29e342b68594c6d222fdcf28","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5278/5278 [48:06&lt;00:00,  2.06it/s, training_loss=0.049]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ffc4fe63ef4742b7b021bb7e503b8365"}},"e8f304fb4a90453a9122da9679d38b32":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b6e9e4fcd6d14154b57efdd2222d6018":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cf3cf25e29e342b68594c6d222fdcf28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ffc4fe63ef4742b7b021bb7e503b8365":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a33e773d78ac43909dadc932cd817053":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d82add1945d64244aa440253f8daf401","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_aa38681f05f049559887481067df703d","IPY_MODEL_ced68a1ad33e4f8c851785a6f975434d"]}},"d82add1945d64244aa440253f8daf401":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aa38681f05f049559887481067df703d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8dec683a312646569dbaf29ba0ff48f9","_dom_classes":[],"description":"Epoch 3: 100%","_model_name":"FloatProgressModel","bar_style":"","max":5278,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5278,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_13ffdbb4a24d402dae6f140a00d19b4b"}},"ced68a1ad33e4f8c851785a6f975434d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_03eabcd2760546ddaeb94b3189e847ef","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5278/5278 [47:51&lt;00:00,  2.04it/s, training_loss=0.000]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e89af0f34c0945e78084441963a104b6"}},"8dec683a312646569dbaf29ba0ff48f9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"13ffdbb4a24d402dae6f140a00d19b4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"03eabcd2760546ddaeb94b3189e847ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e89af0f34c0945e78084441963a104b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7468ccadd3204340842f7bcd2a2bacf2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_401e144da1044713b8db8e2299182ff7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_19c696543ffb41ecb3df47c522b21d8b","IPY_MODEL_267ede7e8fc145ee94118b5880b288ff"]}},"401e144da1044713b8db8e2299182ff7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19c696543ffb41ecb3df47c522b21d8b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0bdd44c7263a42a69c5e18e3c2cb6982","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_612e20814c1b4b2dbc0c1d814e1eec9c"}},"267ede7e8fc145ee94118b5880b288ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0f6c0161cd5a42c0ba37c70aceb9dc90","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3/3 [21:08&lt;00:00, 422.98s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6f465c8c8e184b6990e7f8e08444254b"}},"0bdd44c7263a42a69c5e18e3c2cb6982":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"612e20814c1b4b2dbc0c1d814e1eec9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0f6c0161cd5a42c0ba37c70aceb9dc90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6f465c8c8e184b6990e7f8e08444254b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e000f536ef814602aea430fc24b8f795":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cf65784abdb94bfa8064d09dc8b92206","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_55a8bc6553254be89a74d1d12a773cb4","IPY_MODEL_a9d2576710d2473499ff2df80dbff610"]}},"cf65784abdb94bfa8064d09dc8b92206":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"55a8bc6553254be89a74d1d12a773cb4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5c568f54e23345ff8fff951f835b4694","_dom_classes":[],"description":"Epoch 1: 100%","_model_name":"FloatProgressModel","bar_style":"","max":2110,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2110,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_96a46535cd1b4069b4d0e11f34e9cb51"}},"a9d2576710d2473499ff2df80dbff610":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d658b33dc5a04140b31b5ef75874a4d7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2110/2110 [06:25&lt;00:00,  6.26it/s, training_loss=0.003]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_856d2abae1424d65bc7fe5459793bf13"}},"5c568f54e23345ff8fff951f835b4694":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"96a46535cd1b4069b4d0e11f34e9cb51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d658b33dc5a04140b31b5ef75874a4d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"856d2abae1424d65bc7fe5459793bf13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"49b597cfd955458fa33468d4a8474763":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5d427dfad0224df7aaac6e01daf83f8c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_29243eb21d3849d49f5dfa561f65d0f5","IPY_MODEL_491a52d6df444fa6a5f470b65cedf4db"]}},"5d427dfad0224df7aaac6e01daf83f8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"29243eb21d3849d49f5dfa561f65d0f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5553f748bd4744b39c62b23ce57afe20","_dom_classes":[],"description":"Epoch 2: 100%","_model_name":"FloatProgressModel","bar_style":"","max":2110,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2110,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38a33adf847e4c2187d8bec769d34d56"}},"491a52d6df444fa6a5f470b65cedf4db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9b2e5661ab5a4f878bd635003c20e0a5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2110/2110 [06:24&lt;00:00,  5.44it/s, training_loss=0.001]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_da50178dd2ce4e0e8dd8c9934f2c9043"}},"5553f748bd4744b39c62b23ce57afe20":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"38a33adf847e4c2187d8bec769d34d56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b2e5661ab5a4f878bd635003c20e0a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"da50178dd2ce4e0e8dd8c9934f2c9043":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6f0943028dfa46c0a28130f63a938baf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_adabea3c499442e9b91686df1df86877","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_74bbc2461d3646b89eadf51866a305e4","IPY_MODEL_e12440464bbb4cef9cdc9ce5c9f5a288"]}},"adabea3c499442e9b91686df1df86877":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74bbc2461d3646b89eadf51866a305e4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c04ff95ae722444e944ff87881332dcc","_dom_classes":[],"description":"Epoch 3: 100%","_model_name":"FloatProgressModel","bar_style":"","max":2110,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2110,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2f606a341bfe4ba0933e5279cbfcc05e"}},"e12440464bbb4cef9cdc9ce5c9f5a288":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_af2448fb344a487f9a0c7315edbd4c74","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2110/2110 [06:21&lt;00:00,  5.52it/s, training_loss=0.000]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5555fda1f0d04f41a6892a9b2363f47d"}},"c04ff95ae722444e944ff87881332dcc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2f606a341bfe4ba0933e5279cbfcc05e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af2448fb344a487f9a0c7315edbd4c74":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5555fda1f0d04f41a6892a9b2363f47d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"HIJEjje19PXm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607568270889,"user_tz":360,"elapsed":28280,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}},"outputId":"ac566ae1-b00b-4267-dfd4-8e8eaad3bd11"},"source":["!pip install transformers datasets tweet-preprocessor ray[tune] hyperopt"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 16.4MB/s \n","\u001b[?25hCollecting datasets\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/38/0c24dce24767386123d528d27109024220db0e7a04467b658d587695241a/datasets-1.1.3-py3-none-any.whl (153kB)\n","\u001b[K     |████████████████████████████████| 163kB 45.4MB/s \n","\u001b[?25hCollecting tweet-preprocessor\n","  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n","Collecting ray[tune]\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/87/44476ad712acc1f7957cbf88d307d4a0283a740487cf85d710d0211d0135/ray-1.0.1.post1-cp36-cp36m-manylinux1_x86_64.whl (23.1MB)\n","\u001b[K     |████████████████████████████████| 23.1MB 59.0MB/s \n","\u001b[?25hRequirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.2)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 37.6MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 43.2MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.11.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n","Collecting pyarrow>=0.17.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n","\u001b[K     |████████████████████████████████| 17.7MB 218kB/s \n","\u001b[?25hCollecting xxhash\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n","\u001b[K     |████████████████████████████████| 245kB 51.4MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.33.2)\n","Collecting redis<3.5.0,>=3.3.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/05/1fc7feedc19c123e7a95cfc9e7892eb6cdd2e5df4e9e8af6384349c1cc3d/redis-3.4.1-py2.py3-none-any.whl (71kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.8MB/s \n","\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.6.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.13)\n","Collecting colorful\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/8e/e386e248266952d24d73ed734c2f5513f34d9557032618c8910e605dfaf6/colorful-0.5.4-py2.py3-none-any.whl (201kB)\n","\u001b[K     |████████████████████████████████| 204kB 63.7MB/s \n","\u001b[?25hCollecting aioredis\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/64/1b1612d0a104f21f80eb4c6e1b6075f2e6aba8e228f46f229cfd3fdac859/aioredis-1.3.1-py3-none-any.whl (65kB)\n","\u001b[K     |████████████████████████████████| 71kB 11.8MB/s \n","\u001b[?25hCollecting py-spy>=0.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/a7/ab45c9ee3c4654edda3efbd6b8e2fa4962226718a7e3e3be6e3926bf3617/py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 44.7MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.0.0)\n","Collecting opencensus\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/68/4f407bc0980158001c802222fab17e946728aef13f42e5d80d39dfc9ca67/opencensus-0.7.11-py2.py3-none-any.whl (127kB)\n","\u001b[K     |████████████████████████████████| 133kB 58.2MB/s \n","\u001b[?25hCollecting aiohttp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/e6/d4b6235d776c9b33f853e603efede5aac5a34f71ca9d3877adb30492eb4e/aiohttp-3.7.3-cp36-cp36m-manylinux2014_x86_64.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 43.6MB/s \n","\u001b[?25hCollecting aiohttp-cors\n","  Downloading https://files.pythonhosted.org/packages/13/e7/e436a0c0eb5127d8b491a9b83ecd2391c6ff7dcd5548dfaec2080a2340fd/aiohttp_cors-0.7.0-py3-none-any.whl\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.12.4)\n","Collecting gpustat\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/69/d8c849715171aeabd61af7da080fdc60948b5a396d2422f1f4672e43d008/gpustat-0.6.0.tar.gz (78kB)\n","\u001b[K     |████████████████████████████████| 81kB 13.0MB/s \n","\u001b[?25hRequirement already satisfied: google in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.0.3)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (7.1.2)\n","Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.9.0)\n","Collecting tensorboardX; extra == \"tune\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n","\u001b[K     |████████████████████████████████| 317kB 50.9MB/s \n","\u001b[?25hRequirement already satisfied: tabulate; extra == \"tune\" in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.8.7)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.15.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.4.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.5)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.11.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n","Collecting async-timeout\n","  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n","Collecting hiredis\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/7d/6acf1c8d4f2fb327ff6feec000b4c56a20628fbe966a4c7cd16c0b80343c/hiredis-1.1.0-cp36-cp36m-manylinux2010_x86_64.whl (61kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.9MB/s \n","\u001b[?25hCollecting opencensus-context==0.1.2\n","  Downloading https://files.pythonhosted.org/packages/f1/33/990f1bd9e7ee770fc8d3c154fc24743a96f16a0e49e14e1b7540cc2fdd93/opencensus_context-0.1.2-py2.py3-none-any.whl\n","Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray[tune]) (1.16.0)\n","Collecting yarl<2.0,>=1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/08/52b26b44bce7b818b410aee37c5e424c9ea420c557bca97dc2adac29b151/yarl-1.6.3-cp36-cp36m-manylinux2014_x86_64.whl (293kB)\n","\u001b[K     |████████████████████████████████| 296kB 53.4MB/s \n","\u001b[?25hCollecting idna-ssl>=1.0; python_version < \"3.7\"\n","  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (20.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (3.7.4.3)\n","Collecting multidict<7.0,>=4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/35/b22524d6b9cacfb4c5eff413a069bbc17c6ea628e54da5c6c989998ced5f/multidict-5.1.0-cp36-cp36m-manylinux2014_x86_64.whl (141kB)\n","\u001b[K     |████████████████████████████████| 143kB 50.5MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray[tune]) (50.3.2)\n","Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray[tune]) (7.352.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from gpustat->ray[tune]) (5.4.8)\n","Collecting blessings>=1.6\n","  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google->ray[tune]) (4.6.3)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.4.2)\n","Collecting contextvars; python_version >= \"3.6\" and python_version < \"3.7\"\n","  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n","Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.17.2)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.52.0)\n","Collecting immutables>=0.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n","\u001b[K     |████████████████████████████████| 102kB 14.3MB/s \n","\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.1.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.2.8)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.4.8)\n","Building wheels for collected packages: sacremoses, gpustat, idna-ssl, contextvars\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=fbc4b4bf444e5dbaacc703bf59e624f93249b40145e68066cdbfc5176589b41f\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gpustat: filename=gpustat-0.6.0-cp36-none-any.whl size=12622 sha256=9a1bedd8b485620959f0ed5d410da607fe7e3c31a9cd50feb70cf999da3ec83e\n","  Stored in directory: /root/.cache/pip/wheels/48/b4/d5/fb5b7f1d040f2ff20687e3bad6867d63155dbde5a7c10f4293\n","  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-cp36-none-any.whl size=3161 sha256=9c55c54faf91305fe67f43d653787816489b4aceae61eb63c116c3737ed6ed07\n","  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n","  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=37fa6ed888d834b52e2b4eefd4fcb81cef1f4b49e98fcd4faa443728d2763b71\n","  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n","Successfully built sacremoses gpustat idna-ssl contextvars\n","Installing collected packages: sacremoses, tokenizers, transformers, pyarrow, xxhash, datasets, tweet-preprocessor, redis, colorful, async-timeout, hiredis, aioredis, py-spy, colorama, immutables, contextvars, opencensus-context, opencensus, multidict, yarl, idna-ssl, aiohttp, aiohttp-cors, blessings, gpustat, tensorboardX, ray\n","  Found existing installation: pyarrow 0.14.1\n","    Uninstalling pyarrow-0.14.1:\n","      Successfully uninstalled pyarrow-0.14.1\n","Successfully installed aiohttp-3.7.3 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-3.0.1 blessings-1.7 colorama-0.4.4 colorful-0.5.4 contextvars-2.4 datasets-1.1.3 gpustat-0.6.0 hiredis-1.1.0 idna-ssl-1.1.0 immutables-0.14 multidict-5.1.0 opencensus-0.7.11 opencensus-context-0.1.2 py-spy-0.3.3 pyarrow-2.0.0 ray-1.0.1.post1 redis-3.4.1 sacremoses-0.0.43 tensorboardX-2.1 tokenizers-0.9.4 transformers-4.0.1 tweet-preprocessor-0.6.0 xxhash-2.0.0 yarl-1.6.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_guPtNMu1SKb","executionInfo":{"status":"ok","timestamp":1607568282559,"user_tz":360,"elapsed":7558,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import wordcloud\n","import preprocessor as p # tweet-preprocessor\n","import nltk\n","import re\n","import seaborn as sns\n","import torch\n","\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n","from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from scipy.special import softmax\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from tqdm.notebook import tqdm\n","from ray import tune\n","from ray.tune import CLIReporter\n","from ray.tune.schedulers import ASHAScheduler\n","from ray.tune.suggest.hyperopt import HyperOptSearch"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpfCrTnxbRga","executionInfo":{"status":"ok","timestamp":1607568303944,"user_tz":360,"elapsed":18510,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}},"outputId":"7cae38c6-7b9f-454f-9d68-90a25bea2bdc"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3NoYbhabPHjf","colab":{"base_uri":"https://localhost:8080/","height":462},"executionInfo":{"status":"ok","timestamp":1607562778894,"user_tz":360,"elapsed":12014,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}},"outputId":"6b234090-8934-4b47-e57a-be2283eca90d"},"source":["# dataset_dem = pd.read_csv('/content/drive/MyDrive/democrat_tweets_v2.csv')\n","# dataset_gop = pd.read_csv('/content/drive/MyDrive/republican_tweets_v2.csv')\n","\n","# dataset_dem[\"label\"] = \"Democrat\"\n","# dataset_gop[\"label\"] = \"Republican\"\n","\n","# dataset_final = pd.concat([dataset_dem, dataset_gop])\n","# dataset_final.reset_index(drop=True, inplace=True)\n","dataset_final = pd.read_csv(\"/content/drive/MyDrive/Copy of 2020_labled_political_tweets.csv.zip\")\n","dataset_final = dataset_final.iloc[0:50000]\n","for index, row in dataset_final.iterrows():\n","    if str(row['party']) !=\"D\":\n","      if str(row[\"party\"])!=\"R\":\n","        dataset_final.drop(index, inplace=True)\n","dataset_final.head()"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>id</th>\n","      <th>screen_name</th>\n","      <th>user_id</th>\n","      <th>time</th>\n","      <th>link</th>\n","      <th>text</th>\n","      <th>source</th>\n","      <th>party</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1212432932746473472</td>\n","      <td>RepLoriTrahan</td>\n","      <td>1079802482640019456</td>\n","      <td>2020-01-01T12:58:31-05:00</td>\n","      <td>https://www.twitter.com/RepLoriTrahan/statuses...</td>\n","      <td>I am proud of the work we’ve done over the pas...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1212390455729696768</td>\n","      <td>RepDwightEvans</td>\n","      <td>90639372</td>\n","      <td>2020-01-01T10:09:44-05:00</td>\n","      <td>https://www.twitter.com/RepDwightEvans/statuse...</td>\n","      <td>2/ @MorethanmySLE – a cancer survivor and lupu...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1212250054788038656</td>\n","      <td>RepThomasMassie</td>\n","      <td>975200486</td>\n","      <td>2020-01-01T00:51:50-05:00</td>\n","      <td>https://www.twitter.com/RepThomasMassie/status...</td>\n","      <td>@ceQs17 Why are our people in Iraq, and how di...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1212500813593169920</td>\n","      <td>SenCoryGardner</td>\n","      <td>235217558</td>\n","      <td>2020-01-01T17:28:15-05:00</td>\n","      <td>https://www.twitter.com/SenCoryGardner/statuse...</td>\n","      <td>@EnergyGOP @BLMNational @SenatorBennet @Senate...</td>\n","      <td>Twitter Web App</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6</td>\n","      <td>1212239323392856064</td>\n","      <td>RepGraceMeng</td>\n","      <td>1051127714</td>\n","      <td>2020-01-01T00:09:11-05:00</td>\n","      <td>https://www.twitter.com/RepGraceMeng/statuses/...</td>\n","      <td>It’s 2020! As we enter a new decade, I wish ev...</td>\n","      <td>Twitter for iPhone</td>\n","      <td>D</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                   id  ...              source  party\n","0           1  1212432932746473472  ...  Twitter for iPhone      D\n","1           2  1212390455729696768  ...  Twitter for iPhone      D\n","2           3  1212250054788038656  ...  Twitter for iPhone      R\n","3           4  1212500813593169920  ...     Twitter Web App      R\n","4           6  1212239323392856064  ...  Twitter for iPhone      D\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"t-2XQbD631J9","executionInfo":{"status":"ok","timestamp":1607553377314,"user_tz":360,"elapsed":12203,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}}},"source":["LABEL_MAP = {\n","    \"D\": 0,\n","    \"R\": 1\n","}\n","\n","def buildLabels(row):\n","    return LABEL_MAP.get(row[\"party\"])\n","\n","\n","def cleanTweet(row):\n","  tweet = row[\"text\"]\n","  tweet = str(p.clean(tweet))\n","  tweet = re.sub(r'[^\\w\\s]', '', tweet) # punctuation\n","  tweet = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", tweet) # numbers\n","  return tweet\n","\n","  \n","dataset_final[\"party\"] = dataset_final.apply(lambda row: buildLabels(row), axis=1)\n","dataset_final[\"clean_text\"] = dataset_final.apply(lambda row: cleanTweet(row), \n","                                                  axis=1)"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"C6JbCNxH6c9H","colab":{"base_uri":"https://localhost:8080/","height":203},"executionInfo":{"status":"ok","timestamp":1607553378584,"user_tz":360,"elapsed":385,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}},"outputId":"8fc42e65-4a42-448f-9f65-b6574abf2671"},"source":["dataset_clf = dataset_final[[\"clean_text\", \"party\"]]\n","dataset_clf.reset_index(drop=True, inplace=True)\n","dataset_clf.head()"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>clean_text</th>\n","      <th>party</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I am proud of the work weve done over the past...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>a cancer survivor and lupus warrior  spoke wi...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Why are our people in Iraq and how did Iran co...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>This year the first ever statelevel measuremen...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Its  As we enter a new decade I wish everybody...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          clean_text  party\n","0  I am proud of the work weve done over the past...      0\n","1   a cancer survivor and lupus warrior  spoke wi...      0\n","2  Why are our people in Iraq and how did Iran co...      1\n","3  This year the first ever statelevel measuremen...      1\n","4  Its  As we enter a new decade I wish everybody...      0"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"BltNRZ4kVLEX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607520099414,"user_tz":360,"elapsed":78277,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}},"outputId":"514298f5-f656-4aa0-8813-80682e508f5a"},"source":["X_train, X_val, y_train, y_val = train_test_split(dataset_clf.index.values, \n","                                                  dataset_clf.party.values, \n","                                                  test_size=0.15, \n","                                                  random_state=42, \n","                                                  stratify=dataset_clf.party.values)\n","\n","dataset_clf['data_type'] = ['not_set']*dataset_final.shape[0]\n","\n","dataset_clf.loc[X_train, 'data_type'] = 'train'\n","dataset_clf.loc[X_val, 'data_type'] = 'test'\n","\n","dataset_train = dataset_clf.loc[dataset_clf.data_type == 'train']\n","dataset_test = dataset_clf.loc[dataset_clf.data_type == 'test']"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  import sys\n","/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  isetter(loc, value)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PepEuSPxMxXB","executionInfo":{"status":"ok","timestamp":1607547517703,"user_tz":360,"elapsed":380,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}}},"source":["def get_dataloaders(data, batch_size):\n","  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n","                                            do_lower_case=True)\n","  # tokenize train and test data so BERT can understand it\n","  encoded_data_train = tokenizer.batch_encode_plus(\n","      data[data.data_type=='train'].clean_text.values, \n","      add_special_tokens=True, \n","      return_attention_mask=True, \n","      padding=True,\n","      max_length=64, \n","      return_tensors='pt'\n","  )\n","\n","  encoded_data_test = tokenizer.batch_encode_plus(\n","      data[data.data_type=='test'].clean_text.values, \n","      add_special_tokens=True, \n","      return_attention_mask=True, \n","      padding=True, \n","      max_length=64, \n","      return_tensors='pt'\n","  )\n","\n","\n","  # destructure out the input_ids, attention masks, and labels from tokenizer & encoder output\n","  input_ids_train = encoded_data_train['input_ids']\n","  attention_masks_train = encoded_data_train['attention_mask']\n","  labels_train = torch.tensor(data[data.data_type=='train'].party.values)\n","\n","  input_ids_test = encoded_data_test['input_ids']\n","  attention_masks_test = encoded_data_test['attention_mask']\n","  labels_test = torch.tensor(data[data.data_type=='test'].party.values)\n","\n","  train_data = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","  test_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n","\n","  train_dataloader = DataLoader(train_data, \n","                                sampler=RandomSampler(train_data), \n","                                batch_size=batch_size)\n","\n","  test_dataloader = DataLoader(test_data,\n","                              sampler=SequentialSampler(test_data),\n","                              batch_size=batch_size)\n","  \n","  return train_dataloader, test_dataloader"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"RdmRjhMKPPzg","executionInfo":{"status":"ok","timestamp":1607547523139,"user_tz":360,"elapsed":455,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}}},"source":["def auc_score(preds, labels):\n","  soft_preds = softmax(preds, axis=1) # logit -> probability\n","  if np.shape(preds)[1] > 2: # check for multi-class\n","    return roc_auc_score(labels, soft_preds, multi_class='ovr')\n","  else:\n","    soft_preds = soft_preds[:,1]\n","    return roc_auc_score(labels, soft_preds)\n","\n","def acc_score_by_class(preds, labels):\n","  label_dict_inverse = {v: k for k, v in LABEL_MAP.items()} \n","\n","  preds_flat = np.argmax(preds, axis=1).flatten()\n","  labels_flat = labels.flatten()\n","\n","  for label in np.unique(labels_flat):\n","    y_preds = preds_flat[labels_flat==label]\n","    y_true = labels_flat[labels_flat==label]\n","    print(f'Class: {label_dict_inverse[label]}')\n","    print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQfxvBS6PSuc","executionInfo":{"status":"ok","timestamp":1607547526385,"user_tz":360,"elapsed":379,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}}},"source":["def evaluate(model, dataloader, device):\n","  model.eval()\n","\n","  loss_val_total = 0\n","  predictions, true_vals = [], []\n","  \n","  for batch in dataloader:\n","      \n","      # convert data to CUDA\n","      batch = tuple(b.to(device) for b in batch)\n","      \n","      inputs = {\n","          'input_ids':      batch[0],\n","          'attention_mask': batch[1],\n","          'labels':         batch[2],\n","      }\n","\n","      with torch.no_grad():        \n","          outputs = model(**inputs) # get predictions\n","          \n","      loss = outputs[0]\n","      logits = outputs[1]\n","      loss_val_total += loss.item()\n","\n","      logits = logits.detach().cpu().numpy()\n","      label_ids = inputs['labels'].cpu().numpy()\n","      predictions.append(logits)\n","      true_vals.append(label_ids)\n","  \n","  loss_val_avg = loss_val_total/len(dataloader) \n","  \n","  predictions = np.concatenate(predictions, axis=0)\n","  true_vals = np.concatenate(true_vals, axis=0)\n","          \n","  return loss_val_avg, predictions, true_vals"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"GOZt7rnsXamy","executionInfo":{"status":"ok","timestamp":1607547531614,"user_tz":360,"elapsed":402,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}}},"source":["def train_and_hyperparam_search(config,\n","                                model_init, # function to init a clean version of the net\n","                                data,       # data as Pandas array\n","                                cv          # rounds of cross-validation\n","                                ):\n","  losses = []\n","  aucs = []\n","  skf = StratifiedKFold(n_splits=cv, shuffle=True)\n","  for train_idx, test_idx in skf.split(data.clean_text, data.party):\n","    model = model_init()\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    print(f\"Device: {device}\")\n","\n","    optimizer = AdamW(model.parameters(),\n","                    lr=config['lr'],\n","                    eps=1e-8) # keep this the same, just prevents exploding gradients\n","    \n","    data.loc[train_idx, 'data_type'] = 'train'\n","    data.loc[test_idx, 'data_type'] = 'test'\n","    \n","    train_dataloader, test_dataloader = get_dataloaders(data,\n","                                                        config['batch_size'])\n","\n","    for epoch in range(1, config['epochs']+1):\n","      model.train() # enter training mode\n","      loss_train_total = 0\n","\n","      for batch in train_dataloader:\n","          model.zero_grad()\n","          \n","          # get CUDA data\n","          batch = tuple(b.to(device) for b in batch)\n","          \n","          inputs = {\n","              'input_ids':      batch[0],\n","              'attention_mask': batch[1],\n","              'labels':         batch[2],\n","          }\n","\n","          outputs = model(**inputs) # evaluate\n","          \n","          # for reference, we are using cross-entropy loss here,\n","          # as implemented in https://huggingface.co/transformers/_modules/transformers/modeling_bert.html\n","          loss = outputs[0]\n","          loss_train_total += loss.item()\n","          loss.backward() # do backprop\n","\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","          optimizer.step()\n","              \n","      \n","      loss_train_avg = loss_train_total/len(train_dataloader)    \n","      print(f\"Training loss for epoch {epoch}: {loss_train_avg}\")        \n","      \n","      val_loss, predictions, true_vals = evaluate(model, test_dataloader, device)\n","      auc = auc_score(predictions, true_vals)\n","\n","      losses.append(val_loss)\n","      aucs.append(auc)\n","\n","  tune.report(loss=np.mean(losses), auc=np.mean(aucs))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZDqsHpBPJ0T","executionInfo":{"status":"ok","timestamp":1607528444156,"user_tz":360,"elapsed":8423001,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}},"outputId":"55c39657-e144-41ae-9753-21db902ca9b6"},"source":["from functools import partial\n","\n","def model_init():\n","   return BertForSequenceClassification.from_pretrained('bert-base-uncased',\n","                                                        num_labels=2,\n","                                                        output_attentions=False,\n","                                                        output_hidden_states=False)   \n","\n","   \n","config = {\n","    \"lr\": tune.choice([5e-5, 3e-5, 1e-5, 2e-5]),\n","    \"batch_size\": tune.choice([8, 16, 32]),\n","    \"epochs\": tune.choice([2, 3, 4])\n","}\n","\n","scheduler = ASHAScheduler(\n","    metric=\"loss\",\n","    mode=\"min\",\n","    max_t=10,\n","    grace_period=1,\n","    reduction_factor=2\n",")\n","\n","reporter = CLIReporter(metric_columns=[\"loss\", \"auc\", \"training_iteration\"])\n","hyperopt_search = HyperOptSearch(metric=\"loss\", mode=\"min\")\n","\n","result = tune.run(\n","    partial(train_and_hyperparam_search, model_init=model_init, data=dataset_clf, cv=3),\n","    resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n","    config=config,\n","    num_samples=8,\n","    scheduler=scheduler,\n","    search_alg=hyperopt_search,\n","    progress_reporter=reporter\n",")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["2020-12-09 13:21:39,966\tINFO services.py:1092 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n","2020-12-09 13:21:42,558\tWARNING experiment.py:274 -- No name detected on trainable. Using DEFAULT.\n","2020-12-09 13:21:42,561\tINFO registry.py:65 -- Detected unknown callable for trainable. Converting to class.\n","2020-12-09 13:21:42,563\tWARNING function_runner.py:540 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"],"name":"stderr"},{"output_type":"stream","text":["== Status ==\n","Memory usage on this node: 1.4/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n","Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.18 GiB heap, 0.0/2.44 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-09_13-21-42\n","Number of trials: 1/8 (1 RUNNING)\n","+------------------+----------+-------+--------------+----------+-------+\n","| Trial name       | status   | loc   |   batch_size |   epochs |    lr |\n","|------------------+----------+-------+--------------+----------+-------|\n","| DEFAULT_7a6857be | RUNNING  |       |            8 |        3 | 2e-05 |\n","+------------------+----------+-------+--------------+----------+-------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=385)\u001b[0m 2020-12-09 13:21:44.136804: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Downloading: 100%|██████████| 433/433 [00:00<00:00, 575kB/s]\n","Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]\n","Downloading:   2%|▏         | 8.71M/440M [00:00<00:04, 87.1MB/s]\n","Downloading:   4%|▍         | 17.8M/440M [00:00<00:04, 88.2MB/s]\n","Downloading:   6%|▌         | 26.7M/440M [00:00<00:04, 88.5MB/s]\n","Downloading:   8%|▊         | 36.0M/440M [00:00<00:04, 89.8MB/s]\n","Downloading:  10%|█         | 45.1M/440M [00:00<00:04, 90.1MB/s]\n","Downloading:  12%|█▏        | 54.6M/440M [00:00<00:04, 91.6MB/s]\n","Downloading:  14%|█▍        | 63.4M/440M [00:00<00:04, 90.4MB/s]\n","Downloading:  17%|█▋        | 72.7M/440M [00:00<00:04, 91.2MB/s]\n","Downloading:  18%|█▊        | 81.4M/440M [00:00<00:04, 89.6MB/s]\n","Downloading:  21%|██        | 90.9M/440M [00:01<00:03, 91.1MB/s]\n","Downloading:  23%|██▎       | 100M/440M [00:01<00:03, 92.2MB/s] \n","Downloading:  25%|██▍       | 109M/440M [00:01<00:03, 90.4MB/s]\n","Downloading:  27%|██▋       | 118M/440M [00:01<00:03, 84.6MB/s]\n","Downloading:  29%|██▉       | 127M/440M [00:01<00:03, 79.8MB/s]\n","Downloading:  31%|███       | 136M/440M [00:01<00:03, 82.7MB/s]\n","Downloading:  33%|███▎      | 144M/440M [00:01<00:03, 82.1MB/s]\n","Downloading:  35%|███▍      | 153M/440M [00:01<00:03, 83.5MB/s]\n","Downloading:  37%|███▋      | 161M/440M [00:01<00:03, 81.6MB/s]\n","Downloading:  39%|███▊      | 171M/440M [00:01<00:03, 84.7MB/s]\n","Downloading:  41%|████      | 179M/440M [00:02<00:03, 86.0MB/s]\n","Downloading:  43%|████▎     | 188M/440M [00:02<00:02, 86.2MB/s]\n","Downloading:  45%|████▍     | 197M/440M [00:02<00:02, 86.6MB/s]\n","Downloading:  47%|████▋     | 206M/440M [00:02<00:02, 87.4MB/s]\n","Downloading:  49%|████▉     | 215M/440M [00:02<00:02, 88.4MB/s]\n","Downloading:  51%|█████     | 224M/440M [00:02<00:02, 90.4MB/s]\n","Downloading:  53%|█████▎    | 234M/440M [00:02<00:02, 90.3MB/s]\n","Downloading:  55%|█████▌    | 243M/440M [00:02<00:02, 89.9MB/s]\n","Downloading:  57%|█████▋    | 252M/440M [00:02<00:02, 91.4MB/s]\n","Downloading:  59%|█████▉    | 261M/440M [00:02<00:01, 91.5MB/s]\n","Downloading:  61%|██████▏   | 270M/440M [00:03<00:02, 74.7MB/s]\n","Downloading:  63%|██████▎   | 278M/440M [00:03<00:02, 74.9MB/s]\n","Downloading:  65%|██████▌   | 287M/440M [00:03<00:01, 78.4MB/s]\n","Downloading:  67%|██████▋   | 296M/440M [00:03<00:01, 80.2MB/s]\n","Downloading:  69%|██████▉   | 305M/440M [00:03<00:01, 82.9MB/s]\n","Downloading:  71%|███████   | 313M/440M [00:03<00:01, 83.4MB/s]\n","Downloading:  73%|███████▎  | 322M/440M [00:03<00:01, 83.8MB/s]\n","Downloading:  75%|███████▍  | 330M/440M [00:03<00:01, 82.9MB/s]\n","Downloading:  77%|███████▋  | 338M/440M [00:03<00:01, 81.0MB/s]\n","Downloading:  79%|███████▊  | 347M/440M [00:04<00:01, 81.2MB/s]\n","Downloading:  81%|████████  | 356M/440M [00:04<00:01, 83.6MB/s]\n","Downloading:  83%|████████▎ | 364M/440M [00:04<00:00, 84.3MB/s]\n","Downloading:  85%|████████▍ | 373M/440M [00:04<00:00, 79.3MB/s]\n","Downloading:  87%|████████▋ | 381M/440M [00:04<00:00, 81.3MB/s]\n","Downloading:  89%|████████▊ | 390M/440M [00:04<00:00, 83.9MB/s]\n","Downloading:  91%|█████████ | 399M/440M [00:04<00:00, 79.0MB/s]\n","Downloading:  92%|█████████▏| 407M/440M [00:04<00:00, 75.2MB/s]\n","Downloading:  94%|█████████▍| 414M/440M [00:04<00:00, 74.4MB/s]\n","Downloading:  96%|█████████▌| 422M/440M [00:05<00:00, 74.6MB/s]\n","Downloading:  98%|█████████▊| 429M/440M [00:05<00:00, 73.5MB/s]\n","Downloading:  99%|█████████▉| 437M/440M [00:05<00:00, 71.6MB/s]\n","Downloading: 100%|██████████| 440M/440M [00:05<00:00, 83.3MB/s]\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=385)\u001b[0m Device: cuda\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=385)\u001b[0m \rDownloading:   0%|          | 0.00/232k [00:00<?, ?B/s]\rDownloading: 100%|██████████| 232k/232k [00:00<00:00, 20.2MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=385)\u001b[0m Training loss for epoch 1: 0.6163573170053787\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m Training loss for epoch 2: 0.39854388329051976\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m Training loss for epoch 3: 0.22814156145114983\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=385)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=385)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m Training loss for epoch 1: 0.593745406087182\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m Training loss for epoch 2: 0.38976584565218375\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m Training loss for epoch 3: 0.24735796834023868\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=385)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=385)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m Training loss for epoch 1: 0.6241101933202305\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m Training loss for epoch 2: 0.41037320737065613\n","\u001b[2m\u001b[36m(pid=385)\u001b[0m Training loss for epoch 3: 0.2530334459053654\n","Result for DEFAULT_7a6857be:\n","  auc: 0.8521918671231413\n","  date: 2020-12-09_13-42-07\n","  done: false\n","  experiment_id: fb6ee07b395a4effb8f64b8430ea911e\n","  experiment_tag: 1_batch_size=8,epochs=3,lr=2e-05\n","  hostname: dfae92d5365f\n","  iterations_since_restore: 1\n","  loss: 0.6217632158947156\n","  node_ip: 172.28.0.2\n","  pid: 385\n","  time_since_restore: 1221.8476831912994\n","  time_this_iter_s: 1221.8476831912994\n","  time_total_s: 1221.8476831912994\n","  timestamp: 1607521327\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 7a6857be\n","  \n","== Status ==\n","Memory usage on this node: 4.3/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.6217632158947156\n","Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.18 GiB heap, 0.0/2.44 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-09_13-21-42\n","Number of trials: 2/8 (1 PENDING, 1 RUNNING)\n","+------------------+----------+----------------+--------------+----------+-------+----------+----------+----------------------+\n","| Trial name       | status   | loc            |   batch_size |   epochs |    lr |     loss |      auc |   training_iteration |\n","|------------------+----------+----------------+--------------+----------+-------+----------+----------+----------------------|\n","| DEFAULT_7a6857be | RUNNING  | 172.28.0.2:385 |            8 |        3 | 2e-05 | 0.621763 | 0.852192 |                    1 |\n","| DEFAULT_7a9c0bc2 | PENDING  |                |           16 |        2 | 5e-05 |          |          |                      |\n","+------------------+----------+----------------+--------------+----------+-------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=386)\u001b[0m 2020-12-09 13:42:08.637930: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=386)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m Training loss for epoch 1: 0.628031745625003\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m Training loss for epoch 2: 0.37869058430626773\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=386)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=386)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m Training loss for epoch 1: 0.6181302302413516\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m Training loss for epoch 2: 0.3897272947689761\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=386)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=386)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m Training loss for epoch 1: 0.659524104733398\n","\u001b[2m\u001b[36m(pid=386)\u001b[0m Training loss for epoch 2: 0.4744058852466408\n","Result for DEFAULT_7a9c0bc2:\n","  auc: 0.8336465855755205\n","  date: 2020-12-09_13-55-02\n","  done: false\n","  experiment_id: d95e3c48ac434ebba4a16a751d17fb6c\n","  experiment_tag: 2_batch_size=16,epochs=2,lr=5e-05\n","  hostname: dfae92d5365f\n","  iterations_since_restore: 1\n","  loss: 0.5095848584643158\n","  node_ip: 172.28.0.2\n","  pid: 386\n","  time_since_restore: 772.5341606140137\n","  time_this_iter_s: 772.5341606140137\n","  time_total_s: 772.5341606140137\n","  timestamp: 1607522102\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 7a9c0bc2\n","  \n","== Status ==\n","Memory usage on this node: 4.2/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.5656740371795157\n","Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.18 GiB heap, 0.0/2.44 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-09_13-21-42\n","Number of trials: 3/8 (1 PENDING, 1 RUNNING, 1 TERMINATED)\n","+------------------+------------+----------------+--------------+----------+-------+----------+----------+----------------------+\n","| Trial name       | status     | loc            |   batch_size |   epochs |    lr |     loss |      auc |   training_iteration |\n","|------------------+------------+----------------+--------------+----------+-------+----------+----------+----------------------|\n","| DEFAULT_7a9c0bc2 | RUNNING    | 172.28.0.2:386 |           16 |        2 | 5e-05 | 0.509585 | 0.833647 |                    1 |\n","| DEFAULT_546b667a | PENDING    |                |           16 |        3 | 5e-05 |          |          |                      |\n","| DEFAULT_7a6857be | TERMINATED |                |            8 |        3 | 2e-05 | 0.621763 | 0.852192 |                    1 |\n","+------------------+------------+----------------+--------------+----------+-------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=956)\u001b[0m 2020-12-09 13:55:04.243490: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=956)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m Training loss for epoch 1: 0.6095581750075022\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m Training loss for epoch 2: 0.3905989213842125\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m Training loss for epoch 3: 0.2093590086074051\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=956)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=956)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m Training loss for epoch 1: 0.5988135712158277\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m Training loss for epoch 2: 0.372393103685356\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m Training loss for epoch 3: 0.2120149424524555\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=956)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=956)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m Training loss for epoch 1: 0.6684979554535686\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m Training loss for epoch 2: 0.5363291733794742\n","\u001b[2m\u001b[36m(pid=956)\u001b[0m Training loss for epoch 3: 0.3439416029639002\n","Result for DEFAULT_546b667a:\n","  auc: 0.8373084335657307\n","  date: 2020-12-09_14-14-04\n","  done: true\n","  experiment_id: 7ca774b1b6ec4636ba23dfe18d02a513\n","  experiment_tag: 3_batch_size=16,epochs=3,lr=5e-05\n","  hostname: dfae92d5365f\n","  iterations_since_restore: 1\n","  loss: 0.5671508503624071\n","  node_ip: 172.28.0.2\n","  pid: 956\n","  time_since_restore: 1138.8799440860748\n","  time_this_iter_s: 1138.8799440860748\n","  time_total_s: 1138.8799440860748\n","  timestamp: 1607523244\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 546b667a\n","  \n","== Status ==\n","Memory usage on this node: 4.3/12.7 GiB\n","Using AsyncHyperBand: num_stopped=1\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.5671508503624071\n","Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.18 GiB heap, 0.0/2.44 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-09_13-21-42\n","Number of trials: 4/8 (1 PENDING, 3 TERMINATED)\n","+------------------+------------+-------+--------------+----------+-------+----------+----------+----------------------+\n","| Trial name       | status     | loc   |   batch_size |   epochs |    lr |     loss |      auc |   training_iteration |\n","|------------------+------------+-------+--------------+----------+-------+----------+----------+----------------------|\n","| DEFAULT_2279ad46 | PENDING    |       |           16 |        2 | 2e-05 |          |          |                      |\n","| DEFAULT_7a6857be | TERMINATED |       |            8 |        3 | 2e-05 | 0.621763 | 0.852192 |                    1 |\n","| DEFAULT_7a9c0bc2 | TERMINATED |       |           16 |        2 | 5e-05 | 0.509585 | 0.833647 |                    1 |\n","| DEFAULT_546b667a | TERMINATED |       |           16 |        3 | 5e-05 | 0.567151 | 0.837308 |                    1 |\n","+------------------+------------+-------+--------------+----------+-------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1245)\u001b[0m 2020-12-09 14:14:06.425913: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1245)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m Training loss for epoch 1: 0.6415765521606961\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m Training loss for epoch 2: 0.4735718579683903\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1245)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1245)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m Training loss for epoch 1: 0.6214637574942216\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m Training loss for epoch 2: 0.39616632321174594\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1245)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1245)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m Training loss for epoch 1: 0.5983448253161665\n","\u001b[2m\u001b[36m(pid=1245)\u001b[0m Training loss for epoch 2: 0.3934670258043469\n","Result for DEFAULT_2279ad46:\n","  auc: 0.8374665157065424\n","  date: 2020-12-09_14-26-12\n","  done: false\n","  experiment_id: c1cada43388143669b4e910df304f761\n","  experiment_tag: 4_batch_size=16,epochs=2,lr=2e-05\n","  hostname: dfae92d5365f\n","  iterations_since_restore: 1\n","  loss: 0.5023385261734709\n","  node_ip: 172.28.0.2\n","  pid: 1245\n","  time_since_restore: 724.2906517982483\n","  time_this_iter_s: 724.2906517982483\n","  time_total_s: 724.2906517982483\n","  timestamp: 1607523972\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 2279ad46\n","  \n","== Status ==\n","Memory usage on this node: 4.2/12.7 GiB\n","Using AsyncHyperBand: num_stopped=1\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.5383678544133614\n","Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.18 GiB heap, 0.0/2.44 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-09_13-21-42\n","Number of trials: 5/8 (1 PENDING, 1 RUNNING, 3 TERMINATED)\n","+------------------+------------+-----------------+--------------+----------+-------+----------+----------+----------------------+\n","| Trial name       | status     | loc             |   batch_size |   epochs |    lr |     loss |      auc |   training_iteration |\n","|------------------+------------+-----------------+--------------+----------+-------+----------+----------+----------------------|\n","| DEFAULT_2279ad46 | RUNNING    | 172.28.0.2:1245 |           16 |        2 | 2e-05 | 0.502339 | 0.837467 |                    1 |\n","| DEFAULT_cb1e259c | PENDING    |                 |           32 |        3 | 1e-05 |          |          |                      |\n","| DEFAULT_7a6857be | TERMINATED |                 |            8 |        3 | 2e-05 | 0.621763 | 0.852192 |                    1 |\n","| DEFAULT_7a9c0bc2 | TERMINATED |                 |           16 |        2 | 5e-05 | 0.509585 | 0.833647 |                    1 |\n","| DEFAULT_546b667a | TERMINATED |                 |           16 |        3 | 5e-05 | 0.567151 | 0.837308 |                    1 |\n","+------------------+------------+-----------------+--------------+----------+-------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1443)\u001b[0m 2020-12-09 14:26:13.807092: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1443)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m Training loss for epoch 1: 0.6545116924322568\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m Training loss for epoch 2: 0.541412851271721\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m Training loss for epoch 3: 0.40880019318025845\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1443)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1443)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m Training loss for epoch 1: 0.6429526341649202\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m Training loss for epoch 2: 0.5364512838423252\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m Training loss for epoch 3: 0.4228514342640455\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1443)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1443)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m Training loss for epoch 1: 0.6684460903589542\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m Training loss for epoch 2: 0.5912256679282739\n","\u001b[2m\u001b[36m(pid=1443)\u001b[0m Training loss for epoch 3: 0.45878010988235474\n","Result for DEFAULT_cb1e259c:\n","  auc: 0.7734920045381223\n","  date: 2020-12-09_14-43-11\n","  done: true\n","  experiment_id: 8aea6115b58f4d48be668ca6be246c40\n","  experiment_tag: 5_batch_size=32,epochs=3,lr=1e-05\n","  hostname: dfae92d5365f\n","  iterations_since_restore: 1\n","  loss: 0.5669525369492353\n","  node_ip: 172.28.0.2\n","  pid: 1443\n","  time_since_restore: 1016.6535909175873\n","  time_this_iter_s: 1016.6535909175873\n","  time_total_s: 1016.6535909175873\n","  timestamp: 1607524991\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: cb1e259c\n","  \n","== Status ==\n","Memory usage on this node: 4.3/12.7 GiB\n","Using AsyncHyperBand: num_stopped=2\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.5669525369492353\n","Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.18 GiB heap, 0.0/2.44 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-09_13-21-42\n","Number of trials: 6/8 (1 PENDING, 5 TERMINATED)\n","+------------------+------------+-------+--------------+----------+-------+----------+----------+----------------------+\n","| Trial name       | status     | loc   |   batch_size |   epochs |    lr |     loss |      auc |   training_iteration |\n","|------------------+------------+-------+--------------+----------+-------+----------+----------+----------------------|\n","| DEFAULT_7ccd1c2a | PENDING    |       |            8 |        3 | 2e-05 |          |          |                      |\n","| DEFAULT_7a6857be | TERMINATED |       |            8 |        3 | 2e-05 | 0.621763 | 0.852192 |                    1 |\n","| DEFAULT_7a9c0bc2 | TERMINATED |       |           16 |        2 | 5e-05 | 0.509585 | 0.833647 |                    1 |\n","| DEFAULT_546b667a | TERMINATED |       |           16 |        3 | 5e-05 | 0.567151 | 0.837308 |                    1 |\n","| DEFAULT_2279ad46 | TERMINATED |       |           16 |        2 | 2e-05 | 0.502339 | 0.837467 |                    1 |\n","| DEFAULT_cb1e259c | TERMINATED |       |           32 |        3 | 1e-05 | 0.566953 | 0.773492 |                    1 |\n","+------------------+------------+-------+--------------+----------+-------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1704)\u001b[0m 2020-12-09 14:43:13.814070: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1704)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m Training loss for epoch 1: 0.5972731544631691\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m Training loss for epoch 2: 0.3616375879717514\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m Training loss for epoch 3: 0.2361250184524179\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1704)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1704)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m Training loss for epoch 1: 0.6147056800011851\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m Training loss for epoch 2: 0.37516995999908104\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m Training loss for epoch 3: 0.215471639279906\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1704)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=1704)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m Training loss for epoch 1: 0.6088660380258653\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m Training loss for epoch 2: 0.4005644327650468\n","\u001b[2m\u001b[36m(pid=1704)\u001b[0m Training loss for epoch 3: 0.24858389553728688\n","Result for DEFAULT_7ccd1c2a:\n","  auc: 0.8536271697605836\n","  date: 2020-12-09_15-03-26\n","  done: true\n","  experiment_id: 29796f546e6748ba84c0c9e262897ac1\n","  experiment_tag: 6_batch_size=8,epochs=3,lr=2e-05\n","  hostname: dfae92d5365f\n","  iterations_since_restore: 1\n","  loss: 0.6260140958256866\n","  node_ip: 172.28.0.2\n","  pid: 1704\n","  time_since_restore: 1211.056120634079\n","  time_this_iter_s: 1211.056120634079\n","  time_total_s: 1211.056120634079\n","  timestamp: 1607526206\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 7ccd1c2a\n","  \n","== Status ==\n","Memory usage on this node: 4.2/12.7 GiB\n","Using AsyncHyperBand: num_stopped=3\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.5670516936558212\n","Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.18 GiB heap, 0.0/2.44 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-09_13-21-42\n","Number of trials: 7/8 (1 PENDING, 6 TERMINATED)\n","+------------------+------------+-------+--------------+----------+-------+----------+----------+----------------------+\n","| Trial name       | status     | loc   |   batch_size |   epochs |    lr |     loss |      auc |   training_iteration |\n","|------------------+------------+-------+--------------+----------+-------+----------+----------+----------------------|\n","| DEFAULT_dc9d146e | PENDING    |       |           32 |        2 | 2e-05 |          |          |                      |\n","| DEFAULT_7a6857be | TERMINATED |       |            8 |        3 | 2e-05 | 0.621763 | 0.852192 |                    1 |\n","| DEFAULT_7a9c0bc2 | TERMINATED |       |           16 |        2 | 5e-05 | 0.509585 | 0.833647 |                    1 |\n","| DEFAULT_546b667a | TERMINATED |       |           16 |        3 | 5e-05 | 0.567151 | 0.837308 |                    1 |\n","| DEFAULT_2279ad46 | TERMINATED |       |           16 |        2 | 2e-05 | 0.502339 | 0.837467 |                    1 |\n","| DEFAULT_cb1e259c | TERMINATED |       |           32 |        3 | 1e-05 | 0.566953 | 0.773492 |                    1 |\n","| DEFAULT_7ccd1c2a | TERMINATED |       |            8 |        3 | 2e-05 | 0.626014 | 0.853627 |                    1 |\n","+------------------+------------+-------+--------------+----------+-------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=2010)\u001b[0m 2020-12-09 15:03:28.246263: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=2010)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m Training loss for epoch 1: 0.6460603684760057\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m Training loss for epoch 2: 0.47896013065026355\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=2010)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=2010)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m Training loss for epoch 1: 0.6540391760376784\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m Training loss for epoch 2: 0.485520909468715\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=2010)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=2010)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m Training loss for epoch 1: 0.6479547482270461\n","\u001b[2m\u001b[36m(pid=2010)\u001b[0m Training loss for epoch 2: 0.485783673536319\n","Result for DEFAULT_dc9d146e:\n","  auc: 0.8043738499524257\n","  date: 2020-12-09_15-15-21\n","  done: false\n","  experiment_id: f902f36b61a24301be7ae8072d133b1c\n","  experiment_tag: 7_batch_size=32,epochs=2,lr=2e-05\n","  hostname: dfae92d5365f\n","  iterations_since_restore: 1\n","  loss: 0.5383306954247065\n","  node_ip: 172.28.0.2\n","  pid: 2010\n","  time_since_restore: 711.7953827381134\n","  time_this_iter_s: 711.7953827381134\n","  time_total_s: 711.7953827381134\n","  timestamp: 1607526921\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: dc9d146e\n","  \n","== Status ==\n","Memory usage on this node: 4.2/12.7 GiB\n","Using AsyncHyperBand: num_stopped=3\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.5669525369492353\n","Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.18 GiB heap, 0.0/2.44 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-09_13-21-42\n","Number of trials: 8/8 (1 PENDING, 1 RUNNING, 6 TERMINATED)\n","+------------------+------------+-----------------+--------------+----------+-------+----------+----------+----------------------+\n","| Trial name       | status     | loc             |   batch_size |   epochs |    lr |     loss |      auc |   training_iteration |\n","|------------------+------------+-----------------+--------------+----------+-------+----------+----------+----------------------|\n","| DEFAULT_dc9d146e | RUNNING    | 172.28.0.2:2010 |           32 |        2 | 2e-05 | 0.538331 | 0.804374 |                    1 |\n","| DEFAULT_b07de798 | PENDING    |                 |           16 |        4 | 2e-05 |          |          |                      |\n","| DEFAULT_7a6857be | TERMINATED |                 |            8 |        3 | 2e-05 | 0.621763 | 0.852192 |                    1 |\n","| DEFAULT_7a9c0bc2 | TERMINATED |                 |           16 |        2 | 5e-05 | 0.509585 | 0.833647 |                    1 |\n","| DEFAULT_546b667a | TERMINATED |                 |           16 |        3 | 5e-05 | 0.567151 | 0.837308 |                    1 |\n","| DEFAULT_2279ad46 | TERMINATED |                 |           16 |        2 | 2e-05 | 0.502339 | 0.837467 |                    1 |\n","| DEFAULT_cb1e259c | TERMINATED |                 |           32 |        3 | 1e-05 | 0.566953 | 0.773492 |                    1 |\n","| DEFAULT_7ccd1c2a | TERMINATED |                 |            8 |        3 | 2e-05 | 0.626014 | 0.853627 |                    1 |\n","+------------------+------------+-----------------+--------------+----------+-------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=2202)\u001b[0m 2020-12-09 15:15:23.432127: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=2202)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Training loss for epoch 1: 0.6262942112010458\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Training loss for epoch 2: 0.4132556789307203\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Training loss for epoch 3: 0.20980357792642382\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Training loss for epoch 4: 0.11168810254320556\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=2202)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=2202)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Training loss for epoch 1: 0.6270090186077616\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Training loss for epoch 2: 0.43519194222590774\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Training loss for epoch 3: 0.23721409940885174\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Training loss for epoch 4: 0.14021248878249765\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=2202)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[2m\u001b[36m(pid=2202)\u001b[0m Device: cuda\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Training loss for epoch 1: 0.6467352192758938\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Training loss for epoch 2: 0.4376493170497498\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Training loss for epoch 3: 0.23466223894038063\n","\u001b[2m\u001b[36m(pid=2202)\u001b[0m Training loss for epoch 4: 0.13098298916863144\n"],"name":"stdout"},{"output_type":"stream","text":["2020-12-09 15:40:43,870\tINFO tune.py:439 -- Total run time: 8344.54 seconds (8341.16 seconds for the tuning loop).\n"],"name":"stderr"},{"output_type":"stream","text":["Result for DEFAULT_b07de798:\n","  auc: 0.8488854335460952\n","  date: 2020-12-09_15-40-43\n","  done: true\n","  experiment_id: 1f7eb988a8894b42bfbbfa6b347ce9de\n","  experiment_tag: 8_batch_size=16,epochs=4,lr=2e-05\n","  hostname: dfae92d5365f\n","  iterations_since_restore: 1\n","  loss: 0.647390975222105\n","  node_ip: 172.28.0.2\n","  pid: 2202\n","  time_since_restore: 1518.9703786373138\n","  time_this_iter_s: 1518.9703786373138\n","  time_total_s: 1518.9703786373138\n","  timestamp: 1607528443\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: b07de798\n","  \n","== Status ==\n","Memory usage on this node: 4.2/12.7 GiB\n","Using AsyncHyperBand: num_stopped=4\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.5670516936558212\n","Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.18 GiB heap, 0.0/2.44 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-09_13-21-42\n","Number of trials: 8/8 (8 TERMINATED)\n","+------------------+------------+-------+--------------+----------+-------+----------+----------+----------------------+\n","| Trial name       | status     | loc   |   batch_size |   epochs |    lr |     loss |      auc |   training_iteration |\n","|------------------+------------+-------+--------------+----------+-------+----------+----------+----------------------|\n","| DEFAULT_7a6857be | TERMINATED |       |            8 |        3 | 2e-05 | 0.621763 | 0.852192 |                    1 |\n","| DEFAULT_7a9c0bc2 | TERMINATED |       |           16 |        2 | 5e-05 | 0.509585 | 0.833647 |                    1 |\n","| DEFAULT_546b667a | TERMINATED |       |           16 |        3 | 5e-05 | 0.567151 | 0.837308 |                    1 |\n","| DEFAULT_2279ad46 | TERMINATED |       |           16 |        2 | 2e-05 | 0.502339 | 0.837467 |                    1 |\n","| DEFAULT_cb1e259c | TERMINATED |       |           32 |        3 | 1e-05 | 0.566953 | 0.773492 |                    1 |\n","| DEFAULT_7ccd1c2a | TERMINATED |       |            8 |        3 | 2e-05 | 0.626014 | 0.853627 |                    1 |\n","| DEFAULT_dc9d146e | TERMINATED |       |           32 |        2 | 2e-05 | 0.538331 | 0.804374 |                    1 |\n","| DEFAULT_b07de798 | TERMINATED |       |           16 |        4 | 2e-05 | 0.647391 | 0.848885 |                    1 |\n","+------------------+------------+-------+--------------+----------+-------+----------+----------+----------------------+\n","\n","\n","== Status ==\n","Memory usage on this node: 4.2/12.7 GiB\n","Using AsyncHyperBand: num_stopped=4\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.5670516936558212\n","Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.18 GiB heap, 0.0/2.44 GiB objects (0/1.0 accelerator_type:T4)\n","Result logdir: /root/ray_results/DEFAULT_2020-12-09_13-21-42\n","Number of trials: 8/8 (8 TERMINATED)\n","+------------------+------------+-------+--------------+----------+-------+----------+----------+----------------------+\n","| Trial name       | status     | loc   |   batch_size |   epochs |    lr |     loss |      auc |   training_iteration |\n","|------------------+------------+-------+--------------+----------+-------+----------+----------+----------------------|\n","| DEFAULT_7a6857be | TERMINATED |       |            8 |        3 | 2e-05 | 0.621763 | 0.852192 |                    1 |\n","| DEFAULT_7a9c0bc2 | TERMINATED |       |           16 |        2 | 5e-05 | 0.509585 | 0.833647 |                    1 |\n","| DEFAULT_546b667a | TERMINATED |       |           16 |        3 | 5e-05 | 0.567151 | 0.837308 |                    1 |\n","| DEFAULT_2279ad46 | TERMINATED |       |           16 |        2 | 2e-05 | 0.502339 | 0.837467 |                    1 |\n","| DEFAULT_cb1e259c | TERMINATED |       |           32 |        3 | 1e-05 | 0.566953 | 0.773492 |                    1 |\n","| DEFAULT_7ccd1c2a | TERMINATED |       |            8 |        3 | 2e-05 | 0.626014 | 0.853627 |                    1 |\n","| DEFAULT_dc9d146e | TERMINATED |       |           32 |        2 | 2e-05 | 0.538331 | 0.804374 |                    1 |\n","| DEFAULT_b07de798 | TERMINATED |       |           16 |        4 | 2e-05 | 0.647391 | 0.848885 |                    1 |\n","+------------------+------------+-------+--------------+----------+-------+----------+----------+----------------------+\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uyn5bvPkOBKD","colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"status":"ok","timestamp":1607528444394,"user_tz":360,"elapsed":8423228,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}},"outputId":"82bc9e4d-d147-4be0-c4d2-71f1098f2bc6"},"source":["dfs = result.fetch_trial_dataframes()\n","\n","aucs = []\n","losses = []\n","for d in dfs.values():\n","  aucs.append(d.auc)\n","  losses.append(d.loss)\n","\n","plt.plot(range(0, 8), aucs, label=\"AUC\")\n","plt.plot(range(0, 8), losses, label=\"Loss\")\n","plt.legend()\n","plt.xlabel(\"Trial No.\")\n","plt.ylabel(\"Score\")\n"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, 'Score')"]},"metadata":{"tags":[]},"execution_count":13},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"zJ_8nj1gQ-ZN"},"source":["best candidates appear to come from trials with batch 8 epoch 3, and batch 16 epoch 4"]},{"cell_type":"code","metadata":{"id":"YX_eyd6dRFIP","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["1cfd21f16baa4de08e7ed3f632b2ffc3","19b841c63f81492ab9379b29bd6b64d1","8b2da1c67dd647f1b2c8e09f1ad58963","8caf7eb70de5469986614de16c5948bf","146990475e1f4f32994a2e3da6996b17","2870dbf4bdd248f586179dd3cbd8427e","b903bf8d55e34b8cb0e460837b75afdc","ee43b69be8c64a0fa8f45799fe8f22b2"]},"executionInfo":{"status":"ok","timestamp":1607547539179,"user_tz":360,"elapsed":413,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}},"outputId":"388af4bc-9893-4125-8926-010cc1c10c5f"},"source":["def train(model, epochs, train_dataloader, test_dataloader, optimizer, scheduler):\n","  for epoch in tqdm(range(1, epochs+1)): # use tqdm for a progress bar\n","    model.train() # enter training mode\n","    loss_train_total = 0\n","\n","    progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch}', leave=False, disable=False)\n","    for batch in progress_bar:\n","        model.zero_grad()\n","        \n","        # get CUDA data\n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {\n","            'input_ids':      batch[0],\n","            'attention_mask': batch[1],\n","            'labels':         batch[2],\n","        }\n","\n","        outputs = model(**inputs) # evaluate\n","        \n","        # for reference, we are using cross-entropy loss here,\n","        # as implemented in https://huggingface.co/transformers/_modules/transformers/modeling_bert.html\n","        loss = outputs[0]\n","        loss_train_total += loss.item()\n","        loss.backward() # do backprop\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n","          \n","        \n","    torch.save(model.state_dict(), f'/content/drive/MyDrive/finetuned_BERT_epoch_{epoch}.model')\n","        \n","    tqdm.write(f'\\nEpoch {epoch}')\n","    \n","    loss_train_avg = loss_train_total/len(train_dataloader)            \n","    tqdm.write(f'Training loss: {loss_train_avg}')\n","    \n","    val_loss, predictions, true_vals = evaluate(model, test_dataloader, device)\n","    auc = auc_score(predictions, true_vals)\n","    tqdm.write(f'Testing loss: {val_loss}')\n","    tqdm.write(f'AUC: {auc}')\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n","                                          do_lower_case=True)"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1cfd21f16baa4de08e7ed3f632b2ffc3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6lt5Tp79SaXm","executionInfo":{"status":"ok","timestamp":1607549533309,"user_tz":360,"elapsed":375,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}}},"source":["def new_train_test_split(dataset_clf):\n","  X_train, X_val, y_train, y_val = train_test_split(dataset_clf.index.values, \n","                                                    dataset_clf.party.values, \n","                                                    test_size=0.15, \n","                                                    random_state=42, \n","                                                    stratify=dataset_clf.party.values)\n","\n","  dataset_clf['data_type'] = ['not_set']*dataset_final.shape[0]\n","\n","  dataset_clf.loc[X_train, 'data_type'] = 'train'\n","  dataset_clf.loc[X_val, 'data_type'] = 'test'\n","\n","  # dataset_train = dataset_clf.loc[dataset_clf.data_type == 'train']\n","  # dataset_test = dataset_clf.loc[dataset_clf.data_type == 'test']"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Gjc8Pg1XgjS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607553388816,"user_tz":360,"elapsed":343,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}},"outputId":"df68a815-1c78-435d-b248-f8faba92145d"},"source":["new_train_test_split(dataset_clf)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  isetter(loc, value)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"MCBTpyeZUees","colab":{"base_uri":"https://localhost:8080/","height":435,"referenced_widgets":["aedf86e4aef9406e8f070f04512f3f32","48ce09661b784e099a3e1d62e32828fd","12e70703476545ec82b1e3db23dc699e","ca9b36e92ecc41f7a19e9fa33302089a","351908f75d5b4c93bbaca50cf3507268","a0d3717173604fd4ba8a6d27983bf003","c72b9eae4555468ea6513489ab03b297","2aa06c9a904548e4a6c9fef69e830bcd","3c0c7bbf14ad41028c6eef573691baf8","139a27385f704942aa5d99a6ea0297a7","64c0de4931da452792a633bede2311ea","c5abffc436f94a268ca7b95ff8df1219","cef028e4e93740ef89a2aea4866659c7","b16ac8af65d146e7a051d537567d76b3","bf0b224ac1404de687c2ecd90601711c","d90649d62549499c809afa09ccb0beae","12f4b8974f034a8fbc64cdfe584b1b12","96f306869c1c4ec6afe959fdf952ea84","e40c4a1aa78a4075b8d541f02e4fe64c","3afed3c5a3264a5daac1309c6d2b3b67","6fd6edec6c7a46f89239b4ad06cf3bab","e036eb9a9aea4fee80fc45f411522949","fa9057f38fb44940920bf51cf16b8308","75a7be2e6394498bb5645ac9b44afa6a","feb4e4b986634c05b2321069a6e9efb9","8883b2213938457a87d38e3596079dbf","c586891ac961483690da5fb6df07ce9d","20a66a847789494b89ef52ed85945f0f","0d51e4d006534a2daf6fea48327ccb20","03e62d9a45fb4e44a0dede7c208902f1","ea5b360f8c9c4899882d65bb3927fab8","5af1f5f8b95e423aae2f3b95585a8623"]},"executionInfo":{"status":"ok","timestamp":1607551667724,"user_tz":360,"elapsed":1007610,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}},"outputId":"cfe854d1-01ed-4ecd-d3e5-72ff1b552ebb"},"source":["# trial 2 for 10k\n","# |  batch_size |   epochs |          lr |\n","#            16 |        4 | 2e-05\n","\n","import random\n","\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","EPOCHS = 3\n","BATCH_SIZE = 16\n","lr = 2e-5\n","\n","\n","train_dataloader, test_dataloader = get_dataloaders(dataset_clf, BATCH_SIZE)\n","\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n","                                                    num_labels=2,\n","                                                    output_attentions=False,\n","                                                    output_hidden_states=False)\n","\n","optimizer = AdamW(model.parameters(),\n","                  lr=lr,\n","                  eps=1e-8)\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps=0, \n","                                            num_training_steps=len(train_dataloader)*EPOCHS)\n","model.to(device)\n","\n","train(model, EPOCHS, train_dataloader, test_dataloader, optimizer, scheduler)\n","test_loss, preds, labels = evaluate(model, test_dataloader, device)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aedf86e4aef9406e8f070f04512f3f32","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c0c7bbf14ad41028c6eef573691baf8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=528.0, style=ProgressStyle(description_widt…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r\n","Epoch 1\n","Training loss: 0.5386573755266991\n","Testing loss: 0.4175835700428232\n","AUC: 0.8906339576869973\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12f4b8974f034a8fbc64cdfe584b1b12","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=528.0, style=ProgressStyle(description_widt…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r\n","Epoch 2\n","Training loss: 0.31054414546992065\n","Testing loss: 0.39128657089585955\n","AUC: 0.9175344389941767\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"feb4e4b986634c05b2321069a6e9efb9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch 3', max=528.0, style=ProgressStyle(description_widt…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r\n","Epoch 3\n","Training loss: 0.16890854493513788\n","Testing loss: 0.4912815410049355\n","AUC: 0.9160394557597409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mHnh2DuhbXVH","colab":{"base_uri":"https://localhost:8080/","height":335},"executionInfo":{"status":"ok","timestamp":1607549040125,"user_tz":360,"elapsed":628,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}},"outputId":"b194a903-6d68-4eb2-e024-c173fdc7668f"},"source":["print(f\"Accuracy: {accuracy_score(labels, np.argmax(preds, axis=1))}\")\n","print(f\"AUC Score: {auc_score(preds, labels)}\")\n","print(f\"Test loss: {test_loss}\")\n","sns.heatmap(confusion_matrix(labels, np.argmax(preds, axis=1)), annot=True, fmt=\"d\")"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Accuracy: 0.7879194630872484\n","AUC Score: 0.8797161097728583\n","Test loss: 0.6821598135965302\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f1247658eb8>"]},"metadata":{"tags":[]},"execution_count":19},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"2mD-hJ9hV0Hp","colab":{"base_uri":"https://localhost:8080/","height":435,"referenced_widgets":["c9ef9a33db2b4cde92249986068124ca","73a460d9379a4d54bcb09bcb42b22eca","2b5ff1ac8d3149af80104e734c3e0f74","1831070542a74857a0f40789e406a54c","29ee32da890543b4b66eb316991672b0","cbf9cfb3ae0446eeb5faf7c9e3cd05cd","2f73cd982d8c4c748e071ca22101fe66","7093e00c3a2b45588ba2b2bf65bc2089","3f648499a90943e9b6d26bce1ef02655","3f7b38aace164d25ae9b4092c7605c39","c577a11afdde4100a4d51dfcb97f3464","3ca74aa8697c43358d840dfafd9557c5","dbf0b26e0234456384d947ab193abd5a","184ea8a5f9754264b11e7a98188572da","67e02d0ab2d34779b671300c6fa5ec51","596479eb4d6d4a879221cf610d457937","f69570c1e9e945a4a6802d7125a94416","d27dbe86269043959a63cbdd0173ed05","414f68ba7c10437cbaf9dfc5009cda86","72cd75e94bc94ddd956c680006a2d8c5","e8f304fb4a90453a9122da9679d38b32","b6e9e4fcd6d14154b57efdd2222d6018","cf3cf25e29e342b68594c6d222fdcf28","ffc4fe63ef4742b7b021bb7e503b8365","a33e773d78ac43909dadc932cd817053","d82add1945d64244aa440253f8daf401","aa38681f05f049559887481067df703d","ced68a1ad33e4f8c851785a6f975434d","8dec683a312646569dbaf29ba0ff48f9","13ffdbb4a24d402dae6f140a00d19b4b","03eabcd2760546ddaeb94b3189e847ef","e89af0f34c0945e78084441963a104b6"]},"executionInfo":{"status":"ok","timestamp":1607562766842,"user_tz":360,"elapsed":9372148,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}},"outputId":"b003cdb6-1b85-493e-d960-dc10543e47ef"},"source":["# trial 1 for 50k\n","# |  batch_size |   epochs |          lr |\n","# |           8 |        3 | 2e-05 |\n","# Ran with epoch 3 and gave a worse auc/loss/accuracy, so running it with epoch 2\n","import random\n","\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","EPOCHS = 3\n","BATCH_SIZE = 8\n","lr = 2e-5\n","\n","\n","train_dataloader, test_dataloader = get_dataloaders(dataset_clf, BATCH_SIZE)\n","\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n","                                                    num_labels=2,\n","                                                    output_attentions=False,\n","                                                    output_hidden_states=False)\n","\n","optimizer = AdamW(model.parameters(),\n","                  lr=lr,\n","                  eps=1e-8)\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps=0, \n","                                            num_training_steps=len(train_dataloader)*EPOCHS)\n","model.to(device)\n","\n","train(model, EPOCHS, train_dataloader, test_dataloader, optimizer, scheduler)\n","test_loss, preds, labels = evaluate(model, test_dataloader, device)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9ef9a33db2b4cde92249986068124ca","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f648499a90943e9b6d26bce1ef02655","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=5278.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r\r\r\n","Epoch 1\n","Training loss: 0.4298693675768582\n","Testing loss: 0.38231699006999703\n","AUC: 0.9282495508488825\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f69570c1e9e945a4a6802d7125a94416","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=5278.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r\r\r\n","Epoch 2\n","Training loss: 0.2719934223457612\n","Testing loss: 0.4718398309407442\n","AUC: 0.9375457915501538\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a33e773d78ac43909dadc932cd817053","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch 3', max=5278.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r\r\r\n","Epoch 3\n","Training loss: 0.1500415800407391\n","Testing loss: 0.660488260722317\n","AUC: 0.938660206530352\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"THIjCQJoV0Hr","colab":{"base_uri":"https://localhost:8080/","height":335},"executionInfo":{"status":"ok","timestamp":1607562797948,"user_tz":360,"elapsed":459,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}},"outputId":"a6cb3a82-0030-493d-aec1-f0814b7231d7"},"source":["print(f\"Accuracy: {accuracy_score(labels, np.argmax(preds, axis=1))}\")\n","print(f\"AUC Score: {auc_score(preds, labels)}\")\n","print(f\"Test loss: {test_loss}\")\n","sns.heatmap(confusion_matrix(labels, np.argmax(preds, axis=1)), annot=True, fmt=\"d\")"],"execution_count":43,"outputs":[{"output_type":"stream","text":["Accuracy: 0.8696819218896792\n","AUC Score: 0.938660206530352\n","Test loss: 0.660488260722317\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f1246a31400>"]},"metadata":{"tags":[]},"execution_count":43},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"RIwfQJCYNcHk","executionInfo":{"status":"ok","timestamp":1607562936868,"user_tz":360,"elapsed":2741,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}}},"source":["torch.save(model,\"/content/drive/MyDrive/50k_tweets_model.model\")"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaBmAqQhZyGC"},"source":["Trial # 1 seemed to go better (at least on the train-test split we evaluated both models on). Therefore, we will pick that trial as our winner and have the following hyperparameters:\n","\n","- Batch Size: 16\n","- Epochs: 2\n","- Learning rate: 2e-5"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435,"referenced_widgets":["7468ccadd3204340842f7bcd2a2bacf2","401e144da1044713b8db8e2299182ff7","19c696543ffb41ecb3df47c522b21d8b","267ede7e8fc145ee94118b5880b288ff","0bdd44c7263a42a69c5e18e3c2cb6982","612e20814c1b4b2dbc0c1d814e1eec9c","0f6c0161cd5a42c0ba37c70aceb9dc90","6f465c8c8e184b6990e7f8e08444254b","e000f536ef814602aea430fc24b8f795","cf65784abdb94bfa8064d09dc8b92206","55a8bc6553254be89a74d1d12a773cb4","a9d2576710d2473499ff2df80dbff610","5c568f54e23345ff8fff951f835b4694","96a46535cd1b4069b4d0e11f34e9cb51","d658b33dc5a04140b31b5ef75874a4d7","856d2abae1424d65bc7fe5459793bf13","49b597cfd955458fa33468d4a8474763","5d427dfad0224df7aaac6e01daf83f8c","29243eb21d3849d49f5dfa561f65d0f5","491a52d6df444fa6a5f470b65cedf4db","5553f748bd4744b39c62b23ce57afe20","38a33adf847e4c2187d8bec769d34d56","9b2e5661ab5a4f878bd635003c20e0a5","da50178dd2ce4e0e8dd8c9934f2c9043","6f0943028dfa46c0a28130f63a938baf","adabea3c499442e9b91686df1df86877","74bbc2461d3646b89eadf51866a305e4","e12440464bbb4cef9cdc9ce5c9f5a288","c04ff95ae722444e944ff87881332dcc","2f606a341bfe4ba0933e5279cbfcc05e","af2448fb344a487f9a0c7315edbd4c74","5555fda1f0d04f41a6892a9b2363f47d"]},"id":"lfHgJ6MNjb-p","executionInfo":{"status":"ok","timestamp":1607553078484,"user_tz":360,"elapsed":1227996,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}},"outputId":"dd5cdef3-051e-4d55-de14-68f1512b5207"},"source":["# trial 3 for 10k\r\n","# |  batch_size |   epochs |          lr |\r\n","# |           4 |        3 | 2e-05 |\r\n","# Ran with epoch 3 and gave a worse auc/loss/accuracy, so running it with epoch 2\r\n","import random\r\n","\r\n","seed_val = 42\r\n","random.seed(seed_val)\r\n","np.random.seed(seed_val)\r\n","torch.manual_seed(seed_val)\r\n","torch.cuda.manual_seed_all(seed_val)\r\n","\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","EPOCHS = 3\r\n","BATCH_SIZE = 4\r\n","lr = 2e-5\r\n","\r\n","\r\n","train_dataloader, test_dataloader = get_dataloaders(dataset_clf, BATCH_SIZE)\r\n","\r\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\r\n","                                                    num_labels=2,\r\n","                                                    output_attentions=False,\r\n","                                                    output_hidden_states=False)\r\n","\r\n","optimizer = AdamW(model.parameters(),\r\n","                  lr=lr,\r\n","                  eps=1e-8)\r\n","scheduler = get_linear_schedule_with_warmup(optimizer,\r\n","                                            num_warmup_steps=0, \r\n","                                            num_training_steps=len(train_dataloader)*EPOCHS)\r\n","model.to(device)\r\n","\r\n","train(model, EPOCHS, train_dataloader, test_dataloader, optimizer, scheduler)\r\n","test_loss, preds, labels = evaluate(model, test_dataloader, device)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7468ccadd3204340842f7bcd2a2bacf2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e000f536ef814602aea430fc24b8f795","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=2110.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r\n","Epoch 1\n","Training loss: 0.5460656700404228\n","Testing loss: 0.4521691040198341\n","AUC: 0.9051966796993812\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49b597cfd955458fa33468d4a8474763","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=2110.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r\n","Epoch 2\n","Training loss: 0.379504987029127\n","Testing loss: 0.644182944117893\n","AUC: 0.9151297464796001\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f0943028dfa46c0a28130f63a938baf","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch 3', max=2110.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r\n","Epoch 3\n","Training loss: 0.17771465573868833\n","Testing loss: 0.9104426930458069\n","AUC: 0.9161214862824689\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"33QOB_6kh_kK","executionInfo":{"status":"ok","timestamp":1607568515702,"user_tz":360,"elapsed":18711,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}}},"source":["model50 = torch.load(\"/content/drive/MyDrive/Copy of 50k_tweets_model.model\")"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8RsvMnOjScT","executionInfo":{"status":"ok","timestamp":1607568591146,"user_tz":360,"elapsed":2436,"user":{"displayName":"Shujah Ahmad","photoUrl":"","userId":"08196470090891976479"}}},"source":["torch.save(model50.state_dict(),\"/content/drive/MyDrive/new_50k_tweets_model.model\")"],"execution_count":9,"outputs":[]}]}