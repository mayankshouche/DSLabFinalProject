{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EvaluateModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "303fd2f4d0984eeea2f84df9bc608824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_10143970c98c40c6b71d2267f28f9284",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5fe46bb5634c4ac29f58eb3d59c93363",
              "IPY_MODEL_4c00b83df3f74eb29b1f43db4e1598af"
            ]
          }
        },
        "10143970c98c40c6b71d2267f28f9284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5fe46bb5634c4ac29f58eb3d59c93363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_090534af6af74059b8cedd9d4c3c2314",
            "_dom_classes": [],
            "description": "  5%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 373,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 19,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7bbd14965eaa4ee3bc8d7df1dc544246"
          }
        },
        "4c00b83df3f74eb29b1f43db4e1598af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0fb7d68ed59a40b695ed5e7035606d69",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 19/373 [00:23&lt;07:30,  1.27s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e46b4a71c5e94e60b5a11230abc669c5"
          }
        },
        "090534af6af74059b8cedd9d4c3c2314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7bbd14965eaa4ee3bc8d7df1dc544246": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fb7d68ed59a40b695ed5e7035606d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e46b4a71c5e94e60b5a11230abc669c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "579bBwcvMU4e",
        "outputId": "e452e809-15c8-422c-cab8-1545b1e50791"
      },
      "source": [
        "!pip install transformers datasets tweet-preprocessor"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 7.6MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/38/0c24dce24767386123d528d27109024220db0e7a04467b658d587695241a/datasets-1.1.3-py3-none-any.whl (153kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 28.3MB/s \n",
            "\u001b[?25hCollecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 24.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 22.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.4)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 57.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.11.1)\n",
            "Collecting pyarrow>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n",
            "\u001b[K     |████████████████████████████████| 17.7MB 212kB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=793a1ef105f7812e677a8fac3028a9db0d3e8e3cb451bb996cec733265b61a53\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, xxhash, pyarrow, datasets, tweet-preprocessor\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed datasets-1.1.3 pyarrow-2.0.0 sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1 tweet-preprocessor-0.6.0 xxhash-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0AxO3wpL_oG"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import wordcloud\r\n",
        "import preprocessor as p # tweet-preprocessor\r\n",
        "import nltk\r\n",
        "import re\r\n",
        "import seaborn as sns\r\n",
        "import torch\r\n",
        "\r\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup\r\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\r\n",
        "from datasets import Dataset\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from scipy.special import softmax\r\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc3SmAkrPVVi"
      },
      "source": [
        "def auc_score(preds, labels):\r\n",
        "  soft_preds = softmax(preds, axis=1) # logit -> probability\r\n",
        "  print(preds.shape, labels.shape)\r\n",
        "  if np.shape(preds)[1] > 2: # check for multi-class\r\n",
        "    return roc_auc_score(labels, soft_preds, multi_class='ovr')\r\n",
        "  else:\r\n",
        "    soft_preds = soft_preds[:,1]\r\n",
        "    return roc_auc_score(labels, soft_preds)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzSoqAkAPkq5"
      },
      "source": [
        "device = \"cuda\"\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0yShuXhNH_1"
      },
      "source": [
        "X_val = pd.read_csv(\"/content/drive/MyDrive/X_val.csv.zip\")\r\n",
        "y_val = pd.read_csv(\"/content/drive/MyDrive/y_val.csv.zip\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbqTNj3AMlNP"
      },
      "source": [
        "def preprocess_tweet(tweet):\r\n",
        "  clean_tweet = tweet.replace('@', '')\r\n",
        "  clean_tweet = clean_tweet.replace('#', '')\r\n",
        "  clean_tweet = clean_tweet.replace('&', '')\r\n",
        "  clean_tweet = re.sub(r'[^A-Za-z0-9.!, ]+', '', clean_tweet)\r\n",
        "  split = [word.lower() for word in clean_tweet.split() if 'http' not in word.lower() and 'jpg' not in word.lower() and 'www' not in word.lower() and word.lower() not in['amp', 'qt']]\r\n",
        "  return ' '.join(split)\r\n",
        "\r\n",
        "\r\n",
        "X_val[\"clean_text\"] = X_val['text'].apply(lambda x: preprocess_tweet(x))\r\n",
        "y_val[\"label\"] = y_val['party'].apply(lambda party: 1 if party=='R' else 0)\r\n",
        "\r\n",
        "dataset = pd.concat([X_val, y_val.label], axis=1)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "id": "-VBJTguPVmJP",
        "outputId": "2f13c019-5f73-4809-845e-ad2130ab2a64"
      },
      "source": [
        "dataset_test = dataset.sample(frac=0.4, random_state=42)\r\n",
        "dataset_test"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>id</th>\n",
              "      <th>screen_name</th>\n",
              "      <th>user_id</th>\n",
              "      <th>time</th>\n",
              "      <th>link</th>\n",
              "      <th>text</th>\n",
              "      <th>source</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22496</th>\n",
              "      <td>179558</td>\n",
              "      <td>2891</td>\n",
              "      <td>1247288473498849280</td>\n",
              "      <td>RepBarbaraLee</td>\n",
              "      <td>248735463</td>\n",
              "      <td>2020-04-06T18:22:00-04:00</td>\n",
              "      <td>https://www.twitter.com/RepBarbaraLee/statuses...</td>\n",
              "      <td>We all have a duty #StayAtHome. Great song rem...</td>\n",
              "      <td>TweetDeck</td>\n",
              "      <td>we all have a duty stayathome. great song remi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117145</th>\n",
              "      <td>212392</td>\n",
              "      <td>525</td>\n",
              "      <td>1252975709263446016</td>\n",
              "      <td>NRDems</td>\n",
              "      <td>247486443</td>\n",
              "      <td>2020-04-22T11:01:02-04:00</td>\n",
              "      <td>https://www.twitter.com/YellowstoneNPS/statuse...</td>\n",
              "      <td>RT @YellowstoneNPS Happy #EarthDay!\\n\\nTo cele...</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>rt yellowstonenps happy earthday!to celebrate ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>205668</td>\n",
              "      <td>1083</td>\n",
              "      <td>1251571271919382528</td>\n",
              "      <td>justinamash</td>\n",
              "      <td>233842454</td>\n",
              "      <td>2020-04-18T14:00:18-04:00</td>\n",
              "      <td>https://www.twitter.com/justinamash/statuses/1...</td>\n",
              "      <td>@LibertyCliff @YALiberty Thanks!</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>libertycliff yaliberty thanks!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93519</th>\n",
              "      <td>294382</td>\n",
              "      <td>547</td>\n",
              "      <td>1268552145248423936</td>\n",
              "      <td>RepStephenLynch</td>\n",
              "      <td>310310133</td>\n",
              "      <td>2020-06-04T10:36:14-04:00</td>\n",
              "      <td>https://www.twitter.com/RepStephenLynch/status...</td>\n",
              "      <td>The message of Brockton’s unified condemnation...</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>the message of brocktons unified condemnation ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102773</th>\n",
              "      <td>341580</td>\n",
              "      <td>3507</td>\n",
              "      <td>1277767759338901504</td>\n",
              "      <td>RepJimBanks</td>\n",
              "      <td>816131319033950208</td>\n",
              "      <td>2020-06-29T20:55:48-04:00</td>\n",
              "      <td>https://www.twitter.com/RepJimBanks/statuses/1...</td>\n",
              "      <td>Trust me, Ted. We can only hope you guys are d...</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>trust me, ted. we can only hope you guys are d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101910</th>\n",
              "      <td>361530</td>\n",
              "      <td>2838</td>\n",
              "      <td>1281768713386000384</td>\n",
              "      <td>repjimcooper</td>\n",
              "      <td>22523087</td>\n",
              "      <td>2020-07-10T21:54:10-04:00</td>\n",
              "      <td>https://www.twitter.com/repjimcooper/statuses/...</td>\n",
              "      <td>It’s Friday night so if Trump isn’t firing Ins...</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>its friday night so if trump isnt firing inspe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95472</th>\n",
              "      <td>36325</td>\n",
              "      <td>72</td>\n",
              "      <td>1221910354088878080</td>\n",
              "      <td>RepGraceMeng</td>\n",
              "      <td>1051127714</td>\n",
              "      <td>2020-01-27T16:38:25-05:00</td>\n",
              "      <td>https://www.twitter.com/RepGraceMeng/statuses/...</td>\n",
              "      <td>In addition, I’m fighting to ensure that #Musl...</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>in addition, im fighting to ensure that muslim...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>101067</td>\n",
              "      <td>2555</td>\n",
              "      <td>1234926508634001408</td>\n",
              "      <td>SenateGOP</td>\n",
              "      <td>14344823</td>\n",
              "      <td>2020-03-03T14:39:58-05:00</td>\n",
              "      <td>https://www.twitter.com/SenatorTimScott/status...</td>\n",
              "      <td>RT @SenatorTimScott At today's Senate HELP Hea...</td>\n",
              "      <td>TweetDeck</td>\n",
              "      <td>rt senatortimscott at todays senate help heari...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115417</th>\n",
              "      <td>186116</td>\n",
              "      <td>1527</td>\n",
              "      <td>1248282252204744704</td>\n",
              "      <td>SteveScalise</td>\n",
              "      <td>1209417007</td>\n",
              "      <td>2020-04-09T12:10:55-04:00</td>\n",
              "      <td>https://www.twitter.com/RepDLamborn/statuses/1...</td>\n",
              "      <td>RT @RepDLamborn Once again Democrats prefer to...</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>rt repdlamborn once again democrats prefer to ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90015</th>\n",
              "      <td>265830</td>\n",
              "      <td>1752</td>\n",
              "      <td>1262413108561293312</td>\n",
              "      <td>TheBlackCaucus</td>\n",
              "      <td>233783568</td>\n",
              "      <td>2020-05-18T12:01:54-04:00</td>\n",
              "      <td>https://www.twitter.com/TheBlackCaucus/statuse...</td>\n",
              "      <td>Breonna was murdered in March, yet this incide...</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>breonna was murdered in march, yet this incide...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47620 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0  ...  label\n",
              "22496       179558  ...      0\n",
              "117145      212392  ...      0\n",
              "505         205668  ...      0\n",
              "93519       294382  ...      0\n",
              "102773      341580  ...      1\n",
              "...            ...  ...    ...\n",
              "101910      361530  ...      0\n",
              "95472        36325  ...      0\n",
              "200         101067  ...      1\n",
              "115417      186116  ...      1\n",
              "90015       265830  ...      0\n",
              "\n",
              "[47620 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFsNKz21OL9F"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \r\n",
        "                                        do_lower_case=True)\r\n",
        "\r\n",
        "encoded_data_test = tokenizer.batch_encode_plus(\r\n",
        "  dataset_test.clean_text.values, \r\n",
        "  add_special_tokens=True, \r\n",
        "  return_attention_mask=True, \r\n",
        "  padding=True, \r\n",
        "  truncation=True, \r\n",
        "  return_tensors='pt'\r\n",
        ")\r\n",
        "\r\n",
        "input_ids_test = encoded_data_test['input_ids']\r\n",
        "attention_masks_test = encoded_data_test['attention_mask']\r\n",
        "labels_test = torch.tensor(dataset_test.label.values)\r\n",
        "\r\n",
        "BATCH_SIZE=128\r\n",
        "\r\n",
        "test_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\r\n",
        "\r\n",
        "test_dataloader = DataLoader(test_data,\r\n",
        "                             sampler=SequentialSampler(test_data),\r\n",
        "                             batch_size=BATCH_SIZE)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZOdoS6WPV7T"
      },
      "source": [
        "def evaluate(model, dataloader):\r\n",
        "  model.to(device)\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  loss_val_total = 0\r\n",
        "  predictions, true_vals = [], []\r\n",
        "  \r\n",
        "  progress_bar = tqdm(dataloader)\r\n",
        "  for batch in progress_bar:  \r\n",
        "    # convert data to CUDA\r\n",
        "    batch = tuple(b.to(device) for b in batch)\r\n",
        "    \r\n",
        "    inputs = {\r\n",
        "        'input_ids':      batch[0],\r\n",
        "        'attention_mask': batch[1],\r\n",
        "        'labels':         batch[2],\r\n",
        "    }\r\n",
        "\r\n",
        "    with torch.no_grad():        \r\n",
        "        outputs = model(**inputs) # get predictions\r\n",
        "        \r\n",
        "    loss = outputs[0]\r\n",
        "    logits = outputs[1]\r\n",
        "    loss_val_total += loss.item()\r\n",
        "\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    label_ids = inputs['labels'].cpu().numpy()\r\n",
        "    predictions.append(logits)\r\n",
        "    true_vals.append(label_ids)\r\n",
        "\r\n",
        "  loss_val_avg = loss_val_total/len(dataloader) \r\n",
        "\r\n",
        "  predictions = np.concatenate(predictions, axis=0)\r\n",
        "  true_vals = np.concatenate(true_vals, axis=0)\r\n",
        "\r\n",
        "  auc = auc_score(predictions, true_vals)\r\n",
        "\r\n",
        "  print(f'AUC: {auc}')\r\n",
        "  print(f'Cross-entropy loss: {loss_val_avg}')\r\n",
        "  print(f\"Accuracy: {accuracy_score(true_vals, np.argmax(predictions, axis=1))}\")  \r\n",
        "  sns.heatmap(confusion_matrix(true_vals, np.argmax(predictions, axis=1)), annot=True, fmt=\"d\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "303fd2f4d0984eeea2f84df9bc608824",
            "10143970c98c40c6b71d2267f28f9284",
            "5fe46bb5634c4ac29f58eb3d59c93363",
            "4c00b83df3f74eb29b1f43db4e1598af",
            "090534af6af74059b8cedd9d4c3c2314",
            "7bbd14965eaa4ee3bc8d7df1dc544246",
            "0fb7d68ed59a40b695ed5e7035606d69",
            "e46b4a71c5e94e60b5a11230abc669c5"
          ]
        },
        "id": "h9lHwGEtQmxY",
        "outputId": "69673713-5958-46c5-aec6-d0a3297a0312"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\r\n",
        "                                                      num_labels=2,\r\n",
        "                                                      output_attentions=False,\r\n",
        "                                                      output_hidden_states=False)\r\n",
        "\r\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/model_v2.model\"))\r\n",
        "\r\n",
        "evaluate(model, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "303fd2f4d0984eeea2f84df9bc608824",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=373.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}